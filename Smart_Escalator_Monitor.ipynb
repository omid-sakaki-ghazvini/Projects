{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Install dependencies**"
      ],
      "metadata": {
        "id": "VUs-AbjbdU3B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q ultralytics opencv-python-headless numpy tqdm\n",
        "\n",
        "import cv2\n",
        "import numpy as np\n",
        "from ultralytics import YOLO\n",
        "from google.colab import files\n",
        "import os\n",
        "from IPython.display import display, HTML\n",
        "from tqdm.notebook import tqdm\n",
        "import time"
      ],
      "metadata": {
        "id": "0lYNX1V4dP0I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Load YOLOv8 object detection model with GPU support.**"
      ],
      "metadata": {
        "id": "ERBgxML8ddh2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_model():\n",
        "    return YOLO(\"yolov8x.pt\")  # Large model for high accuracy"
      ],
      "metadata": {
        "id": "vuEJY-U3dZ2-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Define ROI covering the upper part of the escalator.**"
      ],
      "metadata": {
        "id": "ahWdzbmsdnhH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def define_roi(width, height):\n",
        "    return [\n",
        "        int(width * 0.45),  # x1: left edge\n",
        "        int(height * 0.15), # y1: top edge\n",
        "        int(width * 0.65),  # x2: right edge\n",
        "        int(height * 0.40)  # y2: bottom edge (upper part of escalator)\n",
        "    ]"
      ],
      "metadata": {
        "id": "ysfU24CDdhTF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Check if a bounding box's center is inside the ROI.**"
      ],
      "metadata": {
        "id": "6TNdB6GodwlR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def is_in_roi(box, roi):\n",
        "    x1, y1, x2, y2 = box\n",
        "    center_x = (x1 + x2) / 2\n",
        "    center_y = (y1 + y2) / 2\n",
        "    rx1, ry1, rx2, ry2 = roi\n",
        "    return rx1 <= center_x <= rx2 and ry1 <= center_y <= ry2"
      ],
      "metadata": {
        "id": "93WuU6scdtWe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Determine ROI rectangle color and message based on person count.**"
      ],
      "metadata": {
        "id": "4GcvWGiHd3P2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_roi_color_and_message(count):\n",
        "    if count == 2:\n",
        "        return (0, 255, 0), \"Normal\"  # Green for 2 people\n",
        "    elif count == 3:\n",
        "        return (0, 255, 255), \"Care\"  # Yellow for 4 people\n",
        "    elif count > 3:\n",
        "        return (0, 0, 255), \"Warning\"  # Red for >4 people\n",
        "    return (255, 255, 255), \"\"  # Default white, no message for other counts"
      ],
      "metadata": {
        "id": "vL0cJlNHd0W_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Process video with tracking, apply colored ROI rectangle with message, and save output.**"
      ],
      "metadata": {
        "id": "FGNxMquEd8d-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def process_video(video_path, output_path):\n",
        "    # Load model and video\n",
        "    model = load_model()\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "    if not cap.isOpened():\n",
        "        print(f\"Error: Could not open video {video_path}\")\n",
        "        return False\n",
        "\n",
        "    # Video properties\n",
        "    fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
        "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "    frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "    roi = define_roi(width, height)\n",
        "\n",
        "    # Initialize video writer\n",
        "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "    out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n",
        "    if not out.isOpened():\n",
        "        print(\"Error: Could not initialize video writer\")\n",
        "        cap.release()\n",
        "        return False\n",
        "\n",
        "    # Process frames with progress bar\n",
        "    print(f\"Processing video with {frame_count} frames...\")\n",
        "    start_time = time.time()\n",
        "    progress_bar = tqdm(total=frame_count, desc=\"Processing Frames\")\n",
        "\n",
        "    while cap.isOpened():\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "\n",
        "        # YOLOv8 prediction with tracking (only detect people, class 0)\n",
        "        results = model.track(frame, stream=True, classes=[0], device='cuda', conf=0.5, iou=0.7, persist=True)\n",
        "\n",
        "        person_count_in_roi = 0\n",
        "        annotated_frame = frame.copy()\n",
        "\n",
        "        for result in results:\n",
        "            boxes = result.boxes.xyxy.cpu().numpy()\n",
        "            track_ids = result.boxes.id.cpu().numpy() if result.boxes.id is not None else []\n",
        "\n",
        "            # Count unique people in ROI using track IDs\n",
        "            unique_ids = set()\n",
        "            for i, box in enumerate(boxes):\n",
        "                if is_in_roi(box, roi) and i < len(track_ids):\n",
        "                    unique_ids.add(track_ids[i])\n",
        "            person_count_in_roi = len(unique_ids)\n",
        "\n",
        "            # Draw green bounding boxes for people in ROI\n",
        "            for box in boxes:\n",
        "                if is_in_roi(box, roi):\n",
        "                    x1, y1, x2, y2 = map(int, box)\n",
        "                    cv2.rectangle(annotated_frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
        "\n",
        "        # Get ROI color and message based on count\n",
        "        roi_color, message = get_roi_color_and_message(person_count_in_roi)\n",
        "\n",
        "        # Draw ROI rectangle with conditional color\n",
        "        cv2.rectangle(annotated_frame, (roi[0], roi[1]), (roi[2], roi[3]), roi_color, 2)\n",
        "\n",
        "        # Add message on ROI rectangle (centered)\n",
        "        if message:\n",
        "            text_size = cv2.getTextSize(message, cv2.FONT_HERSHEY_SIMPLEX, 0.7, 2)[0]\n",
        "            text_x = roi[0] + (roi[2] - roi[0] - text_size[0]) // 2\n",
        "            text_y = roi[1] + (roi[3] - roi[1] + text_size[1]) // 2\n",
        "            cv2.putText(annotated_frame, message, (text_x, text_y), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)\n",
        "\n",
        "        # Add crowd density text at top-left\n",
        "        text = f\"Crowd Density: {person_count_in_roi}\"\n",
        "        cv2.putText(annotated_frame, text, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)\n",
        "\n",
        "        # Write frame to output\n",
        "        out.write(annotated_frame)\n",
        "        progress_bar.update(1)\n",
        "\n",
        "    # Clean up\n",
        "    progress_bar.close()\n",
        "    cap.release()\n",
        "    out.release()\n",
        "    elapsed_time = time.time() - start_time\n",
        "    print(f\"Processing complete! Total time: {elapsed_time:.2f} seconds\")\n",
        "    return True"
      ],
      "metadata": {
        "id": "k1NyOP9nBe7l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Main function to handle video upload, processing, and auto-download.**"
      ],
      "metadata": {
        "id": "93YbXc8xeJ0_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "    # Upload video\n",
        "    print(\"Please upload your video file (e.g., input_video.mp4)\")\n",
        "    uploaded = files.upload()\n",
        "    if not uploaded:\n",
        "        print(\"Error: No video uploaded.\")\n",
        "        return\n",
        "\n",
        "    video_path = list(uploaded.keys())[0]\n",
        "    output_path = \"output_density_mall.mp4\"\n",
        "\n",
        "    # Process video\n",
        "    if process_video(video_path, output_path):\n",
        "        # Auto-download output video\n",
        "        if os.path.exists(output_path):\n",
        "            print(\"Initiating automatic download of processed video...\")\n",
        "            files.download(output_path)\n",
        "        else:\n",
        "            print(\"Error: Output video was not created.\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "CYg7CnEMeGs3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}