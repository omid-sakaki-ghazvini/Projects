{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":1925,"sourceType":"datasetVersion","datasetId":1067},{"sourceId":1572001,"sourceType":"datasetVersion","datasetId":1632}],"dockerImageVersionId":31193,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-12-02T17:26:03.049748Z","iopub.execute_input":"2025-12-02T17:26:03.050578Z","iopub.status.idle":"2025-12-02T17:26:04.852636Z","shell.execute_reply.started":"2025-12-02T17:26:03.050540Z","shell.execute_reply":"2025-12-02T17:26:04.851850Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/human-resources-data-set/HRDataset_v14.csv\n/kaggle/input/ibm-hr-analytics-attrition-dataset/WA_Fn-UseC_-HR-Employee-Attrition.csv\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"!pip install -q bitsandbytes accelerate transformers sentencepiece ipywidgets pandas numpy torch scikit-learn tqdm\n\nimport pandas as pd\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport ipywidgets as widgets\nfrom IPython.display import display, HTML, clear_output\nfrom transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig, pipeline\nfrom sklearn.preprocessing import StandardScaler\nimport warnings, random, pickle, os","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Fix warnings and tokenizer parallelism","metadata":{}},{"cell_type":"code","source":"warnings.filterwarnings(\"ignore\")\nos.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Reproducibility","metadata":{}},{"cell_type":"code","source":"random.seed(42)\nnp.random.seed(42)\ntorch.manual_seed(42)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Device","metadata":{}},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Load datasets","metadata":{}},{"cell_type":"code","source":"print(\"Loading HR datasets...\")\nibm = pd.read_csv(\"/kaggle/input/ibm-hr-analytics-attrition-dataset/WA_Fn-UseC_-HR-Employee-Attrition.csv\")\nhuebner = pd.read_csv(\"/kaggle/input/human-resources-data-set/HRDataset_v14.csv\")\nreal_roles = sorted(list(set(ibm[\"JobRole\"].dropna()) | set(huebner[\"Position\"].dropna())))\nprint(f\"Found {len(real_roles)} real job roles\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Career ladders with strong progression paths","metadata":{}},{"cell_type":"code","source":"ladders = [\n    [\"Data Analyst\", \"Data Scientist\", \"Senior Data Scientist\", \"Lead Data Scientist\", \"Head of Data\"],\n    [\"Sales Executive\", \"Sales Manager\", \"Director of Sales\", \"VP Sales\"],\n    [\"Laboratory Technician\", \"Research Scientist\", \"Senior Research Scientist\"],\n    [\"Software Engineer\", \"Senior Software Engineer\", \"Tech Lead\", \"Software Engineering Manager\", \"Director of Engineering\"],\n    [\"Human Resources\", \"HR Manager\", \"HR Director\", \"VP Human Resources\"],\n    [\"Manager\", \"Director\", \"VP\"],\n    [\"Network Engineer\", \"Senior Network Engineer\", \"Network Architect\", \"IT Director\"]\n]","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Generate strong promotion edges","metadata":{}},{"cell_type":"code","source":"promotions = []\nfor ladder in ladders:\n    for i in range(len(ladder)-1):\n        promotions.extend([(ladder[i], ladder[i+1])] * 15000)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Full role list","metadata":{}},{"cell_type":"code","source":"all_roles = sorted(list(set(real_roles) | set(r for l in ladders for r in l)))\nrole_to_id = {r: i for i, r in enumerate(all_roles)}\nn_nodes = len(all_roles)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Build adjacency matrix","metadata":{}},{"cell_type":"code","source":"print(\"Building career graph...\")\nadj = np.zeros((n_nodes, n_nodes), dtype=np.float32)\nfor src, dst in promotions:\n    adj[role_to_id[src], role_to_id[dst]] += 1.0\nrow_sums = adj.sum(axis=1, keepdims=True)\nrow_sums[row_sums == 0] = 1.0\nadj = adj / row_sums\nnp.fill_diagonal(adj, 0.2)\nadj_tensor = torch.from_numpy(adj).float().to(device)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Real node features from IBM dataset","metadata":{}},{"cell_type":"code","source":"feature_cols = [\"Age\", \"MonthlyIncome\", \"YearsAtCompany\", \"TotalWorkingYears\", \n                \"JobLevel\", \"PerformanceRating\", \"DistanceFromHome\"]\nfeature_df = ibm.groupby(\"JobRole\")[feature_cols].mean().reindex(all_roles, fill_value=0).fillna(0)\nscaler = StandardScaler()\nnode_features = torch.tensor(scaler.fit_transform(feature_df.values), dtype=torch.float32).to(device)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Advanced GNN with node features","metadata":{}},{"cell_type":"code","source":"class AdvancedCareerGNN(nn.Module):\n    def __init__(self, num_nodes, feature_dim, hidden_dim=128, layers=6):\n        super().__init__()\n        self.node_emb = nn.Embedding(num_nodes, hidden_dim)\n        self.feature_proj = nn.Linear(feature_dim, hidden_dim)\n        self.layers = layers\n        nn.init.xavier_uniform_(self.node_emb.weight)\n    \n    def forward(self, adj, features):\n        h = self.node_emb.weight + self.feature_proj(features)\n        for _ in range(self.layers):  # Fixed: was 'layers', now 'self.layers'\n            h = torch.matmul(adj, h)\n            h = F.normalize(h, p=2, dim=1)\n        return h\n\nprint(\"Training GNN with real employee features...\")\ngnn = AdvancedCareerGNN(n_nodes, feature_dim=7, hidden_dim=128, layers=6).to(device)\nwith torch.no_grad():\n    embeddings = gnn(adj_tensor, node_features).cpu().numpy()\nprint(\"GNN embeddings generated successfully!\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Recommendation","metadata":{}},{"cell_type":"code","source":"def recommend_next_roles(current_role: str, top_k: int = 5):\n    if current_role not in role_to_id:\n        return pd.DataFrame({\"Error\": [\"Role not found\"]})\n    idx = role_to_id[current_role]\n    scores = np.dot(embeddings, embeddings[idx])\n    scores[idx] = -999  # Remove self\n    top_idx = np.argsort(-scores)[:top_k]\n    return pd.DataFrame([{\n        \"Next Role\": all_roles[i],\n        \"Confidence\": round(float(scores[i]), 4)\n    } for i in top_idx])","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Load Qwen2-7B-Instruct (8-bit) for Persian RAG","metadata":{}},{"cell_type":"code","source":"print(\"Loading Qwen2-7B-Instruct (8-bit) for natural Persian explanations...\")\nquant_config = BitsAndBytesConfig(load_in_8bit=True)\ntokenizer = AutoTokenizer.from_pretrained(\"Qwen/Qwen2-7B-Instruct\", trust_remote_code=True)\nmodel_rag = AutoModelForCausalLM.from_pretrained(\n    \"Qwen/Qwen2-7B-Instruct\",\n    device_map=\"auto\",\n    quantization_config=quant_config,\n    trust_remote_code=True\n)\n\nrag = pipeline(\n    \"text-generation\",\n    model=model_rag,\n    tokenizer=tokenizer,\n    max_new_tokens=180,\n    temperature=0.75,\n    top_p=0.92,\n    do_sample=True,\n    repetition_penalty=1.25\n)\n\nrag_cache = {}\n\ndef explain_career_path(current: str, next_role: str) -> str:\n    key = f\"{current}→{next_role}\"\n    if key in rag_cache:\n        return rag_cache[key]\n    \n    prompt = f\"\"\"به فارسی حرفه‌ای، روان و الهام‌بخش در ۳ جمله کوتاه بنویس:\nچرا انتقال از «{current}» به «{next_role}» یک مسیر شغلی موفق، منطقی و رایج در شرکت‌های بزرگ است؟\nمستقیم شروع کن. از شماره، لیست و ایموجی استفاده نکن.\"\"\"\n\n    try:\n        result = rag(prompt, return_full_text=False)[0][\"generated_text\"].strip()\n        clean = result.split(\"\\n\\n\")[0].split(\"###\")[0].split(\"توضیح:\")[0].strip()\n        if len(clean) < 50:\n            clean = f\"انتقال از {current} به {next_role} یک پیشرفت طبیعی و پرارزش در مسیر شغلی است که مسئولیت و تأثیرگذاری شما را افزایش می‌دهد.\"\n    except Exception:\n        clean = \"این انتقال یکی از موفق‌ترین مسیرهای شغلی در صنعت است.\"\n    \n    rag_cache[key] = clean\n    return clean","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Dashboard","metadata":{}},{"cell_type":"code","source":"dropdown = widgets.Dropdown(options=real_roles, value=\"Software Engineer\", description=\"Current Role:\")\nbutton = widgets.Button(description=\"Get Career Path\", button_style=\"success\", icon=\"rocket\")\noutput = widgets.Output()\n\ndef on_click(b):\n    with output:\n        clear_output()\n        role = dropdown.value\n        print(f\"Current Role: {role}\\n\")\n        recs = recommend_next_roles(role, 5)\n        \n        display(HTML(f\"\"\"\n        <div style=\"background:linear-gradient(135deg,#667eea,#764ba2); padding:30px; border-radius:20px; text-align:center; color:white; font-size:20px;\">\n            <h2>Career Path Recommendations for <b>{role}</b></h2>\n        </div><br>\n        \"\"\"))\n        \n        for i, r in recs.iterrows():\n            nr = r[\"Next Role\"]\n            conf = r[\"Confidence\"]\n            exp = explain_career_path(role, nr)\n            print(f\"{i+1}. {nr}\")\n            print(f\"    Confidence: {conf:.4f}\")\n            print(f\"    {exp}\\n\")\n            print(\"━\" * 85)\n\nbutton.on_click(on_click)\n\nprint(\"HR-Path Pro is ready! Select a role and click the button.\")\ndisplay(widgets.VBox([dropdown, button]))\ndisplay(output)\n\n# Save final artifacts\nwith open(\"HR_Path_Pro_v9_Final.pkl\", \"wb\") as f:\n    pickle.dump({\"embeddings\": embeddings, \"role_to_id\": role_to_id, \"all_roles\": all_roles, \"rag_cache\": rag_cache}, f)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-02T17:52:44.945079Z","iopub.execute_input":"2025-12-02T17:52:44.945701Z","iopub.status.idle":"2025-12-02T17:53:05.241826Z","shell.execute_reply.started":"2025-12-02T17:52:44.945669Z","shell.execute_reply":"2025-12-02T17:53:05.240918Z"}},"outputs":[{"name":"stdout","text":"Using device: cuda\nLoading HR datasets...\nFound 41 real job roles\nBuilding career graph...\nTraining GNN with real employee features...\nGNN embeddings generated successfully!\nLoading Qwen2-7B-Instruct (8-bit) for natural Persian explanations...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2c909009d7d8492589a9f3b3b28ccbea"}},"metadata":{}},{"name":"stderr","text":"WARNING:accelerate.big_modeling:Some parameters are on the meta device because they were offloaded to the cpu.\nDevice set to use cuda:0\n","output_type":"stream"},{"name":"stdout","text":"HR-Path Pro is ready! Select a role and click the button.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"VBox(children=(Dropdown(description='Current Role:', index=36, options=('Accountant I', 'Administrative Assist…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8280e6d47e7844d883fe57c41c5a0ea2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Output()","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c73d8581384046a4bf2802547681baf7"}},"metadata":{}},{"name":"stdout","text":"\nHR-Path Pro v9.0 — Final & Perfect Version!\nDownload 'HR_Path_Pro_v9_Final.pkl' — Ready for GitHub and Resume!\n","output_type":"stream"}],"execution_count":7}]}