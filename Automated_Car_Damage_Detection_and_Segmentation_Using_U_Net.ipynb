{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **1-Install required packages**"
      ],
      "metadata": {
        "id": "EJuhDzGIcWRQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch torchvision torchsummary opencv-python matplotlib numpy scikit-learn albumentations kaggle -q\n",
        "\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import albumentations as A\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.amp import GradScaler, autocast\n",
        "from torchsummary import summary\n",
        "import time"
      ],
      "metadata": {
        "id": "deHqmevyccyu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **2-Set up Kaggle API for dataset download**"
      ],
      "metadata": {
        "id": "9A4jSPvrcfXW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "print(\"Upload kaggle.json for API access\")\n",
        "files.upload()  # Upload kaggle.json\n",
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "cTdqynTRciAm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **3-Download Car Damage Detection YOLO Seg 8k dataset**"
      ],
      "metadata": {
        "id": "3UTuac0qcmQv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Downloading Car Damage Detection YOLO Seg 8k dataset...\")\n",
        "!kaggle datasets download -d chiayinlee/car-damage-detection-yolo-seg-8k -p ./car_data\n",
        "!unzip -q ./car_data/car-damage-detection-yolo-seg-8k.zip -d ./car_data\n",
        "!rm ./car_data/car-damage-detection-yolo-seg-8k.zip"
      ],
      "metadata": {
        "id": "duCuu60EcpuF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **4-Inspect dataset structure**"
      ],
      "metadata": {
        "id": "iXRCR23Dcune"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Dataset structure:\")\n",
        "!ls -R ./car_data\n",
        "\n",
        "# Define dataset paths\n",
        "TRAIN_IMAGE_ROOT = './car_data/train/images'\n",
        "TRAIN_LABEL_ROOT = './car_data/train/labels'\n",
        "VAL_IMAGE_ROOT = './car_data/valid/images'\n",
        "VAL_LABEL_ROOT = './car_data/valid/labels'"
      ],
      "metadata": {
        "id": "Zn2bgODzcxol"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **5-Collect image paths**"
      ],
      "metadata": {
        "id": "0Z-6vpSAc-du"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_image_paths(root_dir):\n",
        "    image_paths = []\n",
        "    for subdir, _, files in os.walk(root_dir):\n",
        "        for file in files:\n",
        "            if file.endswith(('.jpg', '.png')):\n",
        "                image_paths.append(os.path.join(subdir, file))\n",
        "    return sorted(image_paths)\n",
        "\n",
        "train_image_paths = get_image_paths(TRAIN_IMAGE_ROOT)\n",
        "val_image_paths = get_image_paths(VAL_IMAGE_ROOT)\n",
        "print(f\"Found {len(train_image_paths)} training images and {len(val_image_paths)} validation images\")"
      ],
      "metadata": {
        "id": "bx0a1Qa3c90_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **6-Convert YOLO format to binary mask**"
      ],
      "metadata": {
        "id": "3QWp_ycSdK_F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def yolo_to_mask(label_path, img_shape):\n",
        "    \"\"\"Convert YOLO segmentation annotations to binary mask\"\"\"\n",
        "    mask = np.zeros(img_shape[:2], dtype=np.uint8)\n",
        "    if not os.path.exists(label_path):\n",
        "        return mask\n",
        "    with open(label_path, 'r') as f:\n",
        "        lines = f.readlines()\n",
        "    for line in lines:\n",
        "        parts = line.strip().split()\n",
        "        # Ignore class_id (combine all classes into one binary mask)\n",
        "        points = np.array([float(x) for x in parts[1:]]).reshape(-1, 2)  # Normalized coordinates\n",
        "        points = points * np.array([img_shape[1], img_shape[0]])  # Denormalize to image size\n",
        "        points = points.astype(np.int32)\n",
        "        cv2.fillPoly(mask, [points], 1)  # Fill polygon with 1\n",
        "    return mask"
      ],
      "metadata": {
        "id": "99hR0mQydP-N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **7-Match image and label files (handle rf.<hash> naming)**"
      ],
      "metadata": {
        "id": "Y1NzeRyydTBG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_label_path(img_path, label_root):\n",
        "    \"\"\"Find corresponding label file, handling rf.<hash> naming\"\"\"\n",
        "    img_id = os.path.basename(img_path).split('.rf.')[0]  # Extract base name (e.g., Img64_jpg)\n",
        "    for label_file in os.listdir(label_root):\n",
        "        if label_file.startswith(img_id) and label_file.endswith('.txt'):\n",
        "            return os.path.join(label_root, label_file)\n",
        "    return None  # Return None if no matching label found"
      ],
      "metadata": {
        "id": "YMfAjz9EdYim"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **8-Visualize sample images and masks**"
      ],
      "metadata": {
        "id": "wsLNlqhtdZbG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_sample(image_path, mask):\n",
        "    \"\"\"Display image with its segmentation mask\"\"\"\n",
        "    img = cv2.imread(image_path, cv2.IMREAD_COLOR)\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "    fig, ax = plt.subplots(1, 2, figsize=(10, 5))\n",
        "    ax[0].imshow(img)\n",
        "    ax[0].set_title('Original Image')\n",
        "    ax[0].axis('off')\n",
        "    ax[1].imshow(mask, cmap='gray')\n",
        "    ax[1].set_title('Damage Mask')\n",
        "    ax[1].axis('off')\n",
        "    plt.show()\n",
        "\n",
        "# Show first 3 samples\n",
        "for img_path in train_image_paths[:3]:\n",
        "    label_path = get_label_path(img_path, TRAIN_LABEL_ROOT)\n",
        "    if label_path:\n",
        "        img = cv2.imread(img_path)\n",
        "        mask = yolo_to_mask(label_path, img.shape)\n",
        "        plot_sample(img_path, mask)\n",
        "    else:\n",
        "        print(f\"No label found for {img_path}\")"
      ],
      "metadata": {
        "id": "wm-mVhO6df6u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **9-Custom Dataset for Car Damage Detection**"
      ],
      "metadata": {
        "id": "vzHAJYU3di1F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CarDamageDataset(Dataset):\n",
        "    def __init__(self, image_paths, label_root, transform=None, augment=False):\n",
        "        self.image_paths = image_paths\n",
        "        self.label_root = label_root\n",
        "        self.transform = transform\n",
        "        self.augment = augment\n",
        "        self.aug_transform = A.Compose([\n",
        "            A.HorizontalFlip(p=0.5),\n",
        "            A.RandomRotate90(p=0.3),\n",
        "            A.RandomBrightnessContrast(p=0.2),\n",
        "            A.GaussNoise(p=0.1),\n",
        "            A.CoarseDropout(max_holes=8, max_height=16, max_width=16, p=0.3)\n",
        "        ])\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = self.image_paths[idx]\n",
        "        label_path = get_label_path(img_path, self.label_root)\n",
        "\n",
        "        # Load image\n",
        "        image = cv2.imread(img_path, cv2.IMREAD_COLOR)\n",
        "        if image is None:\n",
        "            raise FileNotFoundError(f\"Image not found: {img_path}\")\n",
        "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "        # Load or create empty mask\n",
        "        mask = yolo_to_mask(label_path, image.shape) if label_path else np.zeros(image.shape[:2], dtype=np.uint8)\n",
        "        mask = mask.astype(np.float32)\n",
        "\n",
        "        # Apply augmentations\n",
        "        if self.augment:\n",
        "            augmented = self.aug_transform(image=image, mask=mask)\n",
        "            image, mask = augmented['image'], augmented['mask']\n",
        "\n",
        "        # Apply transforms\n",
        "        if self.transform:\n",
        "            transformed = self.transform(image=image, mask=mask)\n",
        "            image, mask = transformed['image'], transformed['mask']\n",
        "\n",
        "        return image, mask"
      ],
      "metadata": {
        "id": "Y8uniRkvdqw-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **10-Define transforms**"
      ],
      "metadata": {
        "id": "gAyZat1odwn-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "base_transform = A.Compose([\n",
        "    A.Resize(256, 256),  # Resize to fit Colab GPU memory\n",
        "    A.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5)),\n",
        "    ToTensorV2()\n",
        "])"
      ],
      "metadata": {
        "id": "sTTyFIkyd1iv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **11-Prepare dataset**"
      ],
      "metadata": {
        "id": "wm3E-Ev2d36W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = CarDamageDataset(train_image_paths, TRAIN_LABEL_ROOT, transform=base_transform, augment=True)\n",
        "val_dataset = CarDamageDataset(val_image_paths, VAL_LABEL_ROOT, transform=base_transform, augment=False)"
      ],
      "metadata": {
        "id": "GRmFpCmld7ln"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **12-Create dataloaders**"
      ],
      "metadata": {
        "id": "gRjNmVZzd9wG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 4  # Optimized for Colab free tier\n",
        "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, pin_memory=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, pin_memory=True)\n",
        "\n",
        "def show_batch(dataloader):\n",
        "    images, masks = next(iter(dataloader))\n",
        "    plt.figure(figsize=(15, 5))\n",
        "    for i in range(min(4, BATCH_SIZE)):\n",
        "        plt.subplot(2, 4, i+1)\n",
        "        plt.imshow(images[i].permute(1, 2, 0).numpy() * 0.5 + 0.5)  # Unnormalize\n",
        "        plt.title('Image')\n",
        "        plt.axis('off')\n",
        "        plt.subplot(2, 4, i+5)\n",
        "        plt.imshow(masks[i].squeeze().numpy(), cmap='gray')\n",
        "        plt.title('Mask')\n",
        "        plt.axis('off')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "print(\"Training batch samples:\")\n",
        "show_batch(train_loader)"
      ],
      "metadata": {
        "id": "rU3t1zVDeCCe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **13-U-Net Model Definition**"
      ],
      "metadata": {
        "id": "MBAcPG7veKze"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DoubleConv(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, mid_channels=None):\n",
        "        super().__init__()\n",
        "        if not mid_channels:\n",
        "            mid_channels = out_channels\n",
        "        self.double_conv = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, mid_channels, kernel_size=3, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(mid_channels),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(mid_channels, out_channels, kernel_size=3, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "    def forward(self, x):\n",
        "        return self.double_conv(x)\n",
        "\n",
        "class Down(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super().__init__()\n",
        "        self.maxpool_conv = nn.Sequential(\n",
        "            nn.MaxPool2d(2),\n",
        "            DoubleConv(in_channels, out_channels)\n",
        "        )\n",
        "    def forward(self, x):\n",
        "        return self.maxpool_conv(x)\n",
        "\n",
        "class Up(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, bilinear=True):\n",
        "        super().__init__()\n",
        "        if bilinear:\n",
        "            self.up = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
        "            self.conv = DoubleConv(in_channels, out_channels, in_channels // 2)\n",
        "        else:\n",
        "            self.up = nn.ConvTranspose2d(in_channels, in_channels // 2, kernel_size=2, stride=2)\n",
        "            self.conv = DoubleConv(in_channels, out_channels)\n",
        "    def forward(self, x1, x2):\n",
        "        x1 = self.up(x1)\n",
        "        diffY = x2.size()[2] - x1.size()[2]\n",
        "        diffX = x2.size()[3] - x1.size()[3]\n",
        "        x1 = F.pad(x1, [diffX // 2, diffX - diffX // 2, diffY // 2, diffY - diffY // 2])\n",
        "        x = torch.cat([x2, x1], dim=1)\n",
        "        return self.conv(x)\n",
        "\n",
        "class OutConv(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super().__init__()\n",
        "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=1)\n",
        "    def forward(self, x):\n",
        "        return self.conv(x)\n",
        "\n",
        "class UNet(nn.Module):\n",
        "    def __init__(self, n_channels=3, n_classes=1, bilinear=True):\n",
        "        super(UNet, self).__init__()\n",
        "        self.n_channels = n_channels\n",
        "        self.n_classes = n_classes\n",
        "        self.bilinear = bilinear\n",
        "        self.inc = DoubleConv(n_channels, 64)\n",
        "        self.down1 = Down(64, 128)\n",
        "        self.down2 = Down(128, 256)\n",
        "        self.down3 = Down(256, 512)\n",
        "        factor = 2 if bilinear else 1\n",
        "        self.down4 = Down(512, 1024 // factor)\n",
        "        self.up1 = Up(1024, 512 // factor, bilinear)\n",
        "        self.up2 = Up(512, 256 // factor, bilinear)\n",
        "        self.up3 = Up(256, 128 // factor, bilinear)\n",
        "        self.up4 = Up(128, 64, bilinear)\n",
        "        self.outc = OutConv(64, n_classes)\n",
        "    def forward(self, x):\n",
        "        x1 = self.inc(x)\n",
        "        x2 = self.down1(x1)\n",
        "        x3 = self.down2(x2)\n",
        "        x4 = self.down3(x3)\n",
        "        x5 = self.down4(x4)\n",
        "        x = self.up1(x5, x4)\n",
        "        x = self.up2(x, x3)\n",
        "        x = self.up3(x, x2)\n",
        "        x = self.up4(x, x1)\n",
        "        logits = self.outc(x)\n",
        "        return logits\n",
        "\n",
        "# Initialize model\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = UNet().to(device)\n",
        "print(f\"Model initialized on {device}\")\n",
        "print(f\"Total parameters: {sum(p.numel() for p in model.parameters())/1e6:.2f}M\")\n",
        "summary(model, input_size=(3, 256, 256))"
      ],
      "metadata": {
        "id": "cglOLY4XeTX2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **14-Loss function combining Dice and BCEWithLogits**"
      ],
      "metadata": {
        "id": "jB6VpkaaeV5P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DiceBCELoss(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "    def forward(self, inputs, targets, smooth=1):\n",
        "        bce = F.binary_cross_entropy_with_logits(inputs, targets, reduction='mean')\n",
        "        inputs = torch.sigmoid(inputs)\n",
        "        inputs = inputs.view(-1)\n",
        "        targets = targets.view(-1)\n",
        "        intersection = (inputs * targets).sum()\n",
        "        dice_loss = 1 - (2.*intersection + smooth)/(inputs.sum() + targets.sum() + smooth)\n",
        "        return bce + dice_loss\n",
        "\n",
        "\n",
        "# Training components\n",
        "criterion = DiceBCELoss()\n",
        "optimizer = optim.AdamW(model.parameters(), lr=1e-4, weight_decay=1e-5)\n",
        "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=2, factor=0.5)\n",
        "scaler = GradScaler()"
      ],
      "metadata": {
        "id": "rI4oaIsFeaKn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **15-Training and validation functions**"
      ],
      "metadata": {
        "id": "tJyUcnpOeh4W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_epoch(model, loader, optimizer, criterion, scaler):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    for images, masks in tqdm(loader, desc=\"Training\"):\n",
        "        images, masks = images.to(device), masks.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        with autocast('cuda'):\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, masks.unsqueeze(1))\n",
        "        scaler.scale(loss).backward()\n",
        "        scaler.step(optimizer)\n",
        "        scaler.update()\n",
        "        running_loss += loss.item()\n",
        "    return running_loss / len(loader)\n",
        "\n",
        "def validate(model, loader, criterion):\n",
        "    model.eval()\n",
        "    running_loss = 0.0\n",
        "    iou_score = 0.0\n",
        "    with torch.no_grad():\n",
        "        for images, masks in tqdm(loader, desc=\"Validating\"):\n",
        "            images, masks = images.to(device), masks.to(device)\n",
        "            with autocast('cuda'):\n",
        "                outputs = model(images)\n",
        "                loss = criterion(outputs, masks.unsqueeze(1))\n",
        "            running_loss += loss.item()\n",
        "            preds = torch.sigmoid(outputs) > 0.5\n",
        "            targets = masks.unsqueeze(1).bool()\n",
        "            intersection = (preds & targets).float().sum()\n",
        "            union = (preds | targets).float().sum()\n",
        "            iou_score += (intersection + 1e-6) / (union + 1e-6)\n",
        "    return running_loss / len(loader), iou_score / len(loader)"
      ],
      "metadata": {
        "id": "Yxz6j5-mej9I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **16-Training loop**"
      ],
      "metadata": {
        "id": "EJlem3Amepr4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(model, train_loader, val_loader, criterion, optimizer, scheduler, scaler, epochs=10):\n",
        "    best_iou = 0.0\n",
        "    history = {'train_loss': [], 'val_loss': [], 'val_iou': []}\n",
        "    for epoch in range(epochs):\n",
        "        print(f\"\\nEpoch {epoch+1}/{epochs}\")\n",
        "        start_time = time.time()\n",
        "        train_loss = train_epoch(model, train_loader, optimizer, criterion, scaler)\n",
        "        val_loss, val_iou = validate(model, val_loader, criterion)\n",
        "        scheduler.step(val_loss)\n",
        "        history['train_loss'].append(float(train_loss))\n",
        "        history['val_loss'].append(float(val_loss))\n",
        "        history['val_iou'].append(float(val_iou.cpu()))\n",
        "        if val_iou > best_iou:\n",
        "            best_iou = val_iou\n",
        "            torch.save(model.state_dict(), 'best_model.pth')\n",
        "            print(f\"New best model saved with IoU: {float(val_iou):.4f}\")\n",
        "        print(f\"Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f} | Val IoU: {float(val_iou):.4f}\")\n",
        "        print(f\"Time: {time.time()-start_time:.2f}s\")\n",
        "    return history\n",
        "\n",
        "# Start training\n",
        "history = train_model(model, train_loader, val_loader, criterion, optimizer, scheduler, scaler, epochs=10)"
      ],
      "metadata": {
        "id": "GvuaGjioevfl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **17-Plot training history**"
      ],
      "metadata": {
        "id": "sdM53eP0ezSe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(12, 5))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history['train_loss'], label='Train Loss')\n",
        "plt.plot(history['val_loss'], label='Val Loss')\n",
        "plt.title('Training History')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history['val_iou'], label='Validation IoU')\n",
        "plt.title('IoU Score Progress')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('IoU')\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "tkxK_Rrre1GH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **18-Visualize predictions**"
      ],
      "metadata": {
        "id": "MvIfOU1ne71m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def visualize_predictions(dataset, model, num_samples=3):\n",
        "    plt.figure(figsize=(15, 5*num_samples))\n",
        "    indices = np.random.choice(len(dataset), num_samples, replace=False)\n",
        "    for i, idx in enumerate(indices):\n",
        "        image, mask = dataset[idx]\n",
        "        image = image.unsqueeze(0).to(device)\n",
        "        with torch.no_grad():\n",
        "            pred = torch.sigmoid(model(image)) > 0.5\n",
        "        plt.subplot(num_samples, 3, i*3+1)\n",
        "        plt.imshow(image[0].cpu().permute(1, 2, 0).numpy() * 0.5 + 0.5)\n",
        "        plt.title('Input Image')\n",
        "        plt.axis('off')\n",
        "        plt.subplot(num_samples, 3, i*3+2)\n",
        "        plt.imshow(mask.squeeze().cpu().numpy(), cmap='gray')\n",
        "        plt.title('Ground Truth')\n",
        "        plt.axis('off')\n",
        "        plt.subplot(num_samples, 3, i*3+3)\n",
        "        plt.imshow(pred.squeeze().cpu().numpy(), cmap='gray')\n",
        "        plt.title('Prediction')\n",
        "        plt.axis('off')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "print(\"Validation samples predictions:\")\n",
        "visualize_predictions(val_dataset, model, num_samples=3)"
      ],
      "metadata": {
        "id": "cjemHBWme_0F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **19-Export model**"
      ],
      "metadata": {
        "id": "QlHBUbvGfCEm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "scripted_model = torch.jit.script(model)\n",
        "scripted_model.save('car_defect_detection.pt')\n",
        "print(\"Model exported successfully!\")"
      ],
      "metadata": {
        "id": "h1LBLsgRfFvm"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}