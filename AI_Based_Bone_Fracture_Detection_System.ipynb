{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "import logging\n",
        "import glob\n",
        "import pathlib\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.animation as animation\n",
        "from tqdm.auto import tqdm\n",
        "from IPython.display import HTML, FileLink, display\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "print(\"Installing required packages...\")\n",
        "!pip install -q ultralytics==8.3.36 kagglehub opencv-python-headless matplotlib tqdm seaborn\n",
        "\n",
        "from ultralytics import YOLO\n",
        "import kagglehub\n",
        "\n",
        "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
        "logger = logging.getLogger('YOLOv12_BoneFracture')"
      ],
      "metadata": {
        "id": "Q4JQ9fTTC3zW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ==============================================================\n",
        "# CONFIGURATION\n",
        "# =============================================================="
      ],
      "metadata": {
        "id": "V62HK5aKDHHG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from dataclasses import dataclass\n",
        "\n",
        "@dataclass\n",
        "class Config:\n",
        "    data_dir: str = None\n",
        "    output_dir: str = \"/content/output\"\n",
        "    epochs: int = 35\n",
        "    imgsz: int = 640\n",
        "    batch: int = 16\n",
        "    patience: int = 8\n",
        "    conf: float = 0.25\n",
        "    iou: float = 0.45\n",
        "    max_frames: int = 30\n",
        "    fps: int = 2\n",
        "\n",
        "    def __post_init__(self):\n",
        "        os.makedirs(self.output_dir, exist_ok=True)"
      ],
      "metadata": {
        "id": "zunzktoQC6QG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ==============================================================\n",
        "# DATASET DOWNLOAD AND SETUP\n",
        "# =============================================================="
      ],
      "metadata": {
        "id": "_bk-Q1qGDKqf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def setup_dataset():\n",
        "    \"\"\"Download and setup the bone fracture dataset\"\"\"\n",
        "    DATASET_SLUG = \"jockeroika/human-bone-fractures-image-dataset\"\n",
        "    print(f\"Downloading dataset: {DATASET_SLUG}...\")\n",
        "\n",
        "    dataset_path = kagglehub.dataset_download(DATASET_SLUG)\n",
        "    print(f\"Dataset downloaded to: {dataset_path}\")\n",
        "\n",
        "    # Auto-detect data directory\n",
        "    potential_roots = [\n",
        "        os.path.join(dataset_path, \"Human Bone Fractures Multi-modal Image Dataset (HBFMID)\", \"Bone Fractures Detection\"),\n",
        "        os.path.join(dataset_path, \"Bone Fractures Detection\"),\n",
        "        dataset_path\n",
        "    ]\n",
        "\n",
        "    DATA_DIR = None\n",
        "    for p in potential_roots:\n",
        "        if os.path.exists(p) and len(glob.glob(os.path.join(p, \"train\", \"images\", \"*.*\"))) > 0:\n",
        "            DATA_DIR = p\n",
        "            break\n",
        "\n",
        "    if DATA_DIR is None:\n",
        "        raise FileNotFoundError(f\"Could not locate train/images in {dataset_path}\")\n",
        "\n",
        "    print(f\"Data directory: {DATA_DIR}\")\n",
        "    return DATA_DIR\n",
        "\n",
        "DATA_DIR = setup_dataset()\n",
        "config = Config(data_dir=DATA_DIR)"
      ],
      "metadata": {
        "id": "uYGNZKfRC80m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ==============================================================\n",
        "# CREATE DATA CONFIGURATION\n",
        "# =============================================================="
      ],
      "metadata": {
        "id": "wkosH4LqDN5O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_data_yaml():\n",
        "    \"\"\"Create data.yaml configuration file\"\"\"\n",
        "    train_img_dir = glob.glob(os.path.join(config.data_dir, \"**\", \"train\", \"images\"), recursive=True)[0]\n",
        "    val_img_dir = glob.glob(os.path.join(config.data_dir, \"**\", \"valid\", \"images\"), recursive=True)[0]\n",
        "\n",
        "    print(f\"Train images: {train_img_dir}\")\n",
        "    print(f\"Val images: {val_img_dir}\")\n",
        "\n",
        "    # Define class names from the dataset\n",
        "    class_names = [\n",
        "        'elbow_positive', 'finger_positive', 'forearm_positive', 'humerus_positive',\n",
        "        'shoulder_positive', 'wrist_positive', 'elbow_negative', 'finger_negative',\n",
        "        'forearm_negative', 'humerus_negative', 'shoulder_negative', 'wrist_negative'\n",
        "    ]\n",
        "\n",
        "    # Build data configuration\n",
        "    root_for_yaml = os.path.dirname(config.data_dir)\n",
        "    data_yaml = {\n",
        "        'path': root_for_yaml,\n",
        "        'train': os.path.relpath(train_img_dir, root_for_yaml).replace(os.sep, '/'),\n",
        "        'val': os.path.relpath(val_img_dir, root_for_yaml).replace(os.sep, '/'),\n",
        "        'nc': len(class_names),\n",
        "        'names': class_names\n",
        "    }\n",
        "\n",
        "    yaml_path = os.path.join(config.output_dir, \"data.yaml\")\n",
        "    with open(yaml_path, \"w\") as f:\n",
        "        import yaml\n",
        "        yaml.dump(data_yaml, f, default_flow_style=False)\n",
        "\n",
        "    logger.info(f\"data.yaml created: {len(class_names)} classes\")\n",
        "    return yaml_path, class_names\n",
        "\n",
        "yaml_path, class_names = create_data_yaml()"
      ],
      "metadata": {
        "id": "Tz8D4zbRC_P9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ==============================================================\n",
        "# MODEL TRAINING\n",
        "# =============================================================="
      ],
      "metadata": {
        "id": "OFnVFEiQDQ82"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model():\n",
        "    \"\"\"Train the YOLO model on bone fracture dataset\"\"\"\n",
        "    print(\"Starting model training...\")\n",
        "\n",
        "    # Use YOLOv8 as a reliable base model\n",
        "    model = YOLO(\"yolov8m.pt\")\n",
        "\n",
        "    results = model.train(\n",
        "        data=yaml_path,\n",
        "        epochs=config.epochs,\n",
        "        imgsz=config.imgsz,\n",
        "        batch=config.batch,\n",
        "        patience=config.patience,\n",
        "        lr0=0.01,\n",
        "        optimizer='AdamW',\n",
        "        weight_decay=0.0005,\n",
        "        momentum=0.937,\n",
        "        conf=config.conf,\n",
        "        iou=config.iou,\n",
        "        project=config.output_dir,\n",
        "        name=\"yolo_bone_fracture\",\n",
        "        exist_ok=True,\n",
        "        plots=True,\n",
        "        save=True,\n",
        "        device=0,\n",
        "        workers=2,\n",
        "        cache=False\n",
        "    )\n",
        "\n",
        "    # Get best model path\n",
        "    best_model_path = str(pathlib.Path(results.save_dir) / \"weights\" / \"best.pt\")\n",
        "    logger.info(f\"Training complete. Best model: {best_model_path}\")\n",
        "    return best_model_path\n",
        "\n",
        "best_model_path = train_model()"
      ],
      "metadata": {
        "id": "UMF7YbXaDBuu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ==============================================================\n",
        "# INFERENCE AND VIDEO GENERATION\n",
        "# =============================================================="
      ],
      "metadata": {
        "id": "46xOkR_cDUf1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_detection_video():\n",
        "    \"\"\"Create detection video with automatic download\"\"\"\n",
        "\n",
        "    print(\"ðŸŽ¥ Starting video generation...\")\n",
        "\n",
        "    # Load the trained model\n",
        "    model = YOLO(best_model_path)\n",
        "    val_img_dir = glob.glob(os.path.join(config.data_dir, \"**\", \"valid\", \"images\"), recursive=True)[0]\n",
        "    val_images = sorted(glob.glob(os.path.join(val_img_dir, \"*.*\")))[:config.max_frames]\n",
        "\n",
        "    print(f\"Processing {len(val_images)} images for video...\")\n",
        "\n",
        "    def draw_detections(img_path, model, img_size=(640, 640)):\n",
        "        \"\"\"Draw detections on a single image\"\"\"\n",
        "        try:\n",
        "            # Read and resize image\n",
        "            img = cv2.imread(img_path)\n",
        "            if img is None:\n",
        "                img = np.random.randint(100, 200, (*img_size, 3), dtype=np.uint8)\n",
        "            else:\n",
        "                img = cv2.resize(img, img_size)\n",
        "                img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "        except:\n",
        "            img = np.random.randint(100, 200, (*img_size, 3), dtype=np.uint8)\n",
        "\n",
        "        # Run inference\n",
        "        results = model.predict(\n",
        "            source=img_path,\n",
        "            conf=0.15,  # Lower confidence for better detection\n",
        "            iou=0.4,\n",
        "            verbose=False\n",
        "        )\n",
        "\n",
        "        # Draw detections\n",
        "        for r in results:\n",
        "            if r.boxes is not None and len(r.boxes) > 0:\n",
        "                boxes = r.boxes.data.cpu().numpy()\n",
        "                for box in boxes:\n",
        "                    x1, y1, x2, y2, conf, cls_id = box\n",
        "                    x1, y1, x2, y2 = map(int, [x1, y1, x2, y2])\n",
        "\n",
        "                    if x2 > x1 and y2 > y1:  # Validate coordinates\n",
        "                        cls_id = int(cls_id)\n",
        "                        label = f\"{class_names[cls_id] if cls_id < len(class_names) else 'unknown'} {conf:.2f}\"\n",
        "\n",
        "                        # Generate color based on class\n",
        "                        color = plt.cm.Set3(cls_id % 12)[:3]\n",
        "                        color = tuple(int(c*255) for c in color)\n",
        "\n",
        "                        # Draw bounding box\n",
        "                        cv2.rectangle(img, (x1, y1), (x2, y2), color, 3)\n",
        "\n",
        "                        # Draw label\n",
        "                        (tw, th), _ = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.6, 2)\n",
        "                        cv2.rectangle(img, (x1, y1 - th - 10), (x1 + tw, y1), color, -1)\n",
        "                        cv2.putText(img, label, (x1, y1-5),\n",
        "                                   cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)\n",
        "            else:\n",
        "                # Add \"No Detection\" text if no detections found\n",
        "                cv2.putText(img, \"No Fracture Detected\", (50, 50),\n",
        "                           cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)\n",
        "\n",
        "        return img\n",
        "\n",
        "    # Generate frames\n",
        "    frames = []\n",
        "    print(\"Generating frames...\")\n",
        "\n",
        "    for i, img_path in enumerate(tqdm(val_images, desc=\"Processing images\")):\n",
        "        try:\n",
        "            frame = draw_detections(img_path, model)\n",
        "            frames.append(frame)\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing image {i}: {e}\")\n",
        "            # Create placeholder frame\n",
        "            placeholder = np.random.randint(100, 200, (640, 640, 3), dtype=np.uint8)\n",
        "            cv2.putText(placeholder, \"Processing Error\", (50, 50),\n",
        "                       cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)\n",
        "            frames.append(placeholder)\n",
        "\n",
        "    # Create video\n",
        "    if frames:\n",
        "        video_path = \"/content/bone_fracture_detection.mp4\"\n",
        "        h, w = frames[0].shape[:2]\n",
        "\n",
        "        # Use better video codec\n",
        "        fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "        writer = cv2.VideoWriter(video_path, fourcc, config.fps, (w, h))\n",
        "\n",
        "        print(\"Creating video...\")\n",
        "        for frame in tqdm(frames, desc=\"Writing video frames\"):\n",
        "            # Convert RGB to BGR for OpenCV\n",
        "            frame_bgr = cv2.cvtColor(frame, cv2.COLOR_RGB2BGR)\n",
        "            writer.write(frame_bgr)\n",
        "\n",
        "        writer.release()\n",
        "        print(f\"âœ… Video created: {video_path}\")\n",
        "\n",
        "        # Auto-download the video\n",
        "        if os.path.exists(video_path):\n",
        "            file_size = os.path.getsize(video_path) / (1024 * 1024)  # Size in MB\n",
        "            print(f\"ðŸ“¦ Video file size: {file_size:.1f} MB\")\n",
        "\n",
        "            # Create download link\n",
        "            print(\"ðŸ”½ Downloading video automatically...\")\n",
        "            display(FileLink(video_path))\n",
        "\n",
        "            # Alternative download method\n",
        "            from google.colab import files\n",
        "            files.download(video_path)\n",
        "\n",
        "            return video_path\n",
        "        else:\n",
        "            print(\"âŒ Video file was not created\")\n",
        "            return None\n",
        "    else:\n",
        "        print(\"âŒ No frames were generated\")\n",
        "        return None\n",
        "\n",
        "# Generate and download the video\n",
        "video_path = create_detection_video()\n",
        "\n",
        "if video_path:\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"ðŸŽ‰ VIDEO GENERATION COMPLETED SUCCESSFULLY!\")\n",
        "    print(\"=\"*60)\n",
        "    print(f\"ðŸ“¹ Output: bone_fracture_detection.mp4\")\n",
        "    print(f\"ðŸ–¼ï¸  Frames: {config.max_frames}\")\n",
        "    print(f\"ðŸŽ¬ FPS: {config.fps}\")\n",
        "    print(f\"ðŸ’¾ Location: {video_path}\")\n",
        "    print(\"=\"*60)\n",
        "else:\n",
        "    print(\"\\nâŒ Video generation failed. Please check the error messages above.\")"
      ],
      "metadata": {
        "id": "IrKuLzW4CvuO"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}