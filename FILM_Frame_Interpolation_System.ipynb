{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install -q mediapy tensorflow tensorflow_hub\n",
        "!apt-get -qq install -y ffmpeg"
      ],
      "metadata": {
        "id": "-byCmi15Wb0W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import numpy as np\n",
        "import mediapy as media\n",
        "from IPython.display import display\n",
        "import ipywidgets as widgets\n",
        "from google.colab import files\n",
        "import time\n",
        "from typing import List, Tuple, Optional\n",
        "import cv2\n",
        "import subprocess"
      ],
      "metadata": {
        "id": "kjNHhcw8WL03"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **1-FILM Interpolator Class**"
      ],
      "metadata": {
        "id": "p3Y9LstEWlq-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class FilmInterpolator:\n",
        "    def __init__(self, model_url: str = \"https://tfhub.dev/google/film/1\"):\n",
        "        self.model = hub.load(model_url)\n",
        "        self.align = 64\n",
        "        self._warmup_model()\n",
        "\n",
        "    def _warmup_model(self):\n",
        "        dummy_input = {\n",
        "            'time': tf.reshape(tf.constant([0.5], dtype=tf.float32), [1, 1]),\n",
        "            'x0': tf.zeros((1, 64, 64, 3), dtype=tf.float32),\n",
        "            'x1': tf.zeros((1, 64, 64, 3), dtype=tf.float32)\n",
        "        }\n",
        "        _ = self.model(dummy_input, training=False)\n",
        "\n",
        "    def _pad_to_align(self, image: tf.Tensor) -> tf.Tensor:\n",
        "        height, width = tf.shape(image)[0], tf.shape(image)[1]\n",
        "        height_to_pad = (self.align - height % self.align) % self.align\n",
        "        width_to_pad = (self.align - width % self.align) % self.align\n",
        "        if height_to_pad != 0 or width_to_pad != 0:\n",
        "            image = tf.pad(\n",
        "                image,\n",
        "                [[0, height_to_pad], [0, width_to_pad], [0, 0]],\n",
        "                mode='REFLECT'\n",
        "            )\n",
        "        return image\n",
        "\n",
        "    def interpolate(self, frame1: np.ndarray, frame2: np.ndarray, time: float = 0.5) -> np.ndarray:\n",
        "        frame1_tensor = tf.convert_to_tensor(frame1, dtype=tf.float32)\n",
        "        frame2_tensor = tf.convert_to_tensor(frame2, dtype=tf.float32)\n",
        "        orig_height, orig_width = frame1_tensor.shape[0], frame1_tensor.shape[1]\n",
        "        frame1_tensor = self._pad_to_align(frame1_tensor)\n",
        "        frame2_tensor = self._pad_to_align(frame2_tensor)\n",
        "        inputs = {\n",
        "            'time': tf.reshape(tf.constant([time], dtype=tf.float32), [1, 1]),\n",
        "            'x0': tf.expand_dims(frame1_tensor, axis=0),\n",
        "            'x1': tf.expand_dims(frame2_tensor, axis=0)\n",
        "        }\n",
        "        with tf.device('/GPU:0' if tf.config.list_physical_devices('GPU') else '/CPU:0'):\n",
        "            result = self.model(inputs, training=False)\n",
        "        output = result['image'][0].numpy()\n",
        "        return output[:orig_height, :orig_width, :]"
      ],
      "metadata": {
        "id": "QlmQeNc5WP_1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **2-Helper Functions**"
      ],
      "metadata": {
        "id": "oWMlnbz_Wv5-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def upload_image(description: str, layout: Optional[widgets.Layout] = None) -> widgets.FileUpload:\n",
        "    if layout is None:\n",
        "        layout = widgets.Layout(width='auto', height='40px')\n",
        "    upload = widgets.FileUpload(\n",
        "        description=description,\n",
        "        accept='image/*',\n",
        "        multiple=False,\n",
        "        style={'description_width': 'initial'},\n",
        "        layout=layout\n",
        "    )\n",
        "    return upload\n",
        "\n",
        "def process_uploaded_image(upload: widgets.FileUpload, max_dim: int = 1024) -> Optional[np.ndarray]:\n",
        "    if not upload.value:\n",
        "        return None\n",
        "    try:\n",
        "        uploaded_file = next(iter(upload.value.values()))\n",
        "        image = tf.io.decode_image(uploaded_file['content'], channels=3)\n",
        "        image = tf.image.convert_image_dtype(image, tf.float32)\n",
        "        original_height, original_width = image.shape[0], image.shape[1]\n",
        "        scale = min(max_dim / original_height, max_dim / original_width)\n",
        "        if scale < 1:\n",
        "            new_height = int(original_height * scale)\n",
        "            new_width = int(original_width * scale)\n",
        "            image = tf.image.resize(image, [new_height, new_width], method=tf.image.ResizeMethod.AREA)\n",
        "        return image.numpy()\n",
        "    except Exception as e:\n",
        "        print(f\"Image processing error: {str(e)}\")\n",
        "        return None\n",
        "\n",
        "def generate_interpolated_frames(\n",
        "    frame1: np.ndarray,\n",
        "    frame2: np.ndarray,\n",
        "    num_frames: int = 5,\n",
        "    interpolator: Optional[FilmInterpolator] = None\n",
        ") -> List[np.ndarray]:\n",
        "    if interpolator is None:\n",
        "        interpolator = FilmInterpolator()\n",
        "    frames = [frame1]\n",
        "    progress = widgets.IntProgress(value=0, max=num_frames-2, description='Processing:')\n",
        "    display(progress)\n",
        "    try:\n",
        "        for i in range(1, num_frames-1):\n",
        "            t = i / (num_frames-1)\n",
        "            mid_frame = interpolator.interpolate(frame1, frame2, t)\n",
        "            frames.append(mid_frame)\n",
        "            progress.value += 1\n",
        "            time.sleep(0.1)\n",
        "        frames.append(frame2)\n",
        "        return frames\n",
        "    finally:\n",
        "        progress.close()\n",
        "\n",
        "def smart_resize(img, target_size):\n",
        "    h, w = img.shape[:2]\n",
        "    target_h, target_w = target_size\n",
        "    scale = min(target_h / h, target_w / w)\n",
        "    if scale == 1:\n",
        "        return img\n",
        "    new_h, new_w = int(h * scale), int(w * scale)\n",
        "    resized = cv2.resize(img, (new_w, new_h), interpolation=cv2.INTER_AREA)\n",
        "    if new_w < target_w or new_h < target_h:\n",
        "        pad_top = (target_h - new_h) // 2\n",
        "        pad_bottom = target_h - new_h - pad_top\n",
        "        pad_left = (target_w - new_w) // 2\n",
        "        pad_right = target_w - new_w - pad_left\n",
        "        resized = cv2.copyMakeBorder(\n",
        "            resized, pad_top, pad_bottom, pad_left, pad_right,\n",
        "            cv2.BORDER_CONSTANT, value=[0, 0, 0]\n",
        "        )\n",
        "    return resized\n",
        "\n",
        "def convert_video(input_path, output_path):\n",
        "    command = [\n",
        "        'ffmpeg', '-y', '-i', input_path,\n",
        "        '-vcodec', 'libx264', '-crf', '23', '-pix_fmt', 'yuv420p',\n",
        "        output_path\n",
        "    ]\n",
        "    subprocess.run(command, check=True)\n",
        "\n",
        "def create_combined_video(\n",
        "    image1: np.ndarray,\n",
        "    image2: np.ndarray,\n",
        "    interpolated_frames,\n",
        "    output_path: str = 'combined_video.mp4',\n",
        "    fps: int = 5\n",
        ") -> str:\n",
        "    img1 = (image1 * 255).astype(np.uint8)\n",
        "    img2 = (image2 * 255).astype(np.uint8)\n",
        "    min_height = min(img1.shape[0], img2.shape[0], *[f.shape[0] for f in interpolated_frames])\n",
        "    target_width = max(img1.shape[1], img2.shape[1])\n",
        "    img1 = smart_resize(img1, (min_height, target_width))\n",
        "    img2 = smart_resize(img2, (min_height, target_width))\n",
        "    interpolated_frames = [\n",
        "        smart_resize((frame * 255).astype(np.uint8), (min_height, target_width))\n",
        "        for frame in interpolated_frames\n",
        "    ]\n",
        "    separator = np.zeros((min_height, 50, 3), dtype=np.uint8)\n",
        "    top_row = np.concatenate([img1, separator, img2], axis=1)\n",
        "    frame_height = top_row.shape[0] + 50 + interpolated_frames[0].shape[0]\n",
        "    frame_width = max(top_row.shape[1], interpolated_frames[0].shape[1])\n",
        "    # Save initial video\n",
        "    temp_path = output_path\n",
        "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "    out = cv2.VideoWriter(temp_path, fourcc, fps, (frame_width, frame_height))\n",
        "    font_scale = 2.2\n",
        "    thickness = 6\n",
        "    for frame in interpolated_frames:\n",
        "        combined_frame = np.zeros((frame_height, frame_width, 3), dtype=np.uint8)\n",
        "        combined_frame[:top_row.shape[0], :top_row.shape[1]] = top_row\n",
        "        video_y = top_row.shape[0] + 30\n",
        "        video_x = (frame_width - frame.shape[1]) // 2\n",
        "        combined_frame[video_y:video_y+frame.shape[0], video_x:video_x+frame.shape[1]] = frame\n",
        "        cv2.putText(combined_frame, 'Original',\n",
        "            (img1.shape[1]//2 - 130, 80),\n",
        "            cv2.FONT_HERSHEY_SIMPLEX, font_scale, (255, 0, 0), thickness)\n",
        "        cv2.putText(combined_frame, 'Original',\n",
        "            (img1.shape[1] + separator.shape[1] + img2.shape[1]//2 - 130, 80),\n",
        "            cv2.FONT_HERSHEY_SIMPLEX, font_scale, (255, 0, 0), thickness)\n",
        "        cv2.putText(combined_frame, 'Generated',\n",
        "            (video_x + frame.shape[1]//2 - 180, video_y - 20),\n",
        "            cv2.FONT_HERSHEY_SIMPLEX, font_scale, (0, 0, 255), thickness)\n",
        "        out.write(combined_frame)\n",
        "    out.release()\n",
        "    # Convert video for mobile compatibility\n",
        "    mobile_path = output_path.replace('.mp4', '_mobile.mp4')\n",
        "    convert_video(output_path, mobile_path)\n",
        "    return mobile_path"
      ],
      "metadata": {
        "id": "C4on6GhZWVAI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **3-User Interface**"
      ],
      "metadata": {
        "id": "_nRJqnt4W0lW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_ui():\n",
        "    style = {'description_width': '150px'}\n",
        "    layout = widgets.Layout(width='auto', height='40px')\n",
        "    header = widgets.HTML(\n",
        "        value=\"<h1 style='text-align:center;color:#1f77b4'>FILM Frame Interpolation System</h1>\"\n",
        "        \"<p style='text-align:center'>Please upload two images for interpolation</p>\"\n",
        "    )\n",
        "    display(header)\n",
        "\n",
        "    # Only build widgets once and display HBox\n",
        "    image1_upload = upload_image(\"First Image:\", layout)\n",
        "    image2_upload = upload_image(\"Second Image:\", layout)\n",
        "    upload_box = widgets.HBox([image1_upload, image2_upload])\n",
        "    display(upload_box)\n",
        "\n",
        "    advanced_settings = widgets.Accordion([\n",
        "        widgets.VBox([\n",
        "            widgets.IntSlider(\n",
        "                value=5,\n",
        "                min=3,\n",
        "                max=15,\n",
        "                step=1,\n",
        "                description='Number of intermediate frames:',\n",
        "                style=style,\n",
        "                layout=layout\n",
        "            ),\n",
        "            widgets.IntSlider(\n",
        "                value=5,\n",
        "                min=1,\n",
        "                max=30,\n",
        "                step=1,\n",
        "                description='Video FPS:',\n",
        "                style=style,\n",
        "                layout=layout\n",
        "            ),\n",
        "            widgets.IntSlider(\n",
        "                value=1024,\n",
        "                min=256,\n",
        "                max=2048,\n",
        "                step=128,\n",
        "                description='Max image size:',\n",
        "                style=style,\n",
        "                layout=layout\n",
        "            )\n",
        "        ])\n",
        "    ], titles=('Advanced Settings',))\n",
        "    display(advanced_settings)\n",
        "\n",
        "    run_button = widgets.Button(\n",
        "        description=\"Run Interpolation and Create Video\",\n",
        "        button_style='success',\n",
        "        icon='play',\n",
        "        layout=widgets.Layout(width='300px', height='50px')\n",
        "    )\n",
        "    display(widgets.HBox([run_button], layout=widgets.Layout(justify_content='center')))\n",
        "    output_area = widgets.Output()\n",
        "    display(output_area)\n",
        "    def on_button_clicked(b):\n",
        "        with output_area:\n",
        "            output_area.clear_output()\n",
        "            print(\"\\nProcessing started...\")\n",
        "            num_frames = advanced_settings.children[0].children[0].value\n",
        "            fps = advanced_settings.children[0].children[1].value\n",
        "            max_dim = advanced_settings.children[0].children[2].value\n",
        "            image1 = process_uploaded_image(image1_upload, max_dim)\n",
        "            image2 = process_uploaded_image(image2_upload, max_dim)\n",
        "            if image1 is None or image2 is None:\n",
        "                print(\"Error: Please upload both images.\")\n",
        "                return\n",
        "            try:\n",
        "                print(f\"\\nImage Info:\\n- Image 1: {image1.shape[1]}x{image1.shape[0]}\\n- Image 2: {image2.shape[1]}x{image2.shape[0]}\")\n",
        "                print(f\"\\nGenerating {num_frames} interpolated frames...\")\n",
        "                start_time = time.time()\n",
        "                frames = generate_interpolated_frames(image1, image2, num_frames)\n",
        "                print(f\"Frame generation finished in {time.time()-start_time:.2f} seconds.\")\n",
        "                print(\"\\nCreating combined video...\")\n",
        "                video_path = create_combined_video(image1, image2, frames, fps=fps)\n",
        "                print(\"\\nFinal video:\")\n",
        "                media.show_video(media.read_video(video_path), fps=fps)\n",
        "                print(\"\\nClick below to download the video:\")\n",
        "                files.download(video_path)\n",
        "            except Exception as e:\n",
        "                print(f\"\\nProcessing error: {str(e)}\")\n",
        "                raise\n",
        "    run_button.on_click(on_button_clicked)\n",
        "\n",
        "create_ui()"
      ],
      "metadata": {
        "id": "McmUv8uVWY5n"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}