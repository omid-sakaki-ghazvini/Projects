{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **1. Install packages**"
      ],
      "metadata": {
        "id": "dFXy2oGjm9tY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q --upgrade \\\n",
        "    transformers==4.51.0 \\\n",
        "    datasets==3.1.0 \\\n",
        "    peft==0.13.2 \\\n",
        "    accelerate==1.0.1 \\\n",
        "    evaluate \\\n",
        "    scikit-learn \\\n",
        "    matplotlib seaborn wordcloud"
      ],
      "metadata": {
        "id": "aemiqurnl90Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **2. Imports**"
      ],
      "metadata": {
        "id": "e7988l8SnGj-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import warnings\n",
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, f1_score, classification_report, confusion_matrix\n",
        "from transformers import (\n",
        "    AutoTokenizer,\n",
        "    AutoModelForSequenceClassification,\n",
        "    Trainer,\n",
        "    TrainingArguments,\n",
        "    DataCollatorWithPadding,\n",
        ")\n",
        "from peft import LoraConfig, get_peft_model, TaskType\n",
        "from datasets import Dataset\n",
        "from huggingface_hub import login\n",
        "from google.colab import userdata, files\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "plt.rcParams['figure.figsize'] = (10, 6)\n",
        "sns.set(style=\"whitegrid\")"
      ],
      "metadata": {
        "id": "BSQv3EA8mAKH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **3. Hugging Face login**"
      ],
      "metadata": {
        "id": "YVb5i-ltnOKP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    login(token=userdata.get('HF_TOKEN'))\n",
        "    print(\"Successfully logged in using Colab secret\")\n",
        "except Exception as e:\n",
        "    print(f\"Secret login failed: {e}\")\n",
        "    try:\n",
        "        login()\n",
        "        print(\"Interactive login successful\")\n",
        "    except:\n",
        "        print(\"Login skipped – may hit rate limits\")"
      ],
      "metadata": {
        "id": "szLyzC-LmCXf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **4. Download dataset from Kaggle**"
      ],
      "metadata": {
        "id": "fHgfTRuBnTn5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if not os.path.exists('/root/.kaggle/kaggle.json'):\n",
        "    print(\"Please upload kaggle.json\")\n",
        "    uploaded = files.upload()\n",
        "    if 'kaggle.json' in uploaded:\n",
        "        !mkdir -p ~/.kaggle\n",
        "        !cp kaggle.json ~/.kaggle/\n",
        "        !chmod 600 ~/.kaggle/kaggle.json\n",
        "\n",
        "!kaggle datasets download -d priyangshumukherjee/mental-health-text-classification-dataset --unzip -p ./data -q\n",
        "print(\"Downloaded files:\", os.listdir('./data'))"
      ],
      "metadata": {
        "id": "5sBsozZdmEho"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **5. Load data & prepare labels**"
      ],
      "metadata": {
        "id": "BTCdjhU2nZtv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "TRAIN_PATH = './data/mental_heath_unbanlanced.csv'\n",
        "TEST_PATH  = './data/mental_health_combined_test.csv'\n",
        "\n",
        "df_train = pd.read_csv(TRAIN_PATH)\n",
        "df_test  = pd.read_csv(TEST_PATH)\n",
        "\n",
        "label2id = {'Normal': 0, 'Depression': 1, 'Anxiety': 2, 'Suicidal': 3}\n",
        "id2label = {v: k for k, v in label2id.items()}\n",
        "\n",
        "df_train['label'] = df_train['status'].map(label2id).astype(int)\n",
        "df_test['label']  = df_test['status'].map(label2id).astype(int)\n",
        "\n",
        "df_train = df_train.rename(columns={'label': 'labels'})\n",
        "df_test  = df_test.rename(columns={'label': 'labels'})\n",
        "\n",
        "# Stratified split\n",
        "train_df, val_df = train_test_split(\n",
        "    df_train,\n",
        "    test_size=0.12,\n",
        "    stratify=df_train['labels'],\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "train_ds = Dataset.from_pandas(train_df[['text', 'labels']].reset_index(drop=True))\n",
        "val_ds   = Dataset.from_pandas(val_df[['text', 'labels']].reset_index(drop=True))\n",
        "test_ds  = Dataset.from_pandas(df_test[['text', 'labels']].reset_index(drop=True))"
      ],
      "metadata": {
        "id": "Y2x5UdfDmJB_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **6. Tokenization**"
      ],
      "metadata": {
        "id": "O_adSw01nnRu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "MODEL_NAME = \"microsoft/deberta-v3-base\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
        "\n",
        "def tokenize_function(examples):\n",
        "    return tokenizer(\n",
        "        examples[\"text\"],\n",
        "        truncation=True,\n",
        "        max_length=224,\n",
        "        padding=False\n",
        "    )\n",
        "\n",
        "tokenized_train = train_ds.map(tokenize_function, batched=True, remove_columns=[\"text\"])\n",
        "tokenized_val   = val_ds.map(tokenize_function, batched=True, remove_columns=[\"text\"])\n",
        "tokenized_test  = test_ds.map(tokenize_function, batched=True, remove_columns=[\"text\"])"
      ],
      "metadata": {
        "id": "tl0euKpWmPJA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **7. Load model**"
      ],
      "metadata": {
        "id": "GuciUybpnuU3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\n",
        "    MODEL_NAME,\n",
        "    num_labels=4,\n",
        "    id2label=id2label,\n",
        "    label2id=label2id,\n",
        "    ignore_mismatched_sizes=True,\n",
        "    torch_dtype=torch.float16,\n",
        ").to(device)"
      ],
      "metadata": {
        "id": "0skDyNtHmQ5v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **8. Apply LoRA**"
      ],
      "metadata": {
        "id": "pKPaE5fzn0Bv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lora_config = LoraConfig(\n",
        "    r=16,\n",
        "    lora_alpha=32,\n",
        "    target_modules=[\"query_proj\", \"value_proj\"],\n",
        "    lora_dropout=0.05,\n",
        "    bias=\"none\",\n",
        "    task_type=TaskType.SEQ_CLS,\n",
        "    modules_to_save=[\"classifier\"]\n",
        ")\n",
        "\n",
        "model = get_peft_model(model, lora_config)\n",
        "model.print_trainable_parameters()\n",
        "\n",
        "for name, param in model.named_parameters():\n",
        "    if param.requires_grad:\n",
        "        param.data = param.data.float()\n",
        "\n",
        "print(\"Trainable parameters\")"
      ],
      "metadata": {
        "id": "a1XaTMKTmS_P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **9. Metrics**"
      ],
      "metadata": {
        "id": "p3WLrFLvoFZ4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_metrics(eval_pred):\n",
        "    logits, labels = eval_pred\n",
        "    preds = np.argmax(logits, axis=1)\n",
        "    acc = accuracy_score(labels, preds)\n",
        "    f1  = f1_score(labels, preds, average=\"weighted\")\n",
        "    return {\"accuracy\": acc, \"f1\": f1}"
      ],
      "metadata": {
        "id": "wg-VRUFOmU9n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **10. TrainingArguments**"
      ],
      "metadata": {
        "id": "1YMCCt8PoLXY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "training_args = TrainingArguments(\n",
        "    output_dir                  = \"./mental_health_deberta_lora\",\n",
        "    num_train_epochs            = 4,\n",
        "    per_device_train_batch_size = 8,\n",
        "    per_device_eval_batch_size  = 16,\n",
        "    gradient_accumulation_steps = 2,\n",
        "    learning_rate               = 1.5e-4,\n",
        "    weight_decay                = 0.01,\n",
        "    warmup_ratio                = 0.1,\n",
        "    fp16                        = True,\n",
        "    eval_strategy               = \"epoch\",\n",
        "    save_strategy               = \"epoch\",\n",
        "    logging_steps               = 100,\n",
        "    load_best_model_at_end      = True,\n",
        "    metric_for_best_model       = \"f1\",\n",
        "    greater_is_better           = True,\n",
        "    report_to                   = \"none\",\n",
        "    optim                       = \"adamw_torch\",\n",
        "    max_grad_norm               = 0.5,\n",
        "    lr_scheduler_type           = \"cosine\",\n",
        "    dataloader_num_workers      = 2,\n",
        "    remove_unused_columns       = False,\n",
        ")"
      ],
      "metadata": {
        "id": "5kPkub1AmW6n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **11. Trainer**"
      ],
      "metadata": {
        "id": "xMH2SghqoSyv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = Trainer(\n",
        "    model           = model,\n",
        "    args            = training_args,\n",
        "    train_dataset   = tokenized_train,\n",
        "    eval_dataset    = tokenized_val,\n",
        "    tokenizer       = tokenizer,\n",
        "    data_collator   = DataCollatorWithPadding(tokenizer=tokenizer),\n",
        "    compute_metrics = compute_metrics,\n",
        ")"
      ],
      "metadata": {
        "id": "QsfPgyhBmY8-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **12. training**"
      ],
      "metadata": {
        "id": "am39KQbGofdn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Starting training...\")\n",
        "trainer.train()"
      ],
      "metadata": {
        "id": "ik7oTJismarX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **13. Evaluate & plot**"
      ],
      "metadata": {
        "id": "EISrtz-VongP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_results = trainer.evaluate(tokenized_test)\n",
        "print(\"\\nTest results:\", test_results)\n",
        "\n",
        "predictions = trainer.predict(tokenized_test)\n",
        "preds = np.argmax(predictions.predictions, axis=1)\n",
        "true_labels = predictions.label_ids\n",
        "\n",
        "print(\"\\nClassification Report:\\n\")\n",
        "print(classification_report(true_labels, preds, target_names=list(id2label.values())))\n",
        "\n",
        "# Confusion Matrix\n",
        "cm = confusion_matrix(true_labels, preds)\n",
        "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\",\n",
        "            xticklabels=list(id2label.values()),\n",
        "            yticklabels=list(id2label.values()))\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"True\")\n",
        "plt.title(\"Confusion Matrix – Balanced Test Set\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "nRDFN1WNmcvv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **14. Save LoRA adapter**"
      ],
      "metadata": {
        "id": "TcAhhJ-9ovOI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Merging LoRA weights into base model...\")\n",
        "merged_model = model.merge_and_unload()\n",
        "\n",
        "# Optional: Save merged model locally first (for backup)\n",
        "merged_model.save_pretrained(\"./merged_mental_health_deberta\")\n",
        "tokenizer.save_pretrained(\"./merged_mental_health_deberta\")\n",
        "print(\"Merged model saved locally.\")"
      ],
      "metadata": {
        "id": "218cxwSKkjrn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **15. Push merged model + tokenizer to Hugging Face Hub**"
      ],
      "metadata": {
        "id": "caupsfln5Gmq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "repo_id = \"OmidSakaki/mental-health-deberta\"\n",
        "\n",
        "print(f\"Pushing merged model to: https://huggingface.co/{repo_id}\")\n",
        "\n",
        "merged_model.push_to_hub(\n",
        "    repo_id=repo_id,\n",
        "    commit_message=\"Full merged model after LoRA fine-tuning (4-class mental health classification)\",\n",
        "    safe_serialization=True,\n",
        "    private=False\n",
        ")\n",
        "\n",
        "tokenizer.push_to_hub(\n",
        "    repo_id=repo_id,\n",
        "    commit_message=\"Tokenizer for merged mental health model\"\n",
        ")\n",
        "\n",
        "print(\"Upload completed! Model is now live at:\", f\"https://huggingface.co/{repo_id}\")"
      ],
      "metadata": {
        "id": "cdXMPr9d49By"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}