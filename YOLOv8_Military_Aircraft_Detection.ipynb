{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install ultralytics torchvision kagglehub pycocotools -q\n",
        "!pip install --upgrade matplotlib seaborn pandas opencv-python tqdm -q\n",
        "\n",
        "import os\n",
        "import glob\n",
        "import random\n",
        "import shutil\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import xml.etree.ElementTree as ET\n",
        "from tqdm.notebook import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import cv2\n",
        "import torch\n",
        "from ultralytics import YOLO\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# ‚úÖ Colab-Specific Setup\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=False)\n",
        "\n",
        "# Set random seeds\n",
        "SEED = 42\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed(SEED)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "\n",
        "print(f\"‚úÖ PyTorch Version: {torch.__version__}\")\n",
        "print(f\"‚úÖ CUDA Available: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"‚úÖ GPU: {torch.cuda.get_device_name(0)}\")"
      ],
      "metadata": {
        "id": "FOrxPfqEr7la"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **1. Download Kaggle Dataset**"
      ],
      "metadata": {
        "id": "yaYAACLtJGd0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# üöÄ DOWNLOAD KAGGLE MILAIR DATASET\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"üì• DOWNLOADING MILAIR DATASET FROM KAGGLE\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "import kagglehub\n",
        "\n",
        "# Download latest version\n",
        "print(\"üì¶ Downloading dataset...\")\n",
        "path = kagglehub.dataset_download(\"nicolassilvanash/milair-dataset\")\n",
        "print(f\"‚úÖ Dataset downloaded to: {path}\")\n",
        "\n",
        "# Set dataset paths\n",
        "DATA_DIR = path\n",
        "IMAGES_DIR = os.path.join(DATA_DIR, \"images\")\n",
        "ANNOTATIONS_DIR = os.path.join(DATA_DIR, \"annotations\")\n",
        "\n",
        "# Verify download\n",
        "print(f\"\\nüìÇ Verifying dataset structure:\")\n",
        "print(f\"   Data directory: {DATA_DIR}\")\n",
        "print(f\"   Images exist: {os.path.exists(IMAGES_DIR)}\")\n",
        "print(f\"   Annotations exist: {os.path.exists(ANNOTATIONS_DIR)}\")\n",
        "\n",
        "# Count files\n",
        "image_files = glob.glob(os.path.join(IMAGES_DIR, \"*\"))\n",
        "annotation_files = glob.glob(os.path.join(ANNOTATIONS_DIR, \"*.xml\"))\n",
        "print(f\"   Number of images: {len(image_files)}\")\n",
        "print(f\"   Number of annotations: {len(annotation_files)}\")\n",
        "\n",
        "# Class mapping\n",
        "CLASS_NAMES = ['ah64', 'chinook', 'cougar', 'f15', 'f16', 'seahawk']\n",
        "CLASS_MAP = {name: idx for idx, name in enumerate(CLASS_NAMES)}\n",
        "\n",
        "print(f\"\\nüìä Classes: {CLASS_NAMES}\")"
      ],
      "metadata": {
        "id": "fiYPgHaptuhQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **2. Explore Dataset**"
      ],
      "metadata": {
        "id": "E_4avyBzJMsL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def explore_dataset():\n",
        "    \"\"\"Explore dataset statistics\"\"\"\n",
        "\n",
        "    xml_files = glob.glob(os.path.join(ANNOTATIONS_DIR, \"*.xml\"))\n",
        "    print(f\"üìä Analyzing {len(xml_files)} annotations...\")\n",
        "\n",
        "    class_counts = {cls: 0 for cls in CLASS_NAMES}\n",
        "    image_sizes = []\n",
        "\n",
        "    for xml_file in tqdm(xml_files[:200], desc=\"Processing\"):  # Limit for speed\n",
        "        try:\n",
        "            tree = ET.parse(xml_file)\n",
        "            root = tree.getroot()\n",
        "\n",
        "            # Get image size\n",
        "            size = root.find('size')\n",
        "            if size is not None:\n",
        "                width = int(size.find('width').text)\n",
        "                height = int(size.find('height').text)\n",
        "                image_sizes.append((width, height))\n",
        "\n",
        "            # Count objects\n",
        "            for obj in root.findall('object'):\n",
        "                name = obj.find('name').text.lower()\n",
        "                if name in class_counts:\n",
        "                    class_counts[name] += 1\n",
        "        except Exception as e:\n",
        "            continue\n",
        "\n",
        "    # Display statistics\n",
        "    print(\"\\nüìà Class Distribution:\")\n",
        "    total_objects = sum(class_counts.values())\n",
        "    for cls, count in class_counts.items():\n",
        "        percentage = (count / total_objects * 100) if total_objects > 0 else 0\n",
        "        print(f\"   {cls:10s}: {count:4d} objects ({percentage:.1f}%)\")\n",
        "\n",
        "    # Visualize\n",
        "    fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "    # Class distribution\n",
        "    axes[0].barh(list(class_counts.keys()), list(class_counts.values()))\n",
        "    axes[0].set_title('Class Distribution', fontsize=14, fontweight='bold')\n",
        "    axes[0].set_xlabel('Count')\n",
        "    axes[0].grid(True, alpha=0.3)\n",
        "\n",
        "    # Image size distribution\n",
        "    if image_sizes:\n",
        "        widths, heights = zip(*image_sizes)\n",
        "        axes[1].scatter(widths, heights, alpha=0.5, s=10)\n",
        "        axes[1].set_title('Image Dimensions', fontsize=14, fontweight='bold')\n",
        "        axes[1].set_xlabel('Width (px)')\n",
        "        axes[1].set_ylabel('Height (px)')\n",
        "        axes[1].grid(True, alpha=0.3)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    return len(xml_files)\n",
        "\n",
        "total_samples = explore_dataset()"
      ],
      "metadata": {
        "id": "PL2pnK2oHeW8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **3. Convert to YOLO Format**"
      ],
      "metadata": {
        "id": "YtR7wcoXJTPE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def convert_to_yolo_format():\n",
        "    \"\"\"Convert Pascal VOC to YOLO format\"\"\"\n",
        "\n",
        "    WORKING_DIR = \"/content/milair_yolo\"\n",
        "    os.makedirs(WORKING_DIR, exist_ok=True)\n",
        "\n",
        "    # Create directory structure\n",
        "    for split in ['train', 'val', 'test']:\n",
        "        os.makedirs(os.path.join(WORKING_DIR, f'images/{split}'), exist_ok=True)\n",
        "        os.makedirs(os.path.join(WORKING_DIR, f'labels/{split}'), exist_ok=True)\n",
        "\n",
        "    # Get all XML files\n",
        "    xml_files = glob.glob(os.path.join(ANNOTATIONS_DIR, \"*.xml\"))\n",
        "    print(f\"\\nüîÑ Converting {len(xml_files)} annotations to YOLO format...\")\n",
        "\n",
        "    # Process files\n",
        "    processed_files = []\n",
        "\n",
        "    for xml_file in tqdm(xml_files, desc=\"Converting\"):\n",
        "        try:\n",
        "            tree = ET.parse(xml_file)\n",
        "            root = tree.getroot()\n",
        "\n",
        "            # Get image filename\n",
        "            filename = root.find('filename').text\n",
        "            base_name = os.path.splitext(filename)[0]\n",
        "\n",
        "            # Find image file\n",
        "            img_extensions = ['.jpg', '.jpeg', '.png', '.JPG', '.JPEG']\n",
        "            img_path = None\n",
        "            for ext in img_extensions:\n",
        "                test_path = os.path.join(IMAGES_DIR, base_name + ext)\n",
        "                if os.path.exists(test_path):\n",
        "                    img_path = test_path\n",
        "                    break\n",
        "\n",
        "            if not img_path:\n",
        "                continue\n",
        "\n",
        "            # Get image size\n",
        "            size = root.find('size')\n",
        "            if size is None:\n",
        "                continue\n",
        "\n",
        "            img_w = int(size.find('width').text)\n",
        "            img_h = int(size.find('height').text)\n",
        "\n",
        "            # Extract annotations\n",
        "            annotations = []\n",
        "            for obj in root.findall('object'):\n",
        "                name = obj.find('name').text.lower()\n",
        "                if name not in CLASS_MAP:\n",
        "                    continue\n",
        "\n",
        "                bndbox = obj.find('bndbox')\n",
        "                if bndbox is None:\n",
        "                    continue\n",
        "\n",
        "                try:\n",
        "                    xmin = float(bndbox.find('xmin').text)\n",
        "                    ymin = float(bndbox.find('ymin').text)\n",
        "                    xmax = float(bndbox.find('xmax').text)\n",
        "                    ymax = float(bndbox.find('ymax').text)\n",
        "\n",
        "                    # Convert to YOLO format\n",
        "                    x_center = (xmin + xmax) / 2 / img_w\n",
        "                    y_center = (ymin + ymax) / 2 / img_h\n",
        "                    width = (xmax - xmin) / img_w\n",
        "                    height = (ymax - ymin) / img_h\n",
        "\n",
        "                    # Validate\n",
        "                    if (0 <= x_center <= 1 and 0 <= y_center <= 1 and\n",
        "                        0 < width <= 1 and 0 < height <= 1):\n",
        "                        cls_id = CLASS_MAP[name]\n",
        "                        annotations.append(f\"{cls_id} {x_center:.6f} {y_center:.6f} {width:.6f} {height:.6f}\")\n",
        "                except:\n",
        "                    continue\n",
        "\n",
        "            if annotations:\n",
        "                processed_files.append({\n",
        "                    'image_path': img_path,\n",
        "                    'base_name': base_name,\n",
        "                    'annotations': annotations\n",
        "                })\n",
        "\n",
        "        except Exception as e:\n",
        "            continue\n",
        "\n",
        "    print(f\"‚úÖ Successfully processed: {len(processed_files)}/{len(xml_files)} files\")\n",
        "\n",
        "    # Split dataset\n",
        "    random.shuffle(processed_files)\n",
        "    train_ratio, val_ratio = 0.8, 0.1\n",
        "\n",
        "    train_idx = int(len(processed_files) * train_ratio)\n",
        "    val_idx = train_idx + int(len(processed_files) * val_ratio)\n",
        "\n",
        "    train_data = processed_files[:train_idx]\n",
        "    val_data = processed_files[train_idx:val_idx]\n",
        "    test_data = processed_files[val_idx:]\n",
        "\n",
        "    # Save split data\n",
        "    def save_split(data_list, split_name):\n",
        "        count = 0\n",
        "        for item in tqdm(data_list, desc=f\"Saving {split_name}\"):\n",
        "            try:\n",
        "                # Copy image\n",
        "                img_ext = os.path.splitext(item['image_path'])[1]\n",
        "                img_dest = os.path.join(WORKING_DIR, f\"images/{split_name}\",\n",
        "                                       f\"{item['base_name']}{img_ext}\")\n",
        "                shutil.copy2(item['image_path'], img_dest)\n",
        "\n",
        "                # Save annotations\n",
        "                label_dest = os.path.join(WORKING_DIR, f\"labels/{split_name}\",\n",
        "                                         f\"{item['base_name']}.txt\")\n",
        "                with open(label_dest, 'w') as f:\n",
        "                    f.write('\\n'.join(item['annotations']))\n",
        "\n",
        "                count += 1\n",
        "            except:\n",
        "                continue\n",
        "\n",
        "        return count\n",
        "\n",
        "    train_count = save_split(train_data, 'train')\n",
        "    val_count = save_split(val_data, 'val')\n",
        "    test_count = save_split(test_data, 'test')\n",
        "\n",
        "    print(f\"\\nüìä Dataset Split Complete:\")\n",
        "    print(f\"   Train: {train_count} images\")\n",
        "    print(f\"   Validation: {val_count} images\")\n",
        "    print(f\"   Test: {test_count} images\")\n",
        "\n",
        "    # Create data.yaml\n",
        "    yaml_content = f\"\"\"path: {WORKING_DIR}\n",
        "train: images/train\n",
        "val: images/val\n",
        "test: images/test\n",
        "\n",
        "nc: {len(CLASS_NAMES)}\n",
        "names: {CLASS_NAMES}\n",
        "\"\"\"\n",
        "\n",
        "    yaml_path = os.path.join(WORKING_DIR, \"data.yaml\")\n",
        "    with open(yaml_path, 'w') as f:\n",
        "        f.write(yaml_content)\n",
        "\n",
        "    print(f\"\\n‚úÖ Created data.yaml at: {yaml_path}\")\n",
        "\n",
        "    return WORKING_DIR, yaml_path, train_count, val_count, test_count\n",
        "\n",
        "# Convert dataset\n",
        "WORKING_DIR, YAML_PATH, train_count, val_count, test_count = convert_to_yolo_format()"
      ],
      "metadata": {
        "id": "pRQLZOMHHjcs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **4. Visualize Sample Annotations**"
      ],
      "metadata": {
        "id": "K-eePzCxJcbK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def visualize_sample_annotations(num_samples=4):\n",
        "    \"\"\"Visualize sample annotations with bounding boxes\"\"\"\n",
        "\n",
        "    train_img_dir = os.path.join(WORKING_DIR, \"images/train\")\n",
        "    train_label_dir = os.path.join(WORKING_DIR, \"labels/train\")\n",
        "\n",
        "    image_files = glob.glob(os.path.join(train_img_dir, \"*\"))\n",
        "    random.shuffle(image_files)\n",
        "\n",
        "    fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
        "    axes = axes.ravel()\n",
        "\n",
        "    colors = plt.cm.tab10(np.linspace(0, 1, len(CLASS_NAMES)))\n",
        "\n",
        "    for idx, img_path in enumerate(image_files[:num_samples]):\n",
        "        # Load image\n",
        "        img = cv2.imread(img_path)\n",
        "        if img is None:\n",
        "            continue\n",
        "\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "        # Load annotations\n",
        "        base_name = os.path.splitext(os.path.basename(img_path))[0]\n",
        "        label_path = os.path.join(train_label_dir, f\"{base_name}.txt\")\n",
        "\n",
        "        h, w = img.shape[:2]\n",
        "\n",
        "        if os.path.exists(label_path):\n",
        "            with open(label_path, 'r') as f:\n",
        "                lines = f.readlines()\n",
        "\n",
        "            for line in lines:\n",
        "                parts = line.strip().split()\n",
        "                if len(parts) == 5:\n",
        "                    cls_id, x_center, y_center, bbox_w, bbox_h = map(float, parts)\n",
        "\n",
        "                    # Convert to pixel coordinates\n",
        "                    x_center *= w\n",
        "                    y_center *= h\n",
        "                    bbox_w *= w\n",
        "                    bbox_h *= h\n",
        "\n",
        "                    x1 = int(x_center - bbox_w / 2)\n",
        "                    y1 = int(y_center - bbox_h / 2)\n",
        "                    x2 = int(x_center + bbox_w / 2)\n",
        "                    y2 = int(y_center + bbox_h / 2)\n",
        "\n",
        "                    # Draw bounding box\n",
        "                    color = colors[int(cls_id)]\n",
        "                    cv2.rectangle(img, (x1, y1), (x2, y2),\n",
        "                                (int(color[0]*255), int(color[1]*255), int(color[2]*255)), 2)\n",
        "\n",
        "                    # Add label\n",
        "                    label = CLASS_NAMES[int(cls_id)]\n",
        "                    cv2.putText(img, label, (x1, y1-10),\n",
        "                               cv2.FONT_HERSHEY_SIMPLEX, 0.7,\n",
        "                               (int(color[0]*255), int(color[1]*255), int(color[2]*255)), 2)\n",
        "\n",
        "        axes[idx].imshow(img)\n",
        "        axes[idx].axis('off')\n",
        "        axes[idx].set_title(f'Sample {idx+1}: {base_name}', fontsize=12)\n",
        "\n",
        "    plt.suptitle('MilAir Dataset - Sample Annotations', fontsize=16, fontweight='bold')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "visualize_sample_annotations()"
      ],
      "metadata": {
        "id": "GW7XOgLDHnFT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **5. Colab-Optimized Training**"
      ],
      "metadata": {
        "id": "jA8JP9cIJkK0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ‚öôÔ∏è COLAB OPTIMIZED TRAINING CONFIGURATION\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"üöÄ COLAB OPTIMIZED TRAINING CONFIGURATION\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Clear GPU cache\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "# Initialize model\n",
        "model = YOLO(\"yolov8m.pt\")  # Medium model for best balance\n",
        "\n",
        "# Colab-optimized training config\n",
        "colab_config = {\n",
        "    'data': YAML_PATH,\n",
        "    'epochs': 50,           # Reduced for Colab free tier\n",
        "    'imgsz': 640,\n",
        "    'batch': 8,             # Reduced for memory constraints\n",
        "    'workers': 2,           # Reduced workers\n",
        "    'device': 0 if torch.cuda.is_available() else 'cpu',\n",
        "    'name': 'milair_kaggle_v1',\n",
        "    'patience': 20,\n",
        "    'seed': SEED,\n",
        "\n",
        "    # Optimization\n",
        "    'lr0': 0.01,\n",
        "    'lrf': 0.01,\n",
        "    'momentum': 0.937,\n",
        "    'weight_decay': 0.0005,\n",
        "    'warmup_epochs': 3,\n",
        "\n",
        "    # Augmentation (optimized for aerial images)\n",
        "    'hsv_h': 0.015,\n",
        "    'hsv_s': 0.7,\n",
        "    'hsv_v': 0.4,\n",
        "    'degrees': 15,          # Aircraft can be at various angles\n",
        "    'translate': 0.1,\n",
        "    'scale': 0.2,\n",
        "    'fliplr': 0.5,\n",
        "    'mosaic': 0.8,\n",
        "\n",
        "    # Colab-specific optimizations\n",
        "    'cache': False,         # Save disk space\n",
        "    'save_period': 10,\n",
        "    'exist_ok': True,\n",
        "    'verbose': True,\n",
        "    'amp': True,            # Mixed precision training\n",
        "    'cos_lr': True,         # Cosine learning rate scheduler\n",
        "\n",
        "    # Save to Google Drive\n",
        "    'project': '/content/drive/MyDrive/milair_training',\n",
        "}\n",
        "\n",
        "print(\"\\n‚öôÔ∏è Training Configuration:\")\n",
        "print(f\"   Model: YOLOv8m\")\n",
        "print(f\"   Epochs: {colab_config['epochs']}\")\n",
        "print(f\"   Batch Size: {colab_config['batch']}\")\n",
        "print(f\"   Image Size: {colab_config['imgsz']}\")\n",
        "print(f\"   Classes: {len(CLASS_NAMES)}\")\n",
        "print(f\"   Training samples: {train_count}\")\n",
        "print(f\"   Save location: {colab_config['project']}\")"
      ],
      "metadata": {
        "id": "w9NPmB0cHwfb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **6. Start Training**"
      ],
      "metadata": {
        "id": "b4bXyF7dJppr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# üèÅ START TRAINING\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"üèÅ STARTING TRAINING\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "try:\n",
        "    # Train the model\n",
        "    results = model.train(**colab_config)\n",
        "    print(\"\\n‚úÖ Training completed successfully!\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"\\n‚ö†Ô∏è Training error: {e}\")\n",
        "\n",
        "    # Try with simpler configuration\n",
        "    print(\"üîÑ Trying with simplified configuration...\")\n",
        "\n",
        "    simple_config = colab_config.copy()\n",
        "    simple_config.update({\n",
        "        'epochs': 30,\n",
        "        'batch': 4,\n",
        "        'imgsz': 416,\n",
        "        'workers': 1,\n",
        "        'amp': False,\n",
        "        'mosaic': 0.0,\n",
        "        'cache': False,\n",
        "    })\n",
        "\n",
        "    results = model.train(**simple_config)\n",
        "    print(\"\\n‚úÖ Training completed with simplified config!\")"
      ],
      "metadata": {
        "id": "HE3EN9RpH0JL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **7. Evaluate Model**"
      ],
      "metadata": {
        "id": "wLIMFq8RJuV8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# üìä EVALUATE TRAINED MODEL\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"üìä MODEL EVALUATION\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Find and load best model\n",
        "best_model_paths = [\n",
        "    f\"{colab_config['project']}/{colab_config['name']}/weights/best.pt\",\n",
        "    f\"/content/drive/MyDrive/milair_training/{colab_config['name']}/weights/best.pt\",\n",
        "    f\"/content/runs/detect/{colab_config['name']}/weights/best.pt\"\n",
        "]\n",
        "\n",
        "best_model = None\n",
        "for model_path in best_model_paths:\n",
        "    if os.path.exists(model_path):\n",
        "        best_model = YOLO(model_path)\n",
        "        print(f\"‚úÖ Loaded best model from: {model_path}\")\n",
        "        break\n",
        "\n",
        "if best_model is None:\n",
        "    print(\"‚ö†Ô∏è Best model not found, using last trained model\")\n",
        "    best_model = model\n",
        "\n",
        "# Validate on validation set\n",
        "print(\"\\nüîç Validating model on validation set...\")\n",
        "metrics = best_model.val(\n",
        "    data=YAML_PATH,\n",
        "    split='val',\n",
        "    conf=0.25,\n",
        "    iou=0.45,\n",
        "    device=colab_config['device'],\n",
        "    verbose=True\n",
        ")\n",
        "\n",
        "# Print key metrics\n",
        "if hasattr(metrics, 'box'):\n",
        "    print(f\"\\nüìà Key Metrics:\")\n",
        "    print(f\"   mAP50: {metrics.box.map50:.4f}\")\n",
        "    print(f\"   mAP50-95: {metrics.box.map:.4f}\")"
      ],
      "metadata": {
        "id": "gLpgM_4pH48k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **8. Visualize Predictions**"
      ],
      "metadata": {
        "id": "UBb2wmOmJyTL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def visualize_predictions_colab(num_images=6):\n",
        "    \"\"\"Visualize predictions on test images\"\"\"\n",
        "\n",
        "    # Get test images\n",
        "    test_img_dir = os.path.join(WORKING_DIR, \"images/test\")\n",
        "    if not os.path.exists(test_img_dir):\n",
        "        test_img_dir = os.path.join(WORKING_DIR, \"images/val\")\n",
        "\n",
        "    image_files = glob.glob(os.path.join(test_img_dir, \"*\"))\n",
        "\n",
        "    if not image_files:\n",
        "        print(\"‚ùå No test images found\")\n",
        "        return\n",
        "\n",
        "    # Select random images\n",
        "    selected_images = random.sample(image_files, min(num_images, len(image_files)))\n",
        "\n",
        "    # Run predictions\n",
        "    print(f\"üîç Running predictions on {len(selected_images)} images...\")\n",
        "    results = best_model.predict(\n",
        "        source=selected_images,\n",
        "        conf=0.25,\n",
        "        iou=0.45,\n",
        "        save=False,\n",
        "        save_txt=False,\n",
        "        verbose=False\n",
        "    )\n",
        "\n",
        "    # Create visualization\n",
        "    fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
        "    axes = axes.ravel()\n",
        "\n",
        "    colors = plt.cm.tab10(np.linspace(0, 1, len(CLASS_NAMES)))\n",
        "\n",
        "    for idx, (result, img_path) in enumerate(zip(results, selected_images)):\n",
        "        if idx >= 6:\n",
        "            break\n",
        "\n",
        "        # Load image\n",
        "        img = cv2.imread(img_path)\n",
        "        if img is None:\n",
        "            continue\n",
        "\n",
        "        img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "        # Draw predictions\n",
        "        if result.boxes is not None:\n",
        "            for box in result.boxes.cpu().numpy():\n",
        "                cls_id = int(box.cls[0])\n",
        "                conf = box.conf[0]\n",
        "                bbox = box.xyxy[0].astype(int)\n",
        "\n",
        "                color = colors[cls_id % len(colors)]\n",
        "                color_rgb = (int(color[0]*255), int(color[1]*255), int(color[2]*255))\n",
        "\n",
        "                # Draw bounding box\n",
        "                cv2.rectangle(img_rgb, (bbox[0], bbox[1]), (bbox[2], bbox[3]),\n",
        "                            color_rgb, 3)\n",
        "\n",
        "                # Draw label\n",
        "                label = f\"{CLASS_NAMES[cls_id]}: {conf:.2f}\"\n",
        "                cv2.putText(img_rgb, label, (bbox[0], bbox[1]-10),\n",
        "                          cv2.FONT_HERSHEY_SIMPLEX, 0.8, color_rgb, 2)\n",
        "\n",
        "        axes[idx].imshow(img_rgb)\n",
        "        axes[idx].axis('off')\n",
        "        img_name = os.path.basename(img_path)\n",
        "        detections = len(result.boxes) if result.boxes is not None else 0\n",
        "        axes[idx].set_title(f'{img_name}\\nDetections: {detections}', fontsize=10)\n",
        "\n",
        "    plt.suptitle('MilAir Dataset - YOLOv8 Predictions', fontsize=16, fontweight='bold')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    return results\n",
        "\n",
        "# Run visualization\n",
        "prediction_results = visualize_predictions_colab(6)"
      ],
      "metadata": {
        "id": "L8Imz88JICwb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **9. Save Results to Google Drive**"
      ],
      "metadata": {
        "id": "dSVEavOlJ3OM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# üíæ SAVE RESULTS TO GOOGLE DRIVE\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"üíæ SAVING RESULTS TO GOOGLE DRIVE\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "def save_to_drive():\n",
        "    \"\"\"Save all results to Google Drive\"\"\"\n",
        "\n",
        "    # Create results directory in Drive\n",
        "    drive_results_dir = \"/content/drive/MyDrive/milair_results\"\n",
        "    os.makedirs(drive_results_dir, exist_ok=True)\n",
        "\n",
        "    # Items to save\n",
        "    items_to_save = [\n",
        "        (WORKING_DIR, \"dataset\"),\n",
        "        (f\"{colab_config['project']}/{colab_config['name']}\", \"training_results\"),\n",
        "    ]\n",
        "\n",
        "    for source_path, dest_name in items_to_save:\n",
        "        if os.path.exists(source_path):\n",
        "            dest_path = os.path.join(drive_results_dir, dest_name)\n",
        "\n",
        "            # Remove existing if present\n",
        "            if os.path.exists(dest_path):\n",
        "                shutil.rmtree(dest_path)\n",
        "\n",
        "            # Copy\n",
        "            shutil.copytree(source_path, dest_path)\n",
        "            print(f\"‚úÖ Saved: {dest_name}\")\n",
        "\n",
        "    # Save model separately\n",
        "    model_dest = os.path.join(drive_results_dir, \"best_model.pt\")\n",
        "    if best_model.ckpt_path and os.path.exists(best_model.ckpt_path):\n",
        "        shutil.copy2(best_model.ckpt_path, model_dest)\n",
        "        print(f\"‚úÖ Saved: best_model.pt\")\n",
        "\n",
        "    # Save predictions\n",
        "    pred_dir = os.path.join(drive_results_dir, \"predictions\")\n",
        "    os.makedirs(pred_dir, exist_ok=True)\n",
        "\n",
        "    test_img_dir = os.path.join(WORKING_DIR, \"images/test\")\n",
        "    if os.path.exists(test_img_dir):\n",
        "        # Run predictions and save\n",
        "        test_images = glob.glob(os.path.join(test_img_dir, \"*\"))[:10]\n",
        "\n",
        "        for img_path in test_images:\n",
        "            result = best_model.predict(img_path, save=False, verbose=False)[0]\n",
        "\n",
        "            # Save annotated image\n",
        "            img_name = os.path.basename(img_path)\n",
        "            save_path = os.path.join(pred_dir, f\"pred_{img_name}\")\n",
        "            result.save(save_path)\n",
        "\n",
        "    print(f\"\\nüéâ All results saved to: {drive_results_dir}\")\n",
        "    print(f\"üìÅ You can access them in your Google Drive\")\n",
        "\n",
        "# Save results\n",
        "save_to_drive()"
      ],
      "metadata": {
        "id": "kxSbeqJIIGAb"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}