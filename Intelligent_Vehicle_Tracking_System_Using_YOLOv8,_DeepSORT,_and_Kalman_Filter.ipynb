{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "from ultralytics import YOLO\n",
        "from filterpy.kalman import KalmanFilter\n",
        "from collections import defaultdict\n",
        "from scipy.spatial import distance_matrix\n",
        "from scipy.optimize import linear_sum_assignment\n",
        "import urllib.request\n"
      ],
      "metadata": {
        "id": "Dld3UQfx9rFO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **1- Video source configuration and Download video from Vecteezy**"
      ],
      "metadata": {
        "id": "VPsbGnut9tw8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "VIDEO_URL = \"https://www.vecteezy.com/video/20749845-traffic-jam-in-city\"\n",
        "VIDEO_PATH = \"traffic_jam.mp4\"\n",
        "\n",
        "try:\n",
        "    print(f\"Downloading traffic video from {VIDEO_URL}...\")\n",
        "    urllib.request.urlretrieve(VIDEO_URL, VIDEO_PATH)\n",
        "    print(\"Video downloaded successfully.\")\n",
        "except Exception as e:\n",
        "    print(f\"⚠️ Error downloading video: {e}\")\n",
        "    print(\"Please upload a traffic video manually.\")\n",
        "    from google.colab import files\n",
        "    uploaded = files.upload()\n",
        "    if uploaded:\n",
        "        VIDEO_PATH = list(uploaded.keys())[0]\n",
        "        print(f\"Using uploaded video: {VIDEO_PATH}\")\n",
        "    else:\n",
        "        print(\"⚠️ Error: No video provided. Using sample video.\")\n",
        "        VIDEO_PATH = \"sample_traffic.mp4\""
      ],
      "metadata": {
        "id": "jVxTRxVE92QN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **2- DeepSORT-inspired Tracker with Kalman Filter**"
      ],
      "metadata": {
        "id": "7YJnGOOP94SN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class VehicleTracker:\n",
        "    def __init__(self):\n",
        "        self.track_id = 0\n",
        "        self.tracks = {}  # Active tracks {id: bbox}\n",
        "        self.kalman_filters = {}  # Kalman filters for each track\n",
        "        self.trajectories = defaultdict(list)  # Movement history\n",
        "        self.inactive_counts = defaultdict(int)  # Frames since last detection\n",
        "        self.max_inactive = 30  # Remove tracks after this many inactive frames\n",
        "        self.max_trajectory = 50  # Max points to store per trajectory\n",
        "        self.vehicle_classes = {2, 5, 7}  # COCO classes: car, bus, truck\n",
        "\n",
        "    def update(self, detections):\n",
        "        # Convert detections to numpy array and filter vehicles\n",
        "        dets = np.array([d for d in detections if d[5] in self.vehicle_classes])\n",
        "\n",
        "        # Initialize updated tracks and matched indices\n",
        "        updated_tracks = {}\n",
        "        active_ids = set()\n",
        "        matched_det_indices = set()\n",
        "\n",
        "        # Only process if we have detections\n",
        "        if len(dets) > 0:\n",
        "            # Step 1: Match existing tracks with detections\n",
        "            if len(self.tracks) > 0:\n",
        "                # Calculate centers for distance matching\n",
        "                track_centers = np.array([[(t[0]+t[2])/2, (t[1]+t[3])/2]\n",
        "                                         for t in self.tracks.values()])\n",
        "                det_centers = np.array([[(d[0]+d[2])/2, (d[1]+d[3])/2]\n",
        "                                      for d in dets])\n",
        "\n",
        "                # Compute cost matrix and solve assignment problem\n",
        "                cost_matrix = distance_matrix(track_centers, det_centers)\n",
        "                row_ind, col_ind = linear_sum_assignment(cost_matrix)\n",
        "\n",
        "                # Process matches\n",
        "                for i, j in zip(row_ind, col_ind):\n",
        "                    if cost_matrix[i, j] < 100:  # Maximum allowed distance\n",
        "                        tid = list(self.tracks.keys())[i]\n",
        "                        updated_tracks[tid] = dets[j][:4]\n",
        "                        active_ids.add(tid)\n",
        "                        matched_det_indices.add(j)\n",
        "\n",
        "                        # Update Kalman filter\n",
        "                        center = [(dets[j][0]+dets[j][2])/2, (dets[j][1]+dets[j][3])/2]\n",
        "                        kf = self.kalman_filters[tid]\n",
        "                        kf.predict()\n",
        "                        kf.update(np.array(center))\n",
        "\n",
        "                        # Update trajectory\n",
        "                        self.trajectories[tid].append(center)\n",
        "                        if len(self.trajectories[tid]) > self.max_trajectory:\n",
        "                            self.trajectories[tid].pop(0)\n",
        "\n",
        "                        self.inactive_counts[tid] = 0\n",
        "\n",
        "            # Step 2: Create new tracks for unmatched detections\n",
        "            for j in range(len(dets)):\n",
        "                if j not in matched_det_indices:\n",
        "                    self.track_id += 1\n",
        "                    tid = self.track_id\n",
        "                    updated_tracks[tid] = dets[j][:4]\n",
        "                    active_ids.add(tid)\n",
        "\n",
        "                    # Initialize Kalman filter\n",
        "                    center = [(dets[j][0]+dets[j][2])/2, (dets[j][1]+dets[j][3])/2]\n",
        "                    kf = KalmanFilter(dim_x=4, dim_z=2)\n",
        "                    kf.F = np.array([[1,0,1,0], [0,1,0,1], [0,0,1,0], [0,0,0,1]])  # State transition\n",
        "                    kf.H = np.array([[1,0,0,0], [0,1,0,0]])  # Measurement function\n",
        "                    kf.P *= 1000  # Covariance matrix\n",
        "                    kf.R = np.array([[5,0], [0,5]])  # Measurement noise\n",
        "                    kf.Q = np.eye(4) * 0.01  # Process noise\n",
        "                    kf.x = np.array([center[0], center[1], 0, 0])  # Initial state\n",
        "\n",
        "                    self.kalman_filters[tid] = kf\n",
        "                    self.trajectories[tid].append(center)\n",
        "                    self.inactive_counts[tid] = 0\n",
        "\n",
        "        # Update tracks and remove inactive ones\n",
        "        self.tracks = updated_tracks\n",
        "        self._remove_inactive_tracks()\n",
        "\n",
        "        return self.tracks, self.kalman_filters, self.trajectories\n",
        "\n",
        "    def _remove_inactive_tracks(self):\n",
        "        for tid in list(self.tracks.keys()):\n",
        "            self.inactive_counts[tid] += 1\n",
        "            if self.inactive_counts[tid] > self.max_inactive:\n",
        "                del self.tracks[tid]\n",
        "                del self.kalman_filters[tid]\n",
        "                del self.trajectories[tid]\n",
        "                del self.inactive_counts[tid]"
      ],
      "metadata": {
        "id": "ExBY3IGp-Net"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **3- Initialize YOLOv8 model and tracker**"
      ],
      "metadata": {
        "id": "JJ40Fjyc-V-M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = YOLO('yolov8n.pt')  # Using nano version for Colab compatibility\n",
        "cap = cv2.VideoCapture(VIDEO_PATH)\n",
        "if not cap.isOpened():\n",
        "    raise IOError(\"Cannot open video file\")\n",
        "\n",
        "frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "if fps <= 0:\n",
        "    fps = 30  # Default FPS if not detected\n",
        "\n",
        "tracker = VehicleTracker()  # Initialize tracker without frame_height"
      ],
      "metadata": {
        "id": "kp4MAE32-ded"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **4- Output video writer**"
      ],
      "metadata": {
        "id": "_Wl5AWql-gEN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "output_path = \"tracking_output.mp4\"\n",
        "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "out = cv2.VideoWriter(output_path, fourcc, fps, (frame_width, frame_height))"
      ],
      "metadata": {
        "id": "ehnWzU3Q-kot"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **5- Visualization settings**"
      ],
      "metadata": {
        "id": "BdgRtuyT-nTu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "COLORS = {\n",
        "    'car': (0, 255, 0),      # Green\n",
        "    'bus': (0, 165, 255),    # Orange\n",
        "    'truck': (0, 0, 255),    # Red\n",
        "    'trajectory': (255, 255, 0),  # Yellow\n",
        "    'prediction': (255, 0, 255)   # Purple\n",
        "}\n",
        "\n",
        "CLASS_NAMES = {\n",
        "    2: 'car',\n",
        "    5: 'bus',\n",
        "    7: 'truck'\n",
        "}"
      ],
      "metadata": {
        "id": "M2pMHNHR-nGV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **6-Main processing loop**"
      ],
      "metadata": {
        "id": "wP3VZ_jm-whd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "frame_count = 0\n",
        "try:\n",
        "    while cap.isOpened():\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "\n",
        "        frame_count += 1\n",
        "        print(f\"Processing frame {frame_count}...\")\n",
        "\n",
        "        # Run YOLO detection\n",
        "        results = model(frame, conf=0.3, verbose=False)  # Lower confidence for busy traffic\n",
        "\n",
        "        # Prepare detections [x1, y1, x2, y2, conf, class]\n",
        "        detections = []\n",
        "        for result in results:\n",
        "            for box in result.boxes:\n",
        "                x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
        "                conf = box.conf.item()\n",
        "                cls = box.cls.item()\n",
        "                detections.append([x1, y1, x2, y2, conf, cls])\n",
        "\n",
        "        # Update tracker\n",
        "        tracks, kfs, trajectories = tracker.update(detections)\n",
        "\n",
        "        # Visualization\n",
        "        for tid, bbox in tracks.items():\n",
        "            x1, y1, x2, y2 = map(int, bbox)\n",
        "\n",
        "            # Get vehicle class (use last detection's class)\n",
        "            class_id = None\n",
        "            for det in detections:\n",
        "                if (abs((det[0]+det[2])/2 - (x1+x2)/2) < 10 and\n",
        "                    abs((det[1]+det[3])/2 - (y1+y2)/2) < 10):\n",
        "                    class_id = int(det[5])\n",
        "                    break\n",
        "\n",
        "            color = COLORS.get(CLASS_NAMES.get(class_id, 'car'), (0, 255, 0))\n",
        "\n",
        "            # Draw bounding box\n",
        "            cv2.rectangle(frame, (x1, y1), (x2, y2), color, 2)\n",
        "            cv2.putText(frame, f\"{CLASS_NAMES.get(class_id, 'vehicle')} {tid}\",\n",
        "                        (x1, y1-10), cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 2)\n",
        "\n",
        "            # Draw trajectory\n",
        "            if tid in trajectories:\n",
        "                trajectory = trajectories[tid]\n",
        "                for i in range(1, len(trajectory)):\n",
        "                    cv2.line(frame,\n",
        "                            (int(trajectory[i-1][0]), int(trajectory[i-1][1])),\n",
        "                            (int(trajectory[i][0]), int(trajectory[i][1])),\n",
        "                            COLORS['trajectory'], 2)\n",
        "\n",
        "            # Draw Kalman filter prediction\n",
        "            if tid in kfs:\n",
        "                kf = kfs[tid]\n",
        "                pred_x, pred_y = int(kf.x[0]), int(kf.x[1])\n",
        "                cv2.circle(frame, (pred_x, pred_y), 5, COLORS['prediction'], -1)\n",
        "                vel_x, vel_y = int(kf.x[2]), int(kf.x[3])\n",
        "                cv2.arrowedLine(frame, (pred_x, pred_y),\n",
        "                               (pred_x + vel_x*5, pred_y + vel_y*5),\n",
        "                               COLORS['prediction'], 2, tipLength=0.3)\n",
        "\n",
        "        # Display vehicle count\n",
        "        cv2.putText(frame, f\"Vehicles: {len(tracks)}\", (20, 40),\n",
        "                   cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
        "\n",
        "        # Write frame to output\n",
        "        out.write(frame)\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"Error during processing: {e}\")\n",
        "finally:\n",
        "    cap.release()\n",
        "    out.release()\n",
        "    print(\"Processing completed. Saving output video...\")\n",
        "\n",
        "# Download the output video\n",
        "if os.path.exists(output_path):\n",
        "    print(f\"Output video saved to {output_path}\")\n",
        "    from google.colab import files\n",
        "    files.download(output_path)\n",
        "else:\n",
        "    print(\"Error: Output video not created\")"
      ],
      "metadata": {
        "id": "lJgavpDh-3_8"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}