{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import logging\n",
        "import sys\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "import gc\n",
        "from pathlib import Path\n",
        "from diffusers import DiffusionPipeline\n",
        "import textwrap\n",
        "import requests\n",
        "import shutil\n",
        "import subprocess\n",
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "6S6SerUPyuUn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Configure memory optimization\n",
        "os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'expandable_segments:True'\n",
        "\n",
        "# Setup logging\n",
        "logging.basicConfig(level=logging.INFO)\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "def check_dependencies():\n",
        "    \"\"\"Verify all required Python packages are installed\"\"\"\n",
        "    required = ['torch', 'diffusers', 'transformers', 'matplotlib', 'imageio', 'xformers']\n",
        "    for module in required:\n",
        "        try:\n",
        "            __import__(module)\n",
        "        except ImportError:\n",
        "            raise ImportError(f\"Required module {module} is not installed. Please install it.\")\n",
        "\n",
        "def clean_memory():\n",
        "    \"\"\"Clear GPU memory and perform garbage collection\"\"\"\n",
        "    torch.cuda.empty_cache()\n",
        "    gc.collect()\n",
        "\n",
        "def check_model_availability(url: str) -> bool:\n",
        "    \"\"\"Verify if a model URL is accessible\"\"\"\n",
        "    try:\n",
        "        response = requests.head(url, timeout=5)\n",
        "        return response.status_code == 200\n",
        "    except requests.RequestException:\n",
        "        return False"
      ],
      "metadata": {
        "id": "gr9URmG9yyf3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Device setup\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "dtype = torch.float16 if torch.cuda.is_available() else torch.float32\n",
        "logger.info(f\"Using device: {device} ({dtype})\")\n",
        "\n",
        "class FaceGenerator:\n",
        "    def __init__(self, low_memory_mode: bool = True):\n",
        "        \"\"\"Initialize the face generator with memory optimization options\"\"\"\n",
        "        check_dependencies()\n",
        "        self.models = {}\n",
        "        self.low_memory_mode = low_memory_mode\n",
        "        self._setup_stylegan_paths()\n",
        "\n",
        "    def _setup_stylegan_paths(self):\n",
        "        \"\"\"Configure StyleGAN2 paths with error handling\"\"\"\n",
        "        stylegan2_path = Path.cwd() / \"stylegan2-ada-pytorch\"\n",
        "        if not stylegan2_path.exists():\n",
        "            raise FileNotFoundError(\"StyleGAN2 repository not found. Ensure it is cloned.\")\n",
        "        sys.path.insert(0, str(stylegan2_path))\n",
        "        global dnnlib, legacy\n",
        "        try:\n",
        "            import dnnlib\n",
        "            import legacy\n",
        "        except ImportError as e:\n",
        "            logger.error(f\"StyleGAN setup error: {str(e)}\")\n",
        "            raise\n",
        "\n",
        "    def _load_diffusion_model(self, model_name: str):\n",
        "        \"\"\"Load diffusion models with memory optimization\"\"\"\n",
        "        if model_name in self.models and self.models[model_name] is not None:\n",
        "            return self.models[model_name]\n",
        "\n",
        "        model_config = {\n",
        "            \"realvisxl\": {\n",
        "                \"repo\": \"SG161222/RealVisXL_V5.0\",\n",
        "                \"variant\": \"fp16\",\n",
        "                \"enable_xformers\": True\n",
        "            },\n",
        "            \"sdxl\": {\n",
        "                \"repo\": \"stabilityai/stable-diffusion-xl-base-1.0\",\n",
        "                \"variant\": \"fp16\",\n",
        "                \"enable_xformers\": True,\n",
        "                \"low_memory\": True\n",
        "            }\n",
        "        }\n",
        "\n",
        "        clean_memory()\n",
        "        logger.info(f\"Loading {model_name}...\")\n",
        "\n",
        "        try:\n",
        "            # Special handling for SDXL in low memory mode\n",
        "            if model_name == \"sdxl\" and self.low_memory_mode:\n",
        "                pipe = DiffusionPipeline.from_pretrained(\n",
        "                    model_config[model_name][\"repo\"],\n",
        "                    torch_dtype=dtype,\n",
        "                    variant=model_config[model_name][\"variant\"],\n",
        "                    use_safetensors=True\n",
        "                )\n",
        "\n",
        "                # Enable sequential CPU offload for memory optimization\n",
        "                pipe.enable_model_cpu_offload()\n",
        "                pipe.enable_sequential_cpu_offload()\n",
        "            else:\n",
        "                pipe = DiffusionPipeline.from_pretrained(\n",
        "                    model_config[model_name][\"repo\"],\n",
        "                    torch_dtype=dtype,\n",
        "                    variant=model_config[model_name][\"variant\"],\n",
        "                    use_safetensors=True\n",
        "                ).to(device)\n",
        "\n",
        "                if model_config[model_name][\"enable_xformers\"] and device.type == 'cuda':\n",
        "                    pipe.enable_xformers_memory_efficient_attention()\n",
        "\n",
        "            self.models[model_name] = pipe\n",
        "            return pipe\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Failed to load {model_name}: {str(e)}\")\n",
        "            return None\n",
        "\n",
        "    def _load_gan_model(self):\n",
        "        \"\"\"Load StyleGAN2 model with error handling\"\"\"\n",
        "        model_name = \"stylegan2\"\n",
        "        if model_name in self.models and self.models[model_name] is not None:\n",
        "            return self.models[model_name]\n",
        "\n",
        "        model_url = \"https://nvlabs-fi-cdn.nvidia.com/stylegan2-ada-pytorch/pretrained/ffhq.pkl\"\n",
        "\n",
        "        if not check_model_availability(model_url):\n",
        "            logger.error(\"StyleGAN2 model URL is not accessible.\")\n",
        "            return None\n",
        "\n",
        "        clean_memory()\n",
        "        logger.info(\"Loading StyleGAN2...\")\n",
        "\n",
        "        try:\n",
        "            with dnnlib.util.open_url(model_url) as f:\n",
        "                model = legacy.load_network_pkl(f)[\"G_ema\"].to(device)\n",
        "            self.models[model_name] = model\n",
        "            return model\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Failed to load StyleGAN2: {str(e)}\")\n",
        "            return None\n",
        "\n",
        "    def generate_images(self,\n",
        "                       prompt: str = \"Professional portrait photo, detailed facial features, 8k\",\n",
        "                       width: int = 768,\n",
        "                       height: int = 768,\n",
        "                       num_inference_steps: int = 25,\n",
        "                       guidance_scale: float = 7.5) -> dict:\n",
        "        \"\"\"Generate and compare images from three models with memory optimization\"\"\"\n",
        "        results = {}\n",
        "\n",
        "        # Generate with RealVisXL first (most memory efficient)\n",
        "        if \"realvisxl\" not in self.models:\n",
        "            self.models[\"realvisxl\"] = self._load_diffusion_model(\"realvisxl\")\n",
        "\n",
        "        if self.models[\"realvisxl\"]:\n",
        "            logger.info(\"Generating image with RealVisXL...\")\n",
        "            results[\"realvisxl\"] = self._generate_diffusion_image(\n",
        "                \"realvisxl\", prompt, width, height, num_inference_steps, guidance_scale)\n",
        "            clean_memory()\n",
        "\n",
        "        # Generate with SDXL (memory intensive)\n",
        "        if \"sdxl\" not in self.models:\n",
        "            self.models[\"sdxl\"] = self._load_diffusion_model(\"sdxl\")\n",
        "\n",
        "        if self.models[\"sdxl\"]:\n",
        "            logger.info(\"Generating image with SDXL (this may take more memory)...\")\n",
        "            results[\"sdxl\"] = self._generate_diffusion_image(\n",
        "                \"sdxl\", prompt, width, height, num_inference_steps, guidance_scale)\n",
        "            clean_memory()\n",
        "\n",
        "        # Generate with StyleGAN2 last (least memory intensive)\n",
        "        if \"stylegan2\" not in self.models:\n",
        "            self.models[\"stylegan2\"] = self._load_gan_model()\n",
        "\n",
        "        if self.models[\"stylegan2\"]:\n",
        "            logger.info(\"Generating image with StyleGAN2...\")\n",
        "            results[\"stylegan2\"] = self._generate_gan_image()\n",
        "            clean_memory()\n",
        "\n",
        "        return results\n",
        "\n",
        "    def _generate_diffusion_image(self,\n",
        "                                model_name: str,\n",
        "                                prompt: str,\n",
        "                                width: int,\n",
        "                                height: int,\n",
        "                                num_inference_steps: int,\n",
        "                                guidance_scale: float) -> Image.Image:\n",
        "        \"\"\"Generate image from diffusion model with memory protection\"\"\"\n",
        "        try:\n",
        "            # Reduce memory footprint for SDXL\n",
        "            if model_name == \"sdxl\" and self.low_memory_mode:\n",
        "                return self.models[model_name](\n",
        "                    prompt=prompt,\n",
        "                    width=width,\n",
        "                    height=height,\n",
        "                    num_inference_steps=num_inference_steps,\n",
        "                    guidance_scale=guidance_scale,\n",
        "                    generator=torch.Generator(device=\"cpu\")  # Reduce GPU memory usage\n",
        "                ).images[0]\n",
        "            else:\n",
        "                return self.models[model_name](\n",
        "                    prompt=prompt,\n",
        "                    width=width,\n",
        "                    height=height,\n",
        "                    num_inference_steps=num_inference_steps,\n",
        "                    guidance_scale=guidance_scale\n",
        "                ).images[0]\n",
        "        except torch.cuda.OutOfMemoryError:\n",
        "            logger.warning(f\"Out of memory during {model_name} generation. Retrying with lower resolution...\")\n",
        "            clean_memory()\n",
        "            try:\n",
        "                return self.models[model_name](\n",
        "                    prompt=prompt,\n",
        "                    width=512,\n",
        "                    height=512,\n",
        "                    num_inference_steps=num_inference_steps,\n",
        "                    guidance_scale=guidance_scale\n",
        "                ).images[0]\n",
        "            except Exception as e:\n",
        "                logger.error(f\"Generation failed for {model_name}: {str(e)}\")\n",
        "                return None\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Generation failed for {model_name}: {str(e)}\")\n",
        "            return None\n",
        "\n",
        "    def _generate_gan_image(self) -> Image.Image:\n",
        "        \"\"\"Generate image from StyleGAN2 model\"\"\"\n",
        "        try:\n",
        "            model = self.models[\"stylegan2\"]\n",
        "            z = torch.randn([1, model.z_dim]).to(device)\n",
        "            with torch.no_grad():\n",
        "                img = model(z, None, truncation_psi=0.7)\n",
        "                img = (img.permute(0, 2, 3, 1) * 127.5 + 128).clamp(0, 255).to(torch.uint8)\n",
        "            return Image.fromarray(img[0].cpu().numpy())\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Generation failed for StyleGAN2: {str(e)}\")\n",
        "            return None\n",
        "\n",
        "    def visualize_results(self, results: dict, prompt: str):\n",
        "        \"\"\"Display comparison results for three models\"\"\"\n",
        "        valid_results = {k: v for k, v in results.items() if v is not None}\n",
        "        if not valid_results:\n",
        "            logger.warning(\"No images generated. Skipping visualization.\")\n",
        "            return\n",
        "\n",
        "        model_names = {\n",
        "            \"realvisxl\": \"RealVisXL V5.0\",\n",
        "            \"sdxl\": \"Stable Diffusion XL\",\n",
        "            \"stylegan2\": \"StyleGAN2-ADA\"\n",
        "        }\n",
        "\n",
        "        plt.figure(figsize=(15, 5))\n",
        "\n",
        "        for idx, (model_key, model_name) in enumerate(model_names.items(), 1):\n",
        "            if model_key in valid_results:\n",
        "                plt.subplot(1, 3, idx)\n",
        "                plt.imshow(valid_results[model_key])\n",
        "                plt.title(model_name, fontsize=12)\n",
        "                plt.axis('off')\n",
        "                valid_results[model_key].save(f\"{model_key}_output.png\")\n",
        "\n",
        "        plt.suptitle(textwrap.shorten(prompt, width=100, placeholder=\"...\"), y=1.05)\n",
        "        plt.tight_layout()\n",
        "        plt.show()"
      ],
      "metadata": {
        "id": "e482NLwiy6Af"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    try:\n",
        "        # Initialize with low memory mode enabled\n",
        "        generator = FaceGenerator(low_memory_mode=True)\n",
        "\n",
        "        prompt = \"High-quality portrait of man photo with detailed facial features, professional photography, 8k\"\n",
        "\n",
        "        # Generate images with automatic memory management\n",
        "        results = generator.generate_images(\n",
        "            prompt=prompt,\n",
        "            width=768,  # Will automatically reduce if OOM occurs\n",
        "            height=768,\n",
        "            num_inference_steps=25,\n",
        "            guidance_scale=7.5\n",
        "        )\n",
        "\n",
        "        # Visualize results\n",
        "        generator.visualize_results(results, prompt)\n",
        "\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Fatal error: {str(e)}\")\n",
        "        logger.info(\"Please check your setup and try again\")"
      ],
      "metadata": {
        "id": "vn-GdVfZrY6H"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}