{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Install Required Libraries"
      ],
      "metadata": {
        "id": "b5fzf4iYZyXX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q transformers==4.44.2 datasets torch scikit-learn pandas numpy matplotlib seaborn tqdm huggingface_hub"
      ],
      "metadata": {
        "id": "eBPxhnDVZ58W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Hugging Face Login (if you have a HuggingFace account)"
      ],
      "metadata": {
        "id": "yvdqn9b9acX-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import notebook_login\n",
        "notebook_login()"
      ],
      "metadata": {
        "id": "q_zGO8eLahNW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Imports & Setup"
      ],
      "metadata": {
        "id": "Kqgtc9wJakX-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import random\n",
        "import torch\n",
        "from tqdm.notebook import tqdm\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, confusion_matrix, f1_score, precision_score, recall_score, roc_curve, auc\n",
        "from transformers import (\n",
        "    AutoTokenizer, AutoModelForSequenceClassification,\n",
        "    AutoModelForCausalLM, TrainingArguments, Trainer, EarlyStoppingCallback, DistilBertConfig\n",
        ")\n",
        "from datasets import Dataset, load_dataset\n",
        "import re\n",
        "import warnings\n",
        "import os\n",
        "warnings.filterwarnings('ignore')\n",
        "os.environ[\"WANDB_DISABLED\"] = \"true\""
      ],
      "metadata": {
        "id": "g06x6Tigajem"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Device configuration"
      ],
      "metadata": {
        "id": "y_mAQqYfatiX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "if torch.cuda.is_available():\n",
        "    torch.backends.cuda.matmul.allow_tf32 = True\n",
        "    torch.backends.cudnn.allow_tf32 = True\n",
        "    print(\"GPU:\", torch.cuda.get_device_name(0),\n",
        "          f\"({torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB)\")\n",
        "print(\"Using device:\", device)"
      ],
      "metadata": {
        "id": "nzZ_lzOdav0F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5. Set random seeds for reproducibility"
      ],
      "metadata": {
        "id": "OcZhb2RSax4W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "random.seed(42)\n",
        "np.random.seed(42)\n",
        "torch.manual_seed(42)\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed_all(42)"
      ],
      "metadata": {
        "id": "6ZEaR-gHa0S-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6. Load Dataset from HuggingFace"
      ],
      "metadata": {
        "id": "w8Q7Jftua2Eg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Loading dataset...\")\n",
        "dataset = load_dataset(\"zefang-liu/phishing-email-dataset\", split='train')\n",
        "df = dataset.to_pandas()\n",
        "print(\"Raw dataset shape:\", df.shape)\n",
        "print(\"Email Type unique values:\", df['Email Type'].unique())\n",
        "print(\"\\nLabel distribution before cleaning:\\n\", df['Email Type'].value_counts())"
      ],
      "metadata": {
        "id": "e_NWc1NKa38W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 7. Label mapping (robust for any label names)"
      ],
      "metadata": {
        "id": "BN9RJrF9a6l2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "label_map = {name: i for i, name in enumerate(df['Email Type'].unique())}\n",
        "df['label'] = df['Email Type'].map(label_map)\n",
        "print(\"Label mapping used:\", label_map)\n",
        "print(\"Labels after mapping:\", df['label'].value_counts(dropna=False))"
      ],
      "metadata": {
        "id": "SkDVwn44a8ov"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 8. Enhanced Preprocessing"
      ],
      "metadata": {
        "id": "RVe97WmZbGq2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "_url_re = re.compile(r'http\\S+|www\\S+|https\\S+', flags=re.MULTILINE)\n",
        "_email_re = re.compile(r'\\S+@\\S+')\n",
        "_special_re = re.compile(r'[^a-zA-Z\\s\\.\\?\\!]')\n",
        "_spaces_re = re.compile(r'\\s+')\n",
        "\n",
        "def preprocess_text(text):\n",
        "    if not isinstance(text, str):\n",
        "        return \"\"\n",
        "    text = text.lower().strip()\n",
        "    text = _url_re.sub(' [URL] ', text)\n",
        "    text = _email_re.sub(' [EMAIL] ', text)\n",
        "    text = _special_re.sub(' ', text)\n",
        "    text = _spaces_re.sub(' ', text).strip()\n",
        "    return text"
      ],
      "metadata": {
        "id": "BCmcNGi8bI0u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 9. Apply preprocessing"
      ],
      "metadata": {
        "id": "zJXp1G4BbLAf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['Email Text'] = df['Email Text'].apply(preprocess_text)"
      ],
      "metadata": {
        "id": "_B8M4R8BbNbm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 10. Data cleaning"
      ],
      "metadata": {
        "id": "svTkCPS5bPZW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Before label cleaning:\", df.shape)\n",
        "df = df.dropna(subset=['label'])\n",
        "print(\"After label cleaning:\", df.shape)\n",
        "df = df[df['Email Text'].str.len() > 10].reset_index(drop=True)\n",
        "print(\"After removing short texts:\", df.shape)\n",
        "print(\"NaN in label:\", df['label'].isna().sum())\n",
        "print(\"NaN in text:\", df['Email Text'].isna().sum())"
      ],
      "metadata": {
        "id": "7O3RjoQbbRrO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 11. Train-Test Split"
      ],
      "metadata": {
        "id": "Irg69uZjbTN-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_df, test_df = train_test_split(\n",
        "    df[['Email Text', 'label']],\n",
        "    test_size=0.2,\n",
        "    random_state=42,\n",
        "    stratify=df['label']\n",
        ")\n",
        "print(f\"Train size: {len(train_df)}, Test size: {len(test_df)}\")\n",
        "print(\"Sample preprocessed email:\\n\", train_df['Email Text'].iloc[0][:200], \"...\")"
      ],
      "metadata": {
        "id": "bEunnLBUbWZm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 12. Data Augmentation with DistilGPT2 (Colab-optimized)"
      ],
      "metadata": {
        "id": "3NDKOAgJbZZm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nLoading DistilGPT2 for data augmentation...\")\n",
        "gen_model_name = 'distilgpt2'\n",
        "gen_tokenizer = AutoTokenizer.from_pretrained(gen_model_name)\n",
        "gen_tokenizer.pad_token = gen_tokenizer.eos_token\n",
        "gen_model = AutoModelForCausalLM.from_pretrained(gen_model_name).to(device)\n",
        "for param in gen_model.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "def generate_email(prompt, max_length=100, temperature=0.9, top_p=0.9):\n",
        "    inputs = gen_tokenizer.encode(prompt, return_tensors='pt').to(device)\n",
        "    with torch.no_grad():\n",
        "        outputs = gen_model.generate(\n",
        "            inputs,\n",
        "            max_length=max_length,\n",
        "            temperature=temperature,\n",
        "            do_sample=True,\n",
        "            top_p=top_p,\n",
        "            pad_token_id=gen_tokenizer.eos_token_id,\n",
        "            repetition_penalty=1.2,\n",
        "            num_return_sequences=1\n",
        "        )\n",
        "    generated = gen_tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "    return generated[len(prompt):].strip()\n",
        "\n",
        "phishing_prompts = [\n",
        "    \"Urgent: Your account security has been compromised. Please verify your identity immediately at: \",\n",
        "    \"Important: Unusual login activity detected on your account. Confirm your details here: \",\n",
        "    \"Alert: Your subscription payment failed. Update your payment information now: \"\n",
        "]\n",
        "safe_prompts = [\n",
        "    \"Hello, here's our monthly newsletter with updates on our services. \",\n",
        "    \"Thank you for your recent inquiry. We'll get back to you within 24 hours. \",\n",
        "    \"Reminder: Your upcoming appointment is scheduled for tomorrow at 3 PM. \"\n",
        "]\n",
        "\n",
        "num_aug = 60  # Reduced for Colab memory\n",
        "\n",
        "print(\"Generating augmented phishing emails...\")\n",
        "aug_phishing = []\n",
        "for prompt in phishing_prompts:\n",
        "    for _ in tqdm(range(num_aug // len(phishing_prompts)), desc=f'Phishing: {prompt[:20]}'):\n",
        "        try:\n",
        "            aug_text = generate_email(prompt, max_length=80)\n",
        "            aug_phishing.append(prompt + aug_text)\n",
        "        except Exception as e:\n",
        "            print(\"Error:\", e)\n",
        "\n",
        "print(\"Generating augmented safe emails...\")\n",
        "aug_safe = []\n",
        "for prompt in safe_prompts:\n",
        "    for _ in tqdm(range(num_aug // len(safe_prompts)), desc=f'Safe: {prompt[:20]}'):\n",
        "        try:\n",
        "            aug_text = generate_email(prompt, max_length=80)\n",
        "            aug_safe.append(prompt + aug_text)\n",
        "        except Exception as e:\n",
        "            print(\"Error:\", e)\n",
        "\n",
        "aug_phishing_df = pd.DataFrame({'Email Text': aug_phishing, 'label': label_map.get('Phishing Email', 1)})\n",
        "aug_safe_df = pd.DataFrame({'Email Text': aug_safe, 'label': label_map.get('Safe Email', 0)})\n",
        "train_aug_df = pd.concat([train_df, aug_phishing_df, aug_safe_df], ignore_index=True)\n",
        "train_aug_df = train_aug_df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "print(\"Augmented train size:\", len(train_aug_df))\n",
        "print(\"Sample augmented phishing:\\n\", aug_phishing_df['Email Text'].iloc[0][:200], \"...\")"
      ],
      "metadata": {
        "id": "wyU_ytBNbgA-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 13. Visualization"
      ],
      "metadata": {
        "id": "uHcSWnBzbiIe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10, 4))\n",
        "plt.subplot(1, 2, 1)\n",
        "sns.countplot(data=df, x='label')\n",
        "plt.title('Original: Phishing (1) vs Safe (0)')\n",
        "plt.subplot(1, 2, 2)\n",
        "sns.countplot(data=train_aug_df, x='label')\n",
        "plt.title('Augmented: Phishing (1) vs Safe (0)')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "iBlIQJZubj6v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 14. Free up memory"
      ],
      "metadata": {
        "id": "77bBmFR_bm7G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "del gen_model, gen_tokenizer\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "gLkMVEw7bpIe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 15. Load DistilBERT Tokenizer and Model"
      ],
      "metadata": {
        "id": "NXA2j8SabrmG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = 'distilbert-base-uncased'\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "def tokenize_function(examples):\n",
        "    return tokenizer(\n",
        "        examples['Email Text'],\n",
        "        truncation=True,\n",
        "        padding='max_length',\n",
        "        max_length=128\n",
        "    )\n",
        "\n",
        "train_dataset = Dataset.from_pandas(train_aug_df[['Email Text', 'label']])\n",
        "test_dataset = Dataset.from_pandas(test_df[['Email Text', 'label']])\n",
        "train_dataset = train_dataset.map(tokenize_function, batched=True)\n",
        "test_dataset = test_dataset.map(tokenize_function, batched=True)\n",
        "train_dataset.set_format('torch', columns=['input_ids', 'attention_mask', 'label'])\n",
        "test_dataset.set_format('torch', columns=['input_ids', 'attention_mask', 'label'])\n",
        "print(f\"Tokenized train: {len(train_dataset)}, Test: {len(test_dataset)}\")\n",
        "\n",
        "config = DistilBertConfig.from_pretrained(\n",
        "    model_name,\n",
        "    num_labels=2,\n",
        "    hidden_dropout_prob=0.2,\n",
        "    attention_probs_dropout_prob=0.2\n",
        ")\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\n",
        "    model_name,\n",
        "    config=config\n",
        ").to(device)"
      ],
      "metadata": {
        "id": "1I5AqWFdbrE-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 16. TrainingArguments (Colab-optimized)"
      ],
      "metadata": {
        "id": "H8zJzq-ObwaX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "training_args = TrainingArguments(\n",
        "    output_dir='./phishguard-results',\n",
        "    num_train_epochs=2,\n",
        "    per_device_train_batch_size=8,     # Lowered for Colab RAM\n",
        "    per_device_eval_batch_size=16,     # Lowered for Colab RAM\n",
        "    gradient_accumulation_steps=2,\n",
        "    warmup_steps=50,\n",
        "    weight_decay=0.01,\n",
        "    logging_dir='./logs',\n",
        "    logging_steps=30,\n",
        "    evaluation_strategy='epoch',\n",
        "    save_strategy='epoch',\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model='f1',\n",
        "    greater_is_better=True,\n",
        "    report_to=None,\n",
        "    fp16=torch.cuda.is_available(),\n",
        "    dataloader_pin_memory=False,\n",
        ")"
      ],
      "metadata": {
        "id": "DmxBqDsWbyk-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 17. Metrics"
      ],
      "metadata": {
        "id": "eVUW3Yk8b0ym"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_metrics(pred):\n",
        "    labels = pred.label_ids\n",
        "    preds = pred.predictions.argmax(-1)\n",
        "    f1 = f1_score(labels, preds, average='weighted')\n",
        "    precision = precision_score(labels, preds, average='weighted', zero_division=0)\n",
        "    recall = recall_score(labels, preds, average='weighted', zero_division=0)\n",
        "    return {'f1': f1, 'precision': precision, 'recall': recall}"
      ],
      "metadata": {
        "id": "nMEbjwpVb4r1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 18. Trainer"
      ],
      "metadata": {
        "id": "OkL56Qleb7WX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=test_dataset,\n",
        "    compute_metrics=compute_metrics,\n",
        "    tokenizer=tokenizer,\n",
        "    callbacks=[EarlyStoppingCallback(early_stopping_patience=2)]\n",
        ")"
      ],
      "metadata": {
        "id": "r2DKvGIJb9Mu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 19. Train!"
      ],
      "metadata": {
        "id": "k3M_FfuQb_QO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Starting training...\")\n",
        "trainer.train()"
      ],
      "metadata": {
        "id": "3GuauaxgcBIl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 20. Save Model & Tokenizer"
      ],
      "metadata": {
        "id": "IxGFh9TncC5e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.save_model('./phishguard-model')\n",
        "tokenizer.save_pretrained('./phishguard-model')\n",
        "print(\"Model trained and saved!\")"
      ],
      "metadata": {
        "id": "DOLTTmjLcFQ1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 21. Evaluation"
      ],
      "metadata": {
        "id": "s4PcGmI-cHMt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Evaluating model...\")\n",
        "predictions = trainer.predict(test_dataset)\n",
        "preds = np.argmax(predictions.predictions, axis=1)\n",
        "labels = predictions.label_ids\n",
        "\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(labels, preds, target_names=list(label_map.keys())))\n",
        "\n",
        "cm = confusion_matrix(labels, preds)\n",
        "plt.figure(figsize=(10, 4))\n",
        "plt.subplot(1, 2, 1)\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "            xticklabels=list(label_map.keys()),\n",
        "            yticklabels=list(label_map.keys()))\n",
        "plt.title('Confusion Matrix')\n",
        "plt.ylabel('True')\n",
        "plt.xlabel('Predicted')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "fpr, tpr, _ = roc_curve(labels, predictions.predictions[:, 1])\n",
        "roc_auc = auc(fpr, tpr)\n",
        "plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (AUC = {roc_auc:.2f})')\n",
        "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Receiver Operating Characteristic')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(f\"Overall F1-Score: {f1_score(labels, preds, average='weighted'):.4f}\")\n",
        "print(f\"ROC AUC: {roc_auc:.4f}\")"
      ],
      "metadata": {
        "id": "BZ4lf56TcJ4N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 22. Inference Function"
      ],
      "metadata": {
        "id": "5Q48KUVycNLW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loaded_model = AutoModelForSequenceClassification.from_pretrained('./phishguard-model').to(device)\n",
        "loaded_tokenizer = AutoTokenizer.from_pretrained('./phishguard-model')\n",
        "\n",
        "def predict_phishing(email_text):\n",
        "    processed_text = preprocess_text(email_text)\n",
        "    inputs = loaded_tokenizer(\n",
        "        processed_text,\n",
        "        return_tensors='pt',\n",
        "        truncation=True,\n",
        "        padding='max_length',\n",
        "        max_length=128\n",
        "    ).to(device)\n",
        "    with torch.no_grad():\n",
        "        outputs = loaded_model(**inputs)\n",
        "    probs = torch.softmax(outputs.logits, dim=-1)\n",
        "    pred = torch.argmax(probs, dim=-1).item()\n",
        "    label = [k for k, v in label_map.items() if v == pred][0]\n",
        "    confidence = probs[0][pred].item()\n",
        "    return label, confidence, probs.cpu().numpy()[0]"
      ],
      "metadata": {
        "id": "sDiYso2kcMRW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 23. Test Model"
      ],
      "metadata": {
        "id": "SkIWfZfvcS62"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_emails = [\n",
        "    \"Urgent: Your account is compromised. Click http://fake.com/reset now!\",\n",
        "    \"Hi, meeting at 3 PM tomorrow. Regards, John.\",\n",
        "    \"Congratulations! You've won a $1000 gift card. Claim your prize at: http://prize.xyz\",\n",
        "    \"Your invoice #INV-2023-987 is ready for payment. Please review the attached document.\",\n",
        "]\n",
        "print(\"\\nTesting model with sample emails:\")\n",
        "for i, email in enumerate(test_emails):\n",
        "    label, confidence, probs = predict_phishing(email)\n",
        "    print(f\"\\nEmail {i+1}:\")\n",
        "    print(f\"Text: {email[:100]}...\")\n",
        "    print(f\"Prediction: {label} (Confidence: {confidence:.4f})\")\n",
        "    print(f\"Probabilities: {probs}\")\n",
        "\n",
        "print(\"\\nPhishGuard training and evaluation completed!\")"
      ],
      "metadata": {
        "id": "e2fgpLlP-dLD"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}