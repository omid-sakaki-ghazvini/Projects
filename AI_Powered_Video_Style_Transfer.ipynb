{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMqD/H7j7/UPH48jWrM2qXA"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install -q torch torchvision opencv-python diffusers transformers accelerate xformers"
      ],
      "metadata": {
        "id": "6jAzx-UUCvVI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **1- Imports**"
      ],
      "metadata": {
        "id": "6MW6TGKWDnMI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import torch\n",
        "from diffusers import StableDiffusionControlNetPipeline, ControlNetModel\n",
        "from PIL import Image\n",
        "import logging\n",
        "import os\n",
        "from google.colab import files\n",
        "from IPython.display import display, HTML"
      ],
      "metadata": {
        "id": "K8yBmcgFCwKA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **2- Logging Setup**"
      ],
      "metadata": {
        "id": "thRFC9seDtlw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up logging\n",
        "logging.basicConfig(level=logging.INFO)\n",
        "logger = logging.getLogger(__name__)"
      ],
      "metadata": {
        "id": "Cc8tDiblCzmA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **3- Main Converter Class**"
      ],
      "metadata": {
        "id": "qV9k2NiSD3SQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class AnimationVideoConverter:\n",
        "    def __init__(self, style_prompt=\"Studio Ghibli style\", skip_frames=1):\n",
        "        self.device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "        self.dtype = torch.float16\n",
        "        self.style_prompt = style_prompt\n",
        "        self.skip_frames = skip_frames\n",
        "        self._load_models()\n",
        "\n",
        "    #Model_Loading\n",
        "    def _load_models(self):\n",
        "        logger.info(\"Loading Stable Diffusion and ControlNet models...\")\n",
        "        self.controlnet = ControlNetModel.from_pretrained(\n",
        "            \"lllyasviel/control_v11p_sd15_canny\",\n",
        "            torch_dtype=self.dtype\n",
        "        )\n",
        "        self.pipe = StableDiffusionControlNetPipeline.from_pretrained(\n",
        "            \"runwayml/stable-diffusion-v1-5\",\n",
        "            controlnet=self.controlnet,\n",
        "            torch_dtype=self.dtype,\n",
        "            safety_checker=None\n",
        "        ).to(self.device)\n",
        "        self.pipe.enable_attention_slicing()\n",
        "        if self.device == \"cuda\":\n",
        "            self.pipe.enable_xformers_memory_efficient_attention()\n",
        "\n",
        "    #Frame_Processing\n",
        "    def stylize_frame(self, frame):\n",
        "        try:\n",
        "            frame = cv2.resize(frame, (512, 512))\n",
        "            rgb_image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "            pil_image = Image.fromarray(rgb_image)\n",
        "            canny_edges = Image.fromarray(cv2.Canny(rgb_image, 100, 200))\n",
        "            result = self.pipe(\n",
        "                self.style_prompt,\n",
        "                image=canny_edges,\n",
        "                num_inference_steps=15,\n",
        "                guidance_scale=7.0,\n",
        "                generator=torch.Generator(device=self.device).manual_seed(42)\n",
        "            )\n",
        "            return result.images[0]\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Failed to process frame: {e}\")\n",
        "            return None\n",
        "\n",
        "    #Video_Conversion\n",
        "    def convert(self, input_video, output_video):\n",
        "        cap = cv2.VideoCapture(input_video)\n",
        "        if not cap.isOpened():\n",
        "            raise RuntimeError(f\"Could not open video file: {input_video}\")\n",
        "        fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "        writer = cv2.VideoWriter(\n",
        "            output_video,\n",
        "            cv2.VideoWriter_fourcc(*'mp4v'),\n",
        "            fps/(self.skip_frames+1),\n",
        "            (512, 512)\n",
        "        )\n",
        "        frame_idx = 0\n",
        "        written_frames = 0\n",
        "        while True:\n",
        "            ret, frame = cap.read()\n",
        "            if not ret:\n",
        "                break\n",
        "            if frame_idx % (self.skip_frames+1) == 0:\n",
        "                stylized = self.stylize_frame(frame)\n",
        "                if stylized is not None:\n",
        "                    stylized_np = np.array(stylized)\n",
        "                    writer.write(cv2.cvtColor(stylized_np, cv2.COLOR_RGB2BGR))\n",
        "                    written_frames += 1\n",
        "                    logger.info(f\"Stylized frame {written_frames}\")\n",
        "            frame_idx += 1\n",
        "            if frame_idx % 10 == 0:\n",
        "                torch.cuda.empty_cache()\n",
        "        cap.release()\n",
        "        writer.release()\n",
        "        return os.path.exists(output_video)"
      ],
      "metadata": {
        "id": "IsTI15SJDRxR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **4- Side by Side Comparison**"
      ],
      "metadata": {
        "id": "2rPvdX_AEsXA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_side_by_side(original_path, stylized_path, output_path='comparison.mp4'):\n",
        "    cap_o = cv2.VideoCapture(original_path)\n",
        "    cap_s = cv2.VideoCapture(stylized_path)\n",
        "    h = min(int(cap_o.get(cv2.CAP_PROP_FRAME_HEIGHT)), int(cap_s.get(cv2.CAP_PROP_FRAME_HEIGHT)))\n",
        "    fps = min(cap_o.get(cv2.CAP_PROP_FPS), cap_s.get(cv2.CAP_PROP_FPS))\n",
        "    w_o = int(cap_o.get(cv2.CAP_PROP_FRAME_WIDTH) * (h/int(cap_o.get(cv2.CAP_PROP_FRAME_HEIGHT))))\n",
        "    w_s = int(cap_s.get(cv2.CAP_PROP_FRAME_WIDTH) * (h/int(cap_s.get(cv2.CAP_PROP_FRAME_HEIGHT))))\n",
        "    writer = cv2.VideoWriter(\n",
        "        output_path,\n",
        "        cv2.VideoWriter_fourcc(*'mp4v'),\n",
        "        fps,\n",
        "        (w_o+w_s, h)\n",
        "    )\n",
        "    while True:\n",
        "        ret_o, f_o = cap_o.read()\n",
        "        ret_s, f_s = cap_s.read()\n",
        "        if not ret_o or not ret_s:\n",
        "            break\n",
        "        f_o = cv2.resize(f_o, (w_o, h))\n",
        "        f_s = cv2.resize(f_s, (w_s, h))\n",
        "        cv2.putText(f_o, \"Original\", (10,30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0,255,0), 2)\n",
        "        cv2.putText(f_s, \"Stylized\", (10,30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0,255,255), 2)\n",
        "        writer.write(np.hstack((f_o, f_s)))\n",
        "    cap_o.release()\n",
        "    cap_s.release()\n",
        "    writer.release()\n",
        "    return os.path.exists(output_path)"
      ],
      "metadata": {
        "id": "lFXbewvYDVav"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **5- Main Execution**"
      ],
      "metadata": {
        "id": "PwgxPO6IEy5I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    print(\"Upload your video file:\")\n",
        "    uploaded = files.upload()\n",
        "    input_video = list(uploaded.keys())[0]\n",
        "    stylized_video = \"stylized.mp4\"\n",
        "    converter = AnimationVideoConverter()\n",
        "    if converter.convert(input_video, stylized_video):\n",
        "        print(\"âœ… Stylized video created!\")\n",
        "        comparison_video = \"comparison.mp4\"\n",
        "        if create_side_by_side(input_video, stylized_video, comparison_video):\n",
        "            print(\"ðŸŽ¬ Comparison video ready!\")\n",
        "            display(HTML(f\"\"\"\n",
        "            <div style=\"margin: 20px; text-align: center;\">\n",
        "                <h3>Original vs Stylized</h3>\n",
        "                <video width=\"800\" controls>\n",
        "                    <source src=\"{comparison_video}\" type=\"video/mp4\">\n",
        "                </video>\n",
        "            </div>\n",
        "            \"\"\"))\n",
        "            files.download(comparison_video)\n",
        "        else:\n",
        "            print(\"Failed to create comparison video.\")\n",
        "    else:\n",
        "        print(\"Failed to process stylized video.\")"
      ],
      "metadata": {
        "id": "5W_AquQ8DYpw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}