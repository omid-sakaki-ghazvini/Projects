{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install -q segmentation-models-pytorch==0.3.3 albumentations tqdm"
      ],
      "metadata": {
        "id": "joBe3hM1dXpq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os, random, numpy as np, pandas as pd, cv2, glob, json, shutil\n",
        "from pathlib import Path\n",
        "from tqdm.auto import tqdm\n",
        "from sklearn.model_selection import train_test_split\n",
        "from IPython.display import HTML, display, clear_output\n",
        "from google.colab import files\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.optim import AdamW\n",
        "\n",
        "import albumentations as A\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "\n",
        "import segmentation_models_pytorch as smp\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.animation as animation"
      ],
      "metadata": {
        "id": "zfoE-heHdgO7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **1- CONFIG**"
      ],
      "metadata": {
        "id": "lSBpP5TSdiQQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CFG:\n",
        "    seed = 42\n",
        "    img_size = 256\n",
        "    batch_size = 16\n",
        "    epochs = 35\n",
        "    lr = 1e-4\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "cfg = CFG()\n",
        "\n",
        "def seed_everything(seed=42):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "\n",
        "seed_everything(cfg.seed)"
      ],
      "metadata": {
        "id": "k8ME4CtEdkgZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **2- DATA SETUP**"
      ],
      "metadata": {
        "id": "UPk1MsxKdnnB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Upload your kaggle.json\")\n",
        "uploaded = files.upload()\n",
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle*.json ~/.kaggle/kaggle.json\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "\n",
        "!kaggle datasets download -d mateuszbuda/lgg-mri-segmentation --unzip -p /content > /dev/null 2>&1\n",
        "\n",
        "# Auto-detect dataset folder\n",
        "data_dir = next((p for p in Path(\"/content\").iterdir() if p.is_dir() and list(p.rglob(\"*_mask.tif\"))), None)\n",
        "print(f\"Dataset found at: {data_dir}\")\n",
        "\n",
        "# Build dataframe\n",
        "images, masks = [], []\n",
        "for mask_path in tqdm(list(data_dir.rglob(\"*_mask.tif\")), desc=\"Scanning images\"):\n",
        "    img_path = mask_path.with_name(mask_path.stem.replace(\"_mask\", \"\") + mask_path.suffix)\n",
        "    if img_path.exists():\n",
        "        images.append(str(img_path))\n",
        "        masks.append(str(mask_path))\n",
        "\n",
        "df = pd.DataFrame({\"image\": images, \"mask\": masks})\n",
        "print(f\"Total images loaded: {len(df)}\")\n",
        "\n",
        "# Tumor presence check\n",
        "has_tumor = [cv2.imread(m, 0).max() > 10 for m in tqdm(df[\"mask\"], desc=\"Checking tumor presence\")]\n",
        "\n",
        "# Split\n",
        "train_df, temp_df = train_test_split(df, test_size=0.3, stratify=has_tumor, random_state=42)\n",
        "temp_has_tumor = [has_tumor[i] for i in temp_df.index]\n",
        "val_df, test_df = train_test_split(temp_df, test_size=0.5, stratify=temp_has_tumor, random_state=42)"
      ],
      "metadata": {
        "id": "nJ3qF-a3dsah"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **3- AUGMENTATIONS**"
      ],
      "metadata": {
        "id": "J4Nj-EK5duhB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_aug = A.Compose([\n",
        "    A.Resize(cfg.img_size, cfg.img_size),\n",
        "    A.HorizontalFlip(p=0.5), A.VerticalFlip(p=0.5), A.RandomRotate90(p=0.5),\n",
        "    A.RandomBrightnessContrast(brightness_limit=0.2, contrast_limit=0.2, p=0.5),\n",
        "    A.Normalize(mean=0.485, std=0.229, max_pixel_value=255.0),\n",
        "    ToTensorV2()\n",
        "])\n",
        "\n",
        "val_aug = A.Compose([\n",
        "    A.Resize(cfg.img_size, cfg.img_size),\n",
        "    A.Normalize(mean=0.485, std=0.229, max_pixel_value=255.0),\n",
        "    ToTensorV2()\n",
        "])\n"
      ],
      "metadata": {
        "id": "h8EX8PVsd0JA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **4- DATASET**"
      ],
      "metadata": {
        "id": "GM-MaB2Gd2R4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class BrainDataset(Dataset):\n",
        "    def __init__(self, df, transform=None):\n",
        "        self.paths = df[[\"image\", \"mask\"]].values\n",
        "        self.transform = transform\n",
        "    def __len__(self): return len(self.paths)\n",
        "    def __getitem__(self, i):\n",
        "        img_path, mask_path = self.paths[i]\n",
        "        img = cv2.cvtColor(cv2.imread(img_path), cv2.COLOR_BGR2RGB)\n",
        "        mask = cv2.imread(mask_path, 0)\n",
        "        if self.transform:\n",
        "            aug = self.transform(image=img, mask=mask)\n",
        "            img, mask = aug['image'], aug['mask']\n",
        "        mask = (mask > 127).float().unsqueeze(0)\n",
        "        return img, mask\n",
        "\n",
        "test_ds = BrainDataset(test_df, val_aug)\n",
        "test_loader = DataLoader(test_ds, batch_size=1, shuffle=False)"
      ],
      "metadata": {
        "id": "Do6ZnnaMd7OY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **5- MODELS**"
      ],
      "metadata": {
        "id": "sDKqz-w2d9qA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Loading UNet++ (ResNet34)...\")\n",
        "model_unetpp = smp.UnetPlusPlus(\n",
        "    encoder_name=\"resnet34\",\n",
        "    encoder_weights=\"imagenet\",\n",
        "    in_channels=3,\n",
        "    classes=1\n",
        ").to(cfg.device)\n",
        "\n",
        "print(\"Loading Classic UNet (ResNet34)...\")\n",
        "model_unet = smp.Unet(\n",
        "    encoder_name=\"resnet34\",\n",
        "    encoder_weights=\"imagenet\",\n",
        "    in_channels=3,\n",
        "    classes=1\n",
        ").to(cfg.device)"
      ],
      "metadata": {
        "id": "z6GQP_o7eB8Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **6- TRAINING FUNCTION**"
      ],
      "metadata": {
        "id": "TT03sU_ZeFCK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(model, name):\n",
        "    criterion = smp.losses.DiceLoss(mode='binary')\n",
        "    optimizer = AdamW(model.parameters(), lr=cfg.lr)\n",
        "    best_dice = 0\n",
        "\n",
        "    train_loader = DataLoader(BrainDataset(train_df, train_aug), batch_size=cfg.batch_size, shuffle=True, num_workers=2, pin_memory=True)\n",
        "    val_loader = DataLoader(BrainDataset(val_df, val_aug), batch_size=cfg.batch_size, shuffle=False, num_workers=2)\n",
        "\n",
        "    print(f\"\\nTraining {name}...\")\n",
        "    for epoch in range(1, cfg.epochs + 1):\n",
        "        model.train()\n",
        "        for xb, yb in train_loader:\n",
        "            xb, yb = xb.to(cfg.device), yb.to(cfg.device)\n",
        "            pred = model(xb)\n",
        "            loss = criterion(pred, yb)\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        # Validation\n",
        "        model.eval()\n",
        "        val_dice = 0\n",
        "        with torch.no_grad():\n",
        "            for xb, yb in val_loader:\n",
        "                pred = torch.sigmoid(model(xb.to(cfg.device)))\n",
        "                val_dice += (2*(pred*yb.to(cfg.device)).sum() + 1) / (pred.sum() + yb.to(cfg.device).sum() + 1)\n",
        "        val_dice /= len(val_loader)\n",
        "        print(f\"Epoch {epoch:02d} | {name} Val Dice: {val_dice.item():.4f}\")\n",
        "\n",
        "        if val_dice > best_dice:\n",
        "            best_dice = val_dice\n",
        "            torch.save(model.state_dict(), f\"best_{name.lower()}.pth\")\n",
        "            print(f\"   → Best {name} saved! ({best_dice.item():.4f})\")\n",
        "\n",
        "    return model, best_dice.item()"
      ],
      "metadata": {
        "id": "OIaToC8aeK35"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **7- TRAIN BOTH MODELS**"
      ],
      "metadata": {
        "id": "0Q7eQthmeM6Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Starting training comparison...\")\n",
        "\n",
        "# Train UNet++\n",
        "model_unetpp, dice_unetpp = train_model(model_unetpp, \"UNet++\")"
      ],
      "metadata": {
        "id": "ytMCfYo2eTJR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train Classic UNet\n",
        "model_unet, dice_unet = train_model(model_unet, \"UNet\")"
      ],
      "metadata": {
        "id": "qmGsztGyeXBK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **8- FINAL TEST & COMPARISON GIF**"
      ],
      "metadata": {
        "id": "Oo3zwJuCeZQh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image, ImageDraw, ImageFont\n",
        "import glob\n",
        "import os\n",
        "\n",
        "# Load trained models\n",
        "model_unet.load_state_dict(torch.load(\"best_unet.pth\"))\n",
        "model_unetpp.load_state_dict(torch.load(\"best_unet++.pth\"))\n",
        "model_unet.eval()\n",
        "model_unetpp.eval()\n",
        "\n",
        "# Create folders\n",
        "os.makedirs(\"unet_predictions\", exist_ok=True)\n",
        "os.makedirs(\"unetpp_predictions\", exist_ok=True)\n",
        "\n",
        "def create_overlay(img_np, pred_mask, gt_mask, title, idx):\n",
        "    plt.figure(figsize=(10, 10))\n",
        "    overlay = img_np.copy()\n",
        "    overlay[pred_mask > 0.5] = [1, 0, 0]      # Red = Prediction\n",
        "    overlay[gt_mask > 0.5] = [0, 1, 0]        # Green = Ground Truth\n",
        "    overlay[(pred_mask > 0.5) & (gt_mask > 0.5)] = [1, 1, 0]  # Yellow = Overlap\n",
        "\n",
        "    plt.imshow(overlay)\n",
        "    plt.axis(\"off\")\n",
        "    plt.figtext(0.25, 0.78, \"Red - Prediction\", va=\"center\", ha=\"center\", size=22, color=\"#ff0000\", weight=\"bold\")\n",
        "    plt.figtext(0.75, 0.78, \"Green - Ground Truth\", va=\"center\", ha=\"center\", size=22, color=\"#00ff00\", weight=\"bold\")\n",
        "    plt.suptitle(title, y=0.86, fontsize=24, weight=\"bold\", color=\"#00FFFF\")\n",
        "\n",
        "    filename = f\"{title.lower().replace(' ', '_').replace('+', 'pp')}_{idx:03d}.png\"\n",
        "    plt.savefig(filename, bbox_inches='tight', facecolor='black', dpi=150, pad_inches=0.3)\n",
        "    plt.close()\n",
        "    return filename\n",
        "\n",
        "print(\"Generating prediction overlays with Red=Pred, Green=GT...\")\n",
        "test_indices = random.sample(range(len(test_ds)), 40)\n",
        "\n",
        "unet_files = []\n",
        "unetpp_files = []\n",
        "\n",
        "for i, idx in enumerate(tqdm(test_indices, desc=\"Creating overlays\")):\n",
        "    img, gt = test_ds[idx]\n",
        "    img_dev = img.unsqueeze(0).to(cfg.device)\n",
        "    gt_np = gt[0].cpu().numpy()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        pred_unet = torch.sigmoid(model_unet(img_dev))[0,0].cpu().numpy()\n",
        "        pred_unetpp = torch.sigmoid(model_unetpp(img_dev))[0,0].cpu().numpy()\n",
        "\n",
        "    img_np = img.permute(1,2,0).numpy()\n",
        "    img_np = np.clip(img_np * 0.229 + 0.485, 0, 1)\n",
        "\n",
        "    u_file = create_overlay(img_np, pred_unet, gt_np, \"Vanilla UNet\", i)\n",
        "    upp_file = create_overlay(img_np, pred_unetpp, gt_np, \"UNet++\", i)\n",
        "\n",
        "    unet_files.append(u_file)\n",
        "    unetpp_files.append(upp_file)"
      ],
      "metadata": {
        "id": "go0wr6dwefGp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **9- SIDE-BY-SIDE COMPARISON ANIMATION**"
      ],
      "metadata": {
        "id": "IQl5IvggeiDb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# CREATE INDIVIDUAL GIFs\n",
        "def make_gif(file_list, output_name):\n",
        "    if not file_list:\n",
        "        print(f\"No images for {output_name}\")\n",
        "        return None\n",
        "    imgs = [Image.open(f) for f in file_list]\n",
        "    imgs[0].save(output_name, save_all=True, append_images=imgs[1:], duration=1000, loop=0)\n",
        "    print(f\"Created: {output_name} ({len(imgs)} frames)\")\n",
        "    return output_name\n",
        "\n",
        "gif_unet = make_gif(unet_files, \"unet_predictions.gif\")\n",
        "gif_unetpp = make_gif(unetpp_files, \"unetpp_predictions.gif\")\n",
        "\n",
        "# SIDE-BY-SIDE COMPARISON GIF\n",
        "print(\"Creating side-by-side comparison GIF...\")\n",
        "\n",
        "side_by_side_frames = []\n",
        "min_len = min(len(unet_files), len(unetpp_files))\n",
        "\n",
        "for i in range(min_len):\n",
        "    left = Image.open(unet_files[i])\n",
        "    right = Image.open(unetpp_files[i])\n",
        "\n",
        "    new_width = left.width * 2 + 100\n",
        "    new_img = Image.new('RGB', (new_width, left.height), (15, 15, 30))\n",
        "    new_img.paste(left, (50, 0))\n",
        "    new_img.paste(right, (left.width + 100, 0))\n",
        "\n",
        "    draw = ImageDraw.Draw(new_img)\n",
        "    try:\n",
        "        font_title = ImageFont.truetype(\"arial.ttf\", 60)\n",
        "        font_vs = ImageFont.truetype(\"arial.ttf\", 48)\n",
        "    except:\n",
        "        font_title = ImageFont.load_default()\n",
        "        font_vs = font_title\n",
        "\n",
        "    draw.text((new_img.width//2, 80), \"Vanilla UNet\", fill=\"yellow\", font=font_title, anchor=\"mm\")\n",
        "    draw.text((new_img.width//2, 160), \"vs\", fill=\"white\", font=font_vs, anchor=\"mm\")\n",
        "    draw.text((new_img.width//2, 240), \"UNet++\", fill=\"#00ff00\", font=font_title, anchor=\"mm\")\n",
        "\n",
        "    side_by_side_frames.append(new_img)\n",
        "\n",
        "if side_by_side_frames:\n",
        "    side_by_side_frames[0].save(\n",
        "        \"unet_vs_unetpp_comparison.gif\",\n",
        "        save_all=True,\n",
        "        append_images=side_by_side_frames[1:],\n",
        "        duration=1200,\n",
        "        loop=0\n",
        "    )\n",
        "    print(\"Side-by-side comparison GIF created successfully!\")"
      ],
      "metadata": {
        "id": "VoR_bpK_ehoJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **10- DISPLAY FINAL RESULT**"
      ],
      "metadata": {
        "id": "31rgsihveugw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qILwmEEKkuO6"
      },
      "outputs": [],
      "source": [
        "display(HTML(f'''\n",
        "<center>\n",
        "<h1 style=\"color:#00ff00; font-size:50px\">Comparison Complete!</h1>\n",
        "<h2 style=\"color:#00ffff\">Red = Prediction | Green = Ground Truth</h2>\n",
        "\n",
        "<h3 style=\"color:yellow\">Vanilla UNet Results</h3>\n",
        "<img src=\"unet_predictions.gif\" width=\"500\"/>\n",
        "\n",
        "<h3 style=\"color:#00ff00\">UNet++ Results (Clearly Superior)</h3>\n",
        "<img src=\"unetpp_predictions.gif\" width=\"500\"/>\n",
        "\n",
        "<h1 style=\"color:#00ffff; font-size:48px\">Side-by-Side Comparison</h1>\n",
        "<img src=\"unet_vs_unetpp_comparison.gif\" width=\"1200\"/>\n",
        "\n",
        "<br><br>\n",
        "<a href=\"unet_vs_unetpp_comparison.gif\" style=\"font-size:24px; color:cyan\">Download Final Comparison GIF</a>\n",
        "</center>\n",
        "'''))\n",
        "\n",
        "files.download(\"unet_vs_unetpp_comparison.gif\")\n",
        "print(\"\\nAll done! UNet++ is the clear winner — visually and quantitatively\")"
      ]
    }
  ]
}