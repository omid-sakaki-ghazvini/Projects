{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **1. Install Dependencies**"
      ],
      "metadata": {
        "id": "Rbcq_-ZzySDs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Uninstall conflicting packages\n",
        "!pip uninstall -y numpy opencv-python opencv-python-headless opencv-contrib-python thinc umap-learn sklearn-compat\n",
        "# Install compatible versions\n",
        "!pip install -q numpy==1.26.4\n",
        "!pip install -q torch==2.0.1 torchvision torchaudio --index-url https://download.pytorch.org/whl/cpu\n",
        "!pip install -q torch-geometric==2.3.1\n",
        "!pip install -q torch-scatter==2.1.2 torch-sparse==0.6.18 torch-cluster==1.6.3 torch-spline-conv==1.2.2 -f https://data.pyg.org/whl/torch-2.0.1+cpu.html\n",
        "!pip install -q transformers==4.41.2 sentence-transformers==2.7.0 pyvis==0.3.2 plotly==5.22.0 scikit-learn==1.6.0 pandas==2.2.2 tqdm==4.67.0"
      ],
      "metadata": {
        "id": "cX0bHH3XyXln"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **2. Imports and Settings**"
      ],
      "metadata": {
        "id": "k6JtryQMyazZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.data import Data\n",
        "from torch_geometric.nn import GATConv\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from sentence_transformers import SentenceTransformer\n",
        "import numpy as np\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from collections import Counter\n",
        "from tqdm import tqdm\n",
        "from pyvis.network import Network\n",
        "import plotly.express as px\n",
        "from IPython.display import display, HTML\n",
        "import warnings\n",
        "import os\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "torch.manual_seed(42)\n",
        "device = torch.device('cpu')"
      ],
      "metadata": {
        "id": "vs6ktKE1ygGI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **3. Knowledge Graph Builder**"
      ],
      "metadata": {
        "id": "6WVSNVsRyiEg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class KnowledgeGraphBuilder:\n",
        "    def __init__(self, model_name='all-MiniLM-L6-v2'):\n",
        "        self.encoder = SentenceTransformer(model_name)\n",
        "        self.num_features = self.encoder.get_sentence_embedding_dimension()\n",
        "\n",
        "    def build_graph(self):\n",
        "        # Expanded entities and relations\n",
        "        entities = [\n",
        "            \"Artificial Intelligence\", \"Machine Learning\", \"Deep Learning\", \"Neural Networks\",\n",
        "            \"Computer Vision\", \"Natural Language Processing\", \"Supervised Learning\",\n",
        "            \"Unsupervised Learning\", \"Reinforcement Learning\", \"Classification\", \"Clustering\",\n",
        "            \"Regression\", \"Image Recognition\", \"Speech Processing\", \"Transfer Learning\",\n",
        "            \"Generative AI\", \"Convolutional Neural Networks\", \"Recurrent Neural Networks\",\n",
        "            \"Transformer Models\", \"Object Detection\", \"Sentiment Analysis\"\n",
        "        ]\n",
        "        relations = [\n",
        "            (\"Artificial Intelligence\", \"includes\", \"Machine Learning\"),\n",
        "            (\"Artificial Intelligence\", \"includes\", \"Computer Vision\"),\n",
        "            (\"Artificial Intelligence\", \"includes\", \"Natural Language Processing\"),\n",
        "            (\"Machine Learning\", \"includes\", \"Deep Learning\"),\n",
        "            (\"Machine Learning\", \"includes\", \"Supervised Learning\"),\n",
        "            (\"Machine Learning\", \"includes\", \"Unsupervised Learning\"),\n",
        "            (\"Machine Learning\", \"includes\", \"Reinforcement Learning\"),\n",
        "            (\"Machine Learning\", \"includes\", \"Transfer Learning\"),\n",
        "            (\"Deep Learning\", \"uses\", \"Neural Networks\"),\n",
        "            (\"Deep Learning\", \"includes\", \"Convolutional Neural Networks\"),\n",
        "            (\"Deep Learning\", \"includes\", \"Recurrent Neural Networks\"),\n",
        "            (\"Deep Learning\", \"includes\", \"Transformer Models\"),\n",
        "            (\"Computer Vision\", \"uses\", \"Neural Networks\"),\n",
        "            (\"Computer Vision\", \"focuses_on\", \"Image Recognition\"),\n",
        "            (\"Computer Vision\", \"focuses_on\", \"Object Detection\"),\n",
        "            (\"Natural Language Processing\", \"uses\", \"Neural Networks\"),\n",
        "            (\"Natural Language Processing\", \"focuses_on\", \"Speech Processing\"),\n",
        "            (\"Natural Language Processing\", \"focuses_on\", \"Sentiment Analysis\"),\n",
        "            (\"Supervised Learning\", \"includes\", \"Classification\"),\n",
        "            (\"Supervised Learning\", \"includes\", \"Regression\"),\n",
        "            (\"Unsupervised Learning\", \"includes\", \"Clustering\")\n",
        "        ]\n",
        "        entity2id = {ent: idx for idx, ent in enumerate(entities)}\n",
        "        relation_types = sorted(list(set([r[1] for r in relations])))\n",
        "        relation2id = {rel: idx for idx, rel in enumerate(relation_types)}\n",
        "        edge_index = []\n",
        "        edge_type = []\n",
        "        for src, rel, dst in relations:\n",
        "            if src in entity2id and dst in entity2id:\n",
        "                edge_index.append([entity2id[src], entity2id[dst]])\n",
        "                edge_type.append(relation2id[rel])\n",
        "        edge_index = torch.tensor(edge_index, dtype=torch.long).t().contiguous()\n",
        "        edge_type = torch.tensor(edge_type, dtype=torch.long)\n",
        "        features = torch.tensor(self.encoder.encode(entities, convert_to_numpy=True), dtype=torch.float)\n",
        "        return Data(x=features, edge_index=edge_index, edge_attr=edge_type), entity2id, relation2id, entities"
      ],
      "metadata": {
        "id": "_VY95ob6yn2A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **4. GAT Model Architecture**"
      ],
      "metadata": {
        "id": "zUjDbXIXypzR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class KGAT(nn.Module):\n",
        "    def __init__(self, num_features, hidden_dim, num_relations, num_classes):\n",
        "        super().__init__()\n",
        "        self.conv1 = GATConv(num_features, hidden_dim, edge_dim=hidden_dim)\n",
        "        self.conv2 = GATConv(hidden_dim, hidden_dim, edge_dim=hidden_dim)\n",
        "        self.bn1 = nn.BatchNorm1d(hidden_dim)\n",
        "        self.bn2 = nn.BatchNorm1d(hidden_dim)\n",
        "        self.relation_emb = nn.Embedding(num_relations, hidden_dim)\n",
        "        self.question_proj = nn.Linear(num_features, hidden_dim)\n",
        "        self.answer_predictor = nn.Linear(hidden_dim, num_classes)\n",
        "\n",
        "    def forward(self, data, question_emb):\n",
        "        edge_attr = self.relation_emb(data.edge_attr)\n",
        "        x = F.relu(self.bn1(self.conv1(data.x, data.edge_index, edge_attr=edge_attr)))\n",
        "        x = F.dropout(x, p=0.2, training=self.training)\n",
        "        x = F.relu(self.bn2(self.conv2(x, data.edge_index, edge_attr=edge_attr)))\n",
        "        x = F.dropout(x, p=0.2, training=self.training)\n",
        "        if question_emb.dim() == 1:\n",
        "            question_emb = question_emb.unsqueeze(0)\n",
        "        q_proj = self.question_proj(question_emb)\n",
        "        scores = torch.matmul(x, q_proj.t())\n",
        "        attn_weights = F.softmax(scores, dim=0)\n",
        "        aggregated = torch.matmul(attn_weights.t(), x)\n",
        "        return self.answer_predictor(aggregated.squeeze(0))"
      ],
      "metadata": {
        "id": "scgkmaRVyuTx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **5. Training & QA System**"
      ],
      "metadata": {
        "id": "ar4GdoYAywIr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class QATrainingSystem:\n",
        "    def __init__(self, model_name='all-MiniLM-L6-v2'):\n",
        "        self.builder = KnowledgeGraphBuilder(model_name)\n",
        "        self.encoder = self.builder.encoder\n",
        "\n",
        "    def prepare_data(self):\n",
        "        print(\"Building knowledge graph...\")\n",
        "        self.graph, self.entity2id, self.relation2id, self.entities = self.builder.build_graph()\n",
        "        self.id2entity = {v: k for k, v in self.entity2id.items()}\n",
        "        print(f\"\\nEntities: {len(self.entities)} | Relations: {len(self.relation2id)} | Edges: {self.graph.edge_index.shape[1]}\")\n",
        "        self._generate_qa_pairs()\n",
        "\n",
        "    def _generate_qa_pairs(self):\n",
        "        print(\"\\nGenerating QA pairs...\")\n",
        "        templates = [\n",
        "            \"What is {}?\",\n",
        "            \"Explain {}.\",\n",
        "            \"Describe {}.\",\n",
        "            \"Which field includes {}?\",\n",
        "            \"How does {} work?\",\n",
        "            \"What is the relationship between {} and {}?\",\n",
        "            \"How are {} and {} connected?\",\n",
        "            \"Does {} relate to {}?\"\n",
        "        ]\n",
        "        questions, answers = [], []\n",
        "        max_questions_per_entity = 10\n",
        "        entity_counts = Counter()\n",
        "        # Positive examples\n",
        "        for entity, eid in self.entity2id.items():\n",
        "            if entity_counts[eid] < max_questions_per_entity:\n",
        "                questions += [tpl.format(entity) for tpl in templates[:5]]\n",
        "                answers += [eid] * 5\n",
        "                entity_counts[eid] += 5\n",
        "            outgoing_edges = (self.graph.edge_index[0] == eid).nonzero(as_tuple=False).squeeze(1)\n",
        "            for edge_idx in outgoing_edges:\n",
        "                if entity_counts[eid] >= max_questions_per_entity:\n",
        "                    continue\n",
        "                rel_type = list(self.relation2id.keys())[self.graph.edge_attr[edge_idx].item()]\n",
        "                target = self.id2entity[self.graph.edge_index[1, edge_idx].item()]\n",
        "                for tpl in templates[5:]:\n",
        "                    questions.append(tpl.format(entity, target))\n",
        "                    answers.append(eid)\n",
        "                    entity_counts[eid] += 1\n",
        "        # Negative examples\n",
        "        for entity, eid in self.entity2id.items():\n",
        "            if entity_counts[eid] >= max_questions_per_entity:\n",
        "                continue\n",
        "            non_related = [e for e in self.entities if e != entity and not any(\n",
        "                (self.graph.edge_index[0] == self.entity2id[entity]) &\n",
        "                (self.graph.edge_index[1] == self.entity2id[e])\n",
        "            )]\n",
        "            for neg_entity in non_related[:2]:  # Limit to 2 negative examples per entity\n",
        "                questions.append(f\"Does {entity} relate to {neg_entity}?\")\n",
        "                answers.append(eid)\n",
        "                entity_counts[eid] += 1\n",
        "        print(f\"Total QA pairs: {len(questions)}\")\n",
        "        print(\"QA pair distribution:\", Counter([self.id2entity[a] for a in answers]))\n",
        "        # Encode questions\n",
        "        print(\"Encoding questions...\")\n",
        "        question_embs = torch.tensor(self.encoder.encode(questions, convert_to_numpy=True), dtype=torch.float)\n",
        "        self.questions = question_embs\n",
        "        self.answers = torch.tensor(answers, dtype=torch.long)\n",
        "        self.question_texts = questions\n",
        "\n",
        "    def train_model(self):\n",
        "        print(\"\\nInitializing model...\")\n",
        "        self.model = KGAT(\n",
        "            num_features=self.builder.num_features,\n",
        "            hidden_dim=256,\n",
        "            num_relations=len(self.relation2id),\n",
        "            num_classes=len(self.entities)\n",
        "        ).to(device)\n",
        "        optimizer = torch.optim.Adam(self.model.parameters(), lr=1e-3)\n",
        "        scheduler = ReduceLROnPlateau(optimizer, 'min', patience=5, factor=0.2)\n",
        "        class_weights = compute_class_weight('balanced', classes=np.arange(len(self.entities)), y=self.answers.numpy())\n",
        "        class_weights = torch.tensor(class_weights, dtype=torch.float).to(device)\n",
        "        train_idx, val_idx = train_test_split(\n",
        "            np.arange(len(self.questions)), test_size=0.2, random_state=42, stratify=self.answers.numpy()\n",
        "        )\n",
        "        dataset = TensorDataset(self.questions[train_idx].to(device), self.answers[train_idx].to(device))\n",
        "        loader = DataLoader(dataset, batch_size=16, shuffle=True)\n",
        "        X_val = self.questions[val_idx].to(device)\n",
        "        y_val = self.answers[val_idx].to(device)\n",
        "        best_val_loss, patience, counter = float('inf'), 10, 0\n",
        "        train_losses, val_losses = [], []\n",
        "        print(\"\\nTraining...\")\n",
        "        for epoch in range(100):\n",
        "            self.model.train()\n",
        "            epoch_loss = 0\n",
        "            for batch_x, batch_y in loader:\n",
        "                optimizer.zero_grad()\n",
        "                outputs = self.model(self.graph.to(device), batch_x)\n",
        "                loss = F.cross_entropy(outputs, batch_y, weight=class_weights)\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "                epoch_loss += loss.item()\n",
        "            train_losses.append(epoch_loss / len(loader))\n",
        "            self.model.eval()\n",
        "            with torch.no_grad():\n",
        "                val_outputs = self.model(self.graph.to(device), X_val)\n",
        "                val_loss = F.cross_entropy(val_outputs, y_val, weight=class_weights)\n",
        "                val_losses.append(val_loss.item())\n",
        "                _, preds = torch.max(val_outputs, 1)\n",
        "                acc = (preds == y_val).float().mean()\n",
        "            scheduler.step(val_loss)\n",
        "            print(f\"Epoch {epoch+1}: Train Loss: {train_losses[-1]:.4f} | Val Loss: {val_loss.item():.4f} | Val Acc: {acc.item():.4f}\")\n",
        "            if val_loss < best_val_loss:\n",
        "                best_val_loss = val_loss\n",
        "                torch.save({\n",
        "                    'model_state_dict': self.model.state_dict(),\n",
        "                    'entity2id': self.entity2id,\n",
        "                    'relation2id': self.relation2id\n",
        "                }, 'best_model.pth')\n",
        "                counter = 0\n",
        "            else:\n",
        "                counter += 1\n",
        "            if counter >= patience:\n",
        "                print(\"Early stopping.\")\n",
        "                break\n",
        "        # Final evaluation\n",
        "        self.model.eval()\n",
        "        with torch.no_grad():\n",
        "            val_outputs = self.model(self.graph.to(device), X_val)\n",
        "            _, preds = torch.max(val_outputs, 1)\n",
        "            print(\"\\nValidation Metrics:\")\n",
        "            print(classification_report(\n",
        "                y_val.cpu().numpy(), preds.cpu().numpy(),\n",
        "                target_names=[self.id2entity[i] for i in range(len(self.entities))],\n",
        "                zero_division=0\n",
        "            ))\n",
        "            # Inspect predictions\n",
        "            print(\"\\nSample Predictions:\")\n",
        "            for q, pred, true in zip(np.array(self.question_texts)[val_idx][:5], preds[:5], y_val[:5]):\n",
        "                print(f\"Q: {q} | Pred: {self.id2entity[pred.item()]} | True: {self.id2entity[true.item()]}\")\n",
        "        # Plot and save loss curves\n",
        "        fig = px.line(\n",
        "            x=list(range(1, len(train_losses)+1)), y=train_losses,\n",
        "            labels={'x': 'Epoch', 'y': 'Loss'}, title='Training & Validation Loss'\n",
        "        )\n",
        "        fig.add_scatter(x=list(range(1, len(val_losses)+1)), y=val_losses, name='Validation Loss')\n",
        "        fig.write_html(\"loss_plot.html\")\n",
        "        fig.show()\n",
        "        print(\"train_losses:\", train_losses)\n",
        "        print(\"val_losses:\", val_losses)\n",
        "\n",
        "    def visualize_graph(self):\n",
        "        net = Network(height=\"600px\", width=\"100%\", notebook=True, directed=True)\n",
        "        net.show_buttons(filter_=['physics'])\n",
        "        for entity, idx in self.entity2id.items():\n",
        "            net.add_node(idx, label=entity, title=entity, color=\"#3498db\", size=20)\n",
        "        for i in range(self.graph.edge_index.shape[1]):\n",
        "            src = self.graph.edge_index[0, i].item()\n",
        "            dst = self.graph.edge_index[1, i].item()\n",
        "            rel_type = list(self.relation2id.keys())[self.graph.edge_attr[i].item()]\n",
        "            net.add_edge(src, dst, title=rel_type, color=\"#e74c3c\")\n",
        "        net.show(\"knowledge_graph.html\")\n",
        "        display(HTML(\"knowledge_graph.html\"))\n",
        "\n",
        "    def interactive_demo(self):\n",
        "        if not os.path.exists('best_model.pth'):\n",
        "            print(\"No trained model found. Train the model first!\")\n",
        "            return\n",
        "        print(\"\\nInteractive QA Demo (type 'quit' to exit)\")\n",
        "        self.model.load_state_dict(torch.load('best_model.pth', map_location=device)['model_state_dict'])\n",
        "        self.model.eval()\n",
        "        while True:\n",
        "            question = input(\"\\nEnter your question: \")\n",
        "            if question.lower().strip() == 'quit':\n",
        "                break\n",
        "            if not question.strip():\n",
        "                print(\"Please enter a valid question.\")\n",
        "                continue\n",
        "            emb = torch.tensor(self.encoder.encode([question], convert_to_numpy=True), dtype=torch.float).to(device)\n",
        "            with torch.no_grad():\n",
        "                scores = self.model(self.graph.to(device), emb)\n",
        "                probs = F.softmax(scores, dim=0)\n",
        "                top3 = torch.topk(probs, 3)\n",
        "            print(\"\\nTop 3 Answers:\")\n",
        "            for i in range(3):\n",
        "                idx = top3.indices[i].item()\n",
        "                print(f\"{i+1}. {self.id2entity[idx]} (confidence: {top3.values[i].item():.2%})\")"
      ],
      "metadata": {
        "id": "Ops7XUPiy3Ka"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **6. Main Execution**"
      ],
      "metadata": {
        "id": "kWoBr5P9y4_h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    system = QATrainingSystem()\n",
        "    system.prepare_data()\n",
        "    system.visualize_graph()\n",
        "    system.train_model()\n",
        "    system.interactive_demo()"
      ],
      "metadata": {
        "id": "rNwMHGJ5y76w"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}