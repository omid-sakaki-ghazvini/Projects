{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SBUlK19lT-mI"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Stable Diffusion Image-to-Video Converter\n",
        "Converts an input image into an animated video using Stable Diffusion img2img pipeline\n",
        "\"\"\"\n",
        "\n",
        "# Install required packages\n",
        "%%capture\n",
        "!pip uninstall diffusers transformers huggingface-hub torch -y\n",
        "!pip install torch torchvision --upgrade\n",
        "!pip install diffusers>=0.28.0 transformers>=4.31.0 huggingface-hub>=0.30.0\n",
        "!pip install pillow opencv-python ipython numpy accelerate imageio imageio-ffmpeg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oyXjaYupQf1C"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from diffusers import StableDiffusionImg2ImgPipeline, DDIMScheduler\n",
        "from PIL import Image\n",
        "import os\n",
        "import numpy as np\n",
        "import imageio\n",
        "from google.colab import files\n",
        "from IPython.display import display, HTML, Video\n",
        "\n",
        "# Configuration\n",
        "MODEL_NAME = \"runwayml/stable-diffusion-v1-5\"\n",
        "OUTPUT_DIR = \"/content/output\"\n",
        "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
        "\n",
        "def load_stable_model():\n",
        "    \"\"\"Loads the Stable Diffusion model with optimized settings\"\"\"\n",
        "    print(\"üîÑ Loading model...\")\n",
        "    try:\n",
        "        # Use DDIM scheduler for better results\n",
        "        scheduler = DDIMScheduler.from_pretrained(MODEL_NAME, subfolder=\"scheduler\")\n",
        "\n",
        "        # Initialize pipeline with fp16 for faster inference\n",
        "        pipe = StableDiffusionImg2ImgPipeline.from_pretrained(\n",
        "            MODEL_NAME,\n",
        "            torch_dtype=torch.float16,\n",
        "            scheduler=scheduler,\n",
        "            variant=\"fp16\",\n",
        "            use_safetensors=True\n",
        "        ).to(\"cuda\")\n",
        "\n",
        "        # Optimize memory usage\n",
        "        pipe.enable_attention_slicing()\n",
        "        pipe.enable_model_cpu_offload()\n",
        "\n",
        "        print(\"‚úÖ Model loaded successfully\")\n",
        "        return pipe\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Error loading model: {str(e)}\")\n",
        "        return None\n",
        "\n",
        "def create_video(pipe, input_image, prompt, num_frames=24, fps=8):\n",
        "    \"\"\"Generates video frames using gradual image transformations\"\"\"\n",
        "    print(\"üé¨ Creating video...\")\n",
        "\n",
        "    frames = []\n",
        "    current_image = input_image\n",
        "\n",
        "    for i in range(num_frames):\n",
        "        print(f\"üî® Generating frame {i+1}/{num_frames}\", end=\"\\r\")\n",
        "\n",
        "        # Gradually increase strength for smooth transitions\n",
        "        strength = min(0.1 + (i/num_frames)*0.7, 0.8)\n",
        "\n",
        "        result = pipe(\n",
        "            prompt=prompt,\n",
        "            image=current_image,\n",
        "            strength=strength,\n",
        "            guidance_scale=7.5,\n",
        "            num_inference_steps=50\n",
        "        )\n",
        "\n",
        "        current_image = result.images[0]\n",
        "        frames.append(np.array(current_image))\n",
        "\n",
        "    print(\"\\n‚úÖ All frames generated\")\n",
        "    return frames\n",
        "\n",
        "def save_video(frames, fps=8):\n",
        "    \"\"\"Saves frames as an MP4 video file\"\"\"\n",
        "    video_path = os.path.join(OUTPUT_DIR, \"output.mp4\")\n",
        "    with imageio.get_writer(video_path, fps=fps) as writer:\n",
        "        for frame in frames:\n",
        "            writer.append_data(frame)\n",
        "    return video_path\n",
        "\n",
        "def main():\n",
        "    \"\"\"Main execution function\"\"\"\n",
        "    print(\"üì§ Please upload an image (preferably 512x512 pixels)...\")\n",
        "    uploaded = files.upload()\n",
        "    if not uploaded:\n",
        "        print(\"‚ùå No image uploaded\")\n",
        "        return\n",
        "\n",
        "    image_file = next(iter(uploaded))\n",
        "    prompt = input(\"‚úèÔ∏è Enter transformation prompt (in English): \") or \"a beautiful animation\"\n",
        "\n",
        "    try:\n",
        "        # Process input image\n",
        "        img = Image.open(image_file).convert(\"RGB\")\n",
        "        if img.size != (512, 512):\n",
        "            print(\"‚ö†Ô∏è Resizing image to 512x512\")\n",
        "            img = img.resize((512, 512))\n",
        "\n",
        "        # Load model\n",
        "        pipe = load_stable_model()\n",
        "        if pipe is None:\n",
        "            return\n",
        "\n",
        "        # Generate and save video\n",
        "        frames = create_video(pipe, img, prompt)\n",
        "        video_path = save_video(frames)\n",
        "\n",
        "        # Display results\n",
        "        display(HTML(f\"\"\"\n",
        "        <div style=\"text-align:center; margin:20px\">\n",
        "            <h3 style=\"color:green\">‚úÖ Video ready!</h3>\n",
        "            <video width=\"512\" controls style=\"margin:20px; border:2px solid #4CAF50; border-radius:8px;\">\n",
        "                <source src=\"{video_path}\" type=\"video/mp4\">\n",
        "                Your browser doesn't support video tag.\n",
        "            </video>\n",
        "            <div style=\"margin-top:20px;\">\n",
        "                <a href=\"{video_path}\" download=\"generated_video.mp4\" style=\"\n",
        "                    display:inline-block;\n",
        "                    padding:12px 24px;\n",
        "                    background:#4CAF50;\n",
        "                    color:white;\n",
        "                    text-decoration:none;\n",
        "                    border-radius:5px;\n",
        "                    margin:10px;\n",
        "                    font-weight:bold;\n",
        "                    font-size:16px;\">\n",
        "                    Download Video\n",
        "                </a>\n",
        "            </div>\n",
        "        </div>\n",
        "        \"\"\"))\n",
        "\n",
        "        display(Video(video_path, embed=True))\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Processing error: {str(e)}\")\n",
        "    finally:\n",
        "        if 'pipe' in locals():\n",
        "            del pipe\n",
        "        torch.cuda.empty_cache()\n",
        "        print(\"GPU memory cleared\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"\"\"\n",
        "    üé• Stable Diffusion Image-to-Video Converter\n",
        "    -------------------------------------------\n",
        "    Transform your images into animated videos using AI\n",
        "    \"\"\")\n",
        "    main()\n",
        "    print(\"üèÅ Process completed successfully\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}