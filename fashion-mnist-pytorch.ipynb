{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":9243,"sourceType":"datasetVersion","datasetId":2243}],"dockerImageVersionId":30805,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2024-12-12T19:04:50.445607Z","iopub.execute_input":"2024-12-12T19:04:50.446318Z","iopub.status.idle":"2024-12-12T19:04:50.777369Z","shell.execute_reply.started":"2024-12-12T19:04:50.446280Z","shell.execute_reply":"2024-12-12T19:04:50.776597Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/fashionmnist/t10k-labels-idx1-ubyte\n/kaggle/input/fashionmnist/t10k-images-idx3-ubyte\n/kaggle/input/fashionmnist/fashion-mnist_test.csv\n/kaggle/input/fashionmnist/fashion-mnist_train.csv\n/kaggle/input/fashionmnist/train-labels-idx1-ubyte\n/kaggle/input/fashionmnist/train-images-idx3-ubyte\n","output_type":"stream"}],"execution_count":1},{"cell_type":"markdown","source":"# **1- Importing Required Libraries**","metadata":{}},{"cell_type":"code","source":"import torch\nfrom torch import nn\nfrom torch.autograd import Variable\nfrom torch.utils.data import Dataset, DataLoader\n\nfrom torchvision import datasets, models, transforms\nfrom torchvision.utils import make_grid\n\nimport matplotlib.pyplot as plt","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-12T19:04:50.778618Z","iopub.execute_input":"2024-12-12T19:04:50.778941Z","iopub.status.idle":"2024-12-12T19:04:54.875977Z","shell.execute_reply.started":"2024-12-12T19:04:50.778914Z","shell.execute_reply":"2024-12-12T19:04:54.875290Z"}},"outputs":[],"execution_count":2},{"cell_type":"markdown","source":"# **2- Create Data Loader**","metadata":{}},{"cell_type":"code","source":"train_csv = pd.read_csv(\"/kaggle/input/fashionmnist/fashion-mnist_train.csv\")\ntest_csv = pd.read_csv(\"/kaggle/input/fashionmnist/fashion-mnist_test.csv\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-12T19:04:54.876975Z","iopub.execute_input":"2024-12-12T19:04:54.877456Z","iopub.status.idle":"2024-12-12T19:05:00.383181Z","shell.execute_reply.started":"2024-12-12T19:04:54.877416Z","shell.execute_reply":"2024-12-12T19:05:00.382428Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"class FashionDataset(Dataset):\n    \n    def __init__(self, data, transform = None):\n        \"\"\"Method to initilaize variables.\"\"\" \n        self.fashion_MNIST = list(data.values)\n        self.transform = transform\n        \n        label = []\n        image = []\n        \n        for i in self.fashion_MNIST:\n             # first column is of labels.\n            label.append(i[0])\n            image.append(i[1:])\n        self.label = np.asarray(label)\n        # Dimension of Images = 28 * 28 * 1. where height = width = 28 and color_channels = 1.\n        self.image = np.asarray(image).reshape(-1, 28, 28, 1).astype('float32')\n\n    def __getitem__(self, index):\n        label = self.label[index]\n        image = self.image[index]\n        \n        if self.transform is not None:\n            image = self.transform(image)\n\n        return image, label\n\n    def __len__(self):\n        return len(self.label)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-12T19:05:00.384982Z","iopub.execute_input":"2024-12-12T19:05:00.385252Z","iopub.status.idle":"2024-12-12T19:05:00.391398Z","shell.execute_reply.started":"2024-12-12T19:05:00.385225Z","shell.execute_reply":"2024-12-12T19:05:00.390455Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"BATCH_SIZE = 32\n\n# Transform data into Tensor that has a range from 0 to 1\ntrain = FashionDataset(train_csv, transform=transforms.Compose([transforms.ToTensor()]))\ntest = FashionDataset(test_csv, transform=transforms.Compose([transforms.ToTensor()]))\n\n# data loader\ntrain_dataloader = DataLoader(train, batch_size = BATCH_SIZE, shuffle = False)\ntest_dataloader = DataLoader(test, batch_size = BATCH_SIZE, shuffle = False)\n\nprint(\"Training data size:\", len(train_dataloader) * BATCH_SIZE)\nprint(\"Test data size:\", len(test_dataloader) * BATCH_SIZE)\n\nfor X, y in test_dataloader:\n    print(f\"Shape of X [N, C, H, W]: {X.shape}\")\n    print(f\"Shape of y: {y.shape} {y.dtype}\")\n    break","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-12T19:05:00.392395Z","iopub.execute_input":"2024-12-12T19:05:00.392665Z","iopub.status.idle":"2024-12-12T19:05:00.793737Z","shell.execute_reply.started":"2024-12-12T19:05:00.392640Z","shell.execute_reply":"2024-12-12T19:05:00.792798Z"}},"outputs":[{"name":"stdout","text":"Training data size: 60000\nTest data size: 10016\nShape of X [N, C, H, W]: torch.Size([32, 1, 28, 28])\nShape of y: torch.Size([32]) torch.int64\n","output_type":"stream"}],"execution_count":5},{"cell_type":"markdown","source":"# **3- Data Visualisation**","metadata":{}},{"cell_type":"code","source":"def output_label(label):\n    output_mapping = {\n                 0: \"T-shirt/Top\",\n                 1: \"Trouser\",\n                 2: \"Pullover\",\n                 3: \"Dress\",\n                 4: \"Coat\", \n                 5: \"Sandal\", \n                 6: \"Shirt\",\n                 7: \"Sneaker\",\n                 8: \"Bag\",\n                 9: \"Ankle Boot\"\n                 }\n    input = (label.item() if type(label) == torch.Tensor else label)\n    return output_mapping[input]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-12T19:05:00.794733Z","iopub.execute_input":"2024-12-12T19:05:00.795000Z","iopub.status.idle":"2024-12-12T19:05:00.799890Z","shell.execute_reply.started":"2024-12-12T19:05:00.794973Z","shell.execute_reply":"2024-12-12T19:05:00.799095Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"demo_loader = DataLoader(train, batch_size=10)\nbatch = next(iter(demo_loader))\nimages, labels = batch\n\ngrid = make_grid(images, nrow=10)\nplt.figure(figsize=(15, 20))\nplt.imshow(np.transpose(grid, (1, 2, 0)))\nprint(\"labels: \", end=\" \")\nfor i, label in enumerate(labels):\n    print(output_label(label), end=\", \")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-12T19:05:00.800796Z","iopub.execute_input":"2024-12-12T19:05:00.801025Z","iopub.status.idle":"2024-12-12T19:05:01.095393Z","shell.execute_reply.started":"2024-12-12T19:05:00.801001Z","shell.execute_reply":"2024-12-12T19:05:01.094494Z"}},"outputs":[{"name":"stdout","text":"labels:  Pullover, Ankle Boot, Shirt, T-shirt/Top, Dress, Coat, Coat, Sandal, Coat, Bag, ","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 1500x2000 with 1 Axes>","image/png":"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"},"metadata":{}}],"execution_count":7},{"cell_type":"markdown","source":"# **4- Define Neural Network Model**","metadata":{}},{"cell_type":"markdown","source":"<div style=\"background-color: green; padding: 10px; border-radius: 10px; \">\n<font size=\"3px\" color=\"white\">\n<hr style=\"color: red;\">\nWe first determine the best device for performing training with cpu as the default device.\n\nWe then define the AI model as a neural network with 3 layers: an input layer, a hidden layer, and an output layer. Between the layers, we use a ReLU activation function.\n\nSince the input images are 1x28x28 tensors, we need to flatten the input tensors into a 784 element tensor using the Flatten module before passing the input into our neural network. \n<hr style=\"color: red;\">\n</font>\n</div>","metadata":{}},{"cell_type":"code","source":"# Get device for training.\ndevice = torch.device(\n    \"cuda\" if torch.cuda.is_available()\n    else \"mps\" if torch.backends.mps.is_available() # Apple Silicon GPU\n    else \"cpu\"\n)\nprint(f\"Using {device} device\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-12T19:05:01.096413Z","iopub.execute_input":"2024-12-12T19:05:01.096692Z","iopub.status.idle":"2024-12-12T19:05:01.182182Z","shell.execute_reply.started":"2024-12-12T19:05:01.096665Z","shell.execute_reply":"2024-12-12T19:05:01.181296Z"}},"outputs":[{"name":"stdout","text":"Using cuda device\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"# Define model\nclass NeuralNetwork(nn.Module):\n    def __init__(self, input_size, hidden_size, num_classes):\n        super().__init__()\n        self.flatten = nn.Flatten()\n        self.linear_relu_stack = nn.Sequential(\n            nn.Linear(input_size, hidden_size),\n            nn.ReLU(),\n            nn.Linear(hidden_size, hidden_size),\n            nn.ReLU(),\n            nn.Linear(hidden_size, num_classes)\n        )\n\n    def forward(self, image_tensor):\n        image_tensor = self.flatten(image_tensor)\n        logits = self.linear_relu_stack(image_tensor)\n        return logits\n\ninput_size = 28*28\nhidden_size = 512\nnum_classes = 10\n\nmodel = NeuralNetwork(input_size, hidden_size, num_classes).to(device)\nprint(model)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-12T19:05:01.183308Z","iopub.execute_input":"2024-12-12T19:05:01.183606Z","iopub.status.idle":"2024-12-12T19:05:01.372755Z","shell.execute_reply.started":"2024-12-12T19:05:01.183578Z","shell.execute_reply":"2024-12-12T19:05:01.371892Z"}},"outputs":[{"name":"stdout","text":"NeuralNetwork(\n  (flatten): Flatten(start_dim=1, end_dim=-1)\n  (linear_relu_stack): Sequential(\n    (0): Linear(in_features=784, out_features=512, bias=True)\n    (1): ReLU()\n    (2): Linear(in_features=512, out_features=512, bias=True)\n    (3): ReLU()\n    (4): Linear(in_features=512, out_features=10, bias=True)\n  )\n)\n","output_type":"stream"}],"execution_count":9},{"cell_type":"markdown","source":"# **5- Training loop**","metadata":{}},{"cell_type":"markdown","source":"<div style=\"background-color: green; padding: 10px; border-radius: 10px; \">\n<font size=\"3px\" color=\"white\">\n<hr style=\"color: red;\">\n We implement a training function to use with the train_dataloader to train our model. Each iteration over the dataloader returns a batch_size image data tensor along with the expected output. After moving the tensors to the device, we call the forward pass of our model, compute the prediction error using the expected output and then call the backwards pass to compute the gradients and apply them to the model parameters. \n<hr style=\"color: red;\">\n</font>\n</div>","metadata":{}},{"cell_type":"code","source":"# Define our learning rate, loss function and optimizer\nloss_fn = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters())\n\n# Let's define our training function \ndef train(dataloader, model, loss_fn, optimizer):\n    size = len(dataloader.dataset)\n    model.train()\n\n    for batch_num, (X, y) in enumerate(dataloader):\n        X, y = X.to(device), y.to(device)\n\n        # Forward pass to compute prediction\n        pred = model(X)\n        # Compute prediction error using loss function\n        loss = loss_fn(pred, y)\n\n        # Backward pass\n        optimizer.zero_grad() # zero any previous gradient calculations\n        loss.backward() # calculate gradient\n        optimizer.step() # update model parameters\n        \n        if batch_num > 0 and batch_num % 100 == 0:\n            loss, current = loss.item(), batch_num * len(X)\n            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-12T19:05:01.374851Z","iopub.execute_input":"2024-12-12T19:05:01.375115Z","iopub.status.idle":"2024-12-12T19:05:01.381268Z","shell.execute_reply.started":"2024-12-12T19:05:01.375088Z","shell.execute_reply":"2024-12-12T19:05:01.380489Z"}},"outputs":[],"execution_count":10},{"cell_type":"markdown","source":"# **6- Test Loop**","metadata":{}},{"cell_type":"markdown","source":"<div style=\"background-color: green; padding: 10px; border-radius: 10px; \">\n<font size=\"3px\" color=\"white\">\n<hr style=\"color: red;\">\nThe test methods evaluates the model's predictive performance using the test_dataloader. During testing, we don't require gradient computation, so we set the model in evaluate mode.\n<hr style=\"color: red;\">\n</font>\n</div>","metadata":{}},{"cell_type":"code","source":"# Our test function\ndef test(dataloader, model, loss_fn):\n    size = len(dataloader.dataset)\n    num_batches = len(dataloader)\n    model.eval()\n    test_loss, correct = 0, 0\n    for X, y in dataloader:\n        X, y = X.to(device), y.to(device)\n        pred = model(X)\n        test_loss += loss_fn(pred, y).item()\n        correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n    test_loss /= num_batches\n    correct /= size\n    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-12T19:05:01.382218Z","iopub.execute_input":"2024-12-12T19:05:01.382529Z","iopub.status.idle":"2024-12-12T19:05:01.395934Z","shell.execute_reply.started":"2024-12-12T19:05:01.382492Z","shell.execute_reply":"2024-12-12T19:05:01.395088Z"}},"outputs":[],"execution_count":11},{"cell_type":"markdown","source":"# **7- Train the Neural Network Model**","metadata":{}},{"cell_type":"markdown","source":"<div style=\"background-color: green; padding: 10px; border-radius: 10px; \">\n<font size=\"3px\" color=\"white\">\n<hr style=\"color: red;\">\nNow that we have defined methods to train our model and test the trained model's predictive behavior, lets train the model for 5 epochs over the dataset.\n<hr style=\"color: red;\">\n</font>\n</div>","metadata":{}},{"cell_type":"code","source":"# Let's run training\nepochs = 5\nfor t in range(epochs):\n    print(f\"Epoch {t+1}\\n-------------------------------\")\n    train(train_dataloader, model, loss_fn, optimizer)\n    test(test_dataloader, model, loss_fn)\nprint(\"Done!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-12T19:05:01.397049Z","iopub.execute_input":"2024-12-12T19:05:01.397626Z","iopub.status.idle":"2024-12-12T19:05:18.825028Z","shell.execute_reply.started":"2024-12-12T19:05:01.397588Z","shell.execute_reply":"2024-12-12T19:05:18.824316Z"}},"outputs":[{"name":"stdout","text":"Epoch 1\n-------------------------------\nloss: 0.979153  [ 3200/60000]\nloss: 0.503783  [ 6400/60000]\nloss: 0.536911  [ 9600/60000]\nloss: 1.057619  [12800/60000]\nloss: 0.365578  [16000/60000]\nloss: 0.386335  [19200/60000]\nloss: 0.628439  [22400/60000]\nloss: 0.306261  [25600/60000]\nloss: 0.837170  [28800/60000]\nloss: 0.718296  [32000/60000]\nloss: 0.501915  [35200/60000]\nloss: 0.425205  [38400/60000]\nloss: 0.415609  [41600/60000]\nloss: 0.315044  [44800/60000]\nloss: 0.785460  [48000/60000]\nloss: 0.319825  [51200/60000]\nloss: 0.312713  [54400/60000]\nloss: 0.573245  [57600/60000]\nTest Error: \n Accuracy: 84.5%, Avg loss: 0.428401 \n\nEpoch 2\n-------------------------------\nloss: 0.475656  [ 3200/60000]\nloss: 0.416803  [ 6400/60000]\nloss: 0.307328  [ 9600/60000]\nloss: 0.784800  [12800/60000]\nloss: 0.215825  [16000/60000]\nloss: 0.249738  [19200/60000]\nloss: 0.428722  [22400/60000]\nloss: 0.284105  [25600/60000]\nloss: 0.476458  [28800/60000]\nloss: 0.653090  [32000/60000]\nloss: 0.467517  [35200/60000]\nloss: 0.334495  [38400/60000]\nloss: 0.394682  [41600/60000]\nloss: 0.227568  [44800/60000]\nloss: 0.611486  [48000/60000]\nloss: 0.117945  [51200/60000]\nloss: 0.296035  [54400/60000]\nloss: 0.215874  [57600/60000]\nTest Error: \n Accuracy: 85.3%, Avg loss: 0.448287 \n\nEpoch 3\n-------------------------------\nloss: 0.558704  [ 3200/60000]\nloss: 0.341109  [ 6400/60000]\nloss: 0.276440  [ 9600/60000]\nloss: 0.777160  [12800/60000]\nloss: 0.297629  [16000/60000]\nloss: 0.203412  [19200/60000]\nloss: 0.415413  [22400/60000]\nloss: 0.247613  [25600/60000]\nloss: 0.342679  [28800/60000]\nloss: 0.579080  [32000/60000]\nloss: 0.387125  [35200/60000]\nloss: 0.367391  [38400/60000]\nloss: 0.299197  [41600/60000]\nloss: 0.246812  [44800/60000]\nloss: 0.542199  [48000/60000]\nloss: 0.215832  [51200/60000]\nloss: 0.281647  [54400/60000]\nloss: 0.138939  [57600/60000]\nTest Error: \n Accuracy: 86.1%, Avg loss: 0.419638 \n\nEpoch 4\n-------------------------------\nloss: 0.546505  [ 3200/60000]\nloss: 0.439016  [ 6400/60000]\nloss: 0.317942  [ 9600/60000]\nloss: 0.538012  [12800/60000]\nloss: 0.134708  [16000/60000]\nloss: 0.256881  [19200/60000]\nloss: 0.432082  [22400/60000]\nloss: 0.219106  [25600/60000]\nloss: 0.495529  [28800/60000]\nloss: 0.447459  [32000/60000]\nloss: 0.403021  [35200/60000]\nloss: 0.360424  [38400/60000]\nloss: 0.237382  [41600/60000]\nloss: 0.207588  [44800/60000]\nloss: 0.574618  [48000/60000]\nloss: 0.097097  [51200/60000]\nloss: 0.362988  [54400/60000]\nloss: 0.131667  [57600/60000]\nTest Error: \n Accuracy: 87.0%, Avg loss: 0.389022 \n\nEpoch 5\n-------------------------------\nloss: 0.542940  [ 3200/60000]\nloss: 0.371647  [ 6400/60000]\nloss: 0.267112  [ 9600/60000]\nloss: 0.493017  [12800/60000]\nloss: 0.164112  [16000/60000]\nloss: 0.268645  [19200/60000]\nloss: 0.416837  [22400/60000]\nloss: 0.270891  [25600/60000]\nloss: 0.398265  [28800/60000]\nloss: 0.452503  [32000/60000]\nloss: 0.438829  [35200/60000]\nloss: 0.433321  [38400/60000]\nloss: 0.265793  [41600/60000]\nloss: 0.219994  [44800/60000]\nloss: 0.387167  [48000/60000]\nloss: 0.112957  [51200/60000]\nloss: 0.354181  [54400/60000]\nloss: 0.119495  [57600/60000]\nTest Error: \n Accuracy: 86.2%, Avg loss: 0.395123 \n\nDone!\n","output_type":"stream"}],"execution_count":12},{"cell_type":"markdown","source":"# **8- Define Convolutional Neural Networks Model**","metadata":{}},{"cell_type":"code","source":"class ConvolutionalNeuralNetworks(nn.Module):\n    def __init__(self, num_classes):\n        super(ConvolutionalNeuralNetworks, self).__init__()\n        self.conv_layers = nn.Sequential(\n            nn.Conv2d(in_channels=1, out_channels=32, kernel_size=5, stride=1, padding=2),\n            nn.BatchNorm2d(32),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=5, stride=1, padding=2),\n            nn.BatchNorm2d(64),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=2, stride=2)\n        )\n\n        self.dense_layers = nn.Sequential(\n            nn.Dropout(0.2),\n            nn.Linear(7 * 7 * 64, num_classes),\n        )\n\n    def forward(self, x):\n        out = self.conv_layers(x)\n        out = out.reshape(out.size(0), -1)\n        out = self.dense_layers(out)\n        return out","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-12T19:05:18.826085Z","iopub.execute_input":"2024-12-12T19:05:18.826450Z","iopub.status.idle":"2024-12-12T19:05:18.833851Z","shell.execute_reply.started":"2024-12-12T19:05:18.826410Z","shell.execute_reply":"2024-12-12T19:05:18.832856Z"}},"outputs":[],"execution_count":13},{"cell_type":"markdown","source":"# **9- Training loop**","metadata":{}},{"cell_type":"code","source":"# Let's define our training function \ndef train():\n    Train_epoch = 5\n    model = ConvolutionalNeuralNetworks(num_classes).to(device)\n    # Define our learning rate, loss function and optimizer\n    loss_fn = nn.CrossEntropyLoss()\n    optimizer = torch.optim.Adam(model.parameters(), lr = 0.002)\n    \n    for epoch in range(1, Train_epoch + 1):\n        for batch_num, (X, y) in enumerate(train_dataloader):\n            X, y = X.to(device), y.to(device)\n\n            # Forward pass to compute prediction\n            pred = model(X)\n            # Compute prediction error using loss function\n            loss = loss_fn(pred, y)\n\n            # Backward pass\n            optimizer.zero_grad() # zero any previous gradient calculations\n            loss.backward() # calculate gradient\n            optimizer.step() # update model parameters\n\n            if batch_num % 1000 == 0:\n                print('Loss :{:.4f} Epoch[{}/{}]'.format(loss.item(), epoch, Train_epoch))\n    return model","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-12T19:05:18.834782Z","iopub.execute_input":"2024-12-12T19:05:18.835051Z","iopub.status.idle":"2024-12-12T19:05:18.849072Z","shell.execute_reply.started":"2024-12-12T19:05:18.835025Z","shell.execute_reply":"2024-12-12T19:05:18.848324Z"}},"outputs":[],"execution_count":14},{"cell_type":"markdown","source":"# **10- Test Loop**","metadata":{}},{"cell_type":"code","source":"# Our test function\ndef test(model):\n    with torch.no_grad():\n        correct = 0\n        total = 0\n        for X, y in test_dataloader:\n            X = X.to(device)\n            y = y.to(device)\n            pred = model(X)\n            pred = torch.argmax(pred,dim=1)\n            total += y.size(0)\n            correct += (pred == y).sum().item()\n        print('Test Accuracy of the model on the test images: {} %'.format(100 * correct / total))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-12T19:05:18.849962Z","iopub.execute_input":"2024-12-12T19:05:18.850205Z","iopub.status.idle":"2024-12-12T19:05:18.858768Z","shell.execute_reply.started":"2024-12-12T19:05:18.850181Z","shell.execute_reply":"2024-12-12T19:05:18.858031Z"}},"outputs":[],"execution_count":15},{"cell_type":"markdown","source":"# **11- Train the CNN Model**","metadata":{}},{"cell_type":"code","source":"if __name__ == '__main__':\n    model = train()\n    test(model)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-12T19:05:18.859541Z","iopub.execute_input":"2024-12-12T19:05:18.859768Z","iopub.status.idle":"2024-12-12T19:05:42.432767Z","shell.execute_reply.started":"2024-12-12T19:05:18.859744Z","shell.execute_reply":"2024-12-12T19:05:42.431825Z"}},"outputs":[{"name":"stdout","text":"Loss :2.5026 Epoch[1/5]\nLoss :0.5341 Epoch[1/5]\nLoss :0.2803 Epoch[2/5]\nLoss :0.4026 Epoch[2/5]\nLoss :0.1582 Epoch[3/5]\nLoss :0.3913 Epoch[3/5]\nLoss :0.1775 Epoch[4/5]\nLoss :0.2756 Epoch[4/5]\nLoss :0.1788 Epoch[5/5]\nLoss :0.2523 Epoch[5/5]\nTest Accuracy of the model on the test images: 89.75 %\n","output_type":"stream"}],"execution_count":16},{"cell_type":"markdown","source":"<div style=\"background-color: red; padding: 20px; border-radius: 25px; \">\n<font color='white' size=\"5px\">\nIf my notebook was useful for you, please give me a upvote. Thank you for your support ❤️\n    <hr style=\"color: green;\"></font>\n    <font size=\"5px\">\n         <a href=\"https://github.com/omid-sakaki-ghazvini\">Github</a>\n        <br/>\n        <a href=\"http://linkedin.com/in/omid-sakaki-ghazvini-378687217\">linkedin</a> \n    </font>\n</div>","metadata":{}}]}